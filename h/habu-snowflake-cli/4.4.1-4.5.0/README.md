# Comparing `tmp/habu_snowflake_cli-4.4.1-py3-none-any.whl.zip` & `tmp/habu_snowflake_cli-4.5.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,39 +1,39 @@
-Zip file size: 38889 bytes, number of entries: 37
--rw-r--r--  2.0 unx      351 b- defN 24-May-16 11:22 redbeard.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-16 11:22 redbeard_cli/__init__.py
--rw-r--r--  2.0 unx      122 b- defN 24-May-16 11:22 redbeard_cli/file_utils.py
--rw-r--r--  2.0 unx     4580 b- defN 24-May-16 11:22 redbeard_cli/snowflake_utils.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-16 11:22 redbeard_cli/commands/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-16 11:22 redbeard_cli/commands/init/__init__.py
--rw-r--r--  2.0 unx     2398 b- defN 24-May-16 11:22 redbeard_cli/commands/init/clean_room_setup.py
--rw-r--r--  2.0 unx     2259 b- defN 24-May-16 11:22 redbeard_cli/commands/init/cli.py
--rw-r--r--  2.0 unx     3686 b- defN 24-May-16 11:22 redbeard_cli/commands/init/habu_setup.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-16 11:22 redbeard_cli/example/__init__.py
--rw-r--r--  2.0 unx     5110 b- defN 24-May-16 11:22 redbeard_cli/example/dataset.py
--rw-r--r--  2.0 unx     5678 b- defN 24-May-16 11:22 redbeard_cli/example/overlap_queries.py
--rw-r--r--  2.0 unx     3449 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__1init_habu_installer.sql
--rw-r--r--  2.0 unx    10653 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__create_new_dataset.sql
--rw-r--r--  2.0 unx      772 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__handle_error.sql
--rw-r--r--  2.0 unx     3403 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__handle_management_command.sql
--rw-r--r--  2.0 unx    14184 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql
--rw-r--r--  2.0 unx     2092 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__init_habu_shares.sql
--rw-r--r--  2.0 unx     9525 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__new_data_connection.sql
--rw-r--r--  2.0 unx    12182 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__new_question_run.sql
--rw-r--r--  2.0 unx     4960 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__post_run_query.sql
--rw-r--r--  2.0 unx     1232 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__process_request.sql
--rw-r--r--  2.0 unx     4572 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__question_run_accept_result_share.sql
--rw-r--r--  2.0 unx     5885 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__question_run_cleanup.sql
--rw-r--r--  2.0 unx     6346 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__question_run_data_share.sql
--rw-r--r--  2.0 unx     5663 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__question_run_result_share.sql
--rw-r--r--  2.0 unx     4626 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql
--rw-r--r--  2.0 unx     3173 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql
--rw-r--r--  2.0 unx     6622 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__setup_streams_tasks.sql
--rw-r--r--  2.0 unx      603 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/R__sp_logger.sql
--rw-r--r--  2.0 unx      230 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/V1_0_0_create.sql
--rw-r--r--  2.0 unx        0 b- defN 24-May-16 11:22 redbeard_cli/sqlfiles/__init__.py
--rw-r--r--  2.0 unx     1379 b- defN 24-May-16 11:22 habu_snowflake_cli-4.4.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-16 11:22 habu_snowflake_cli-4.4.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       42 b- defN 24-May-16 11:22 habu_snowflake_cli-4.4.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       22 b- defN 24-May-16 11:22 habu_snowflake_cli-4.4.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3588 b- defN 24-May-16 11:22 habu_snowflake_cli-4.4.1.dist-info/RECORD
-37 files, 129479 bytes uncompressed, 32943 bytes compressed:  74.6%
+Zip file size: 39589 bytes, number of entries: 37
+-rw-r--r--  2.0 unx      351 b- defN 24-May-20 16:15 redbeard.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-20 16:15 redbeard_cli/__init__.py
+-rw-r--r--  2.0 unx      122 b- defN 24-May-20 16:15 redbeard_cli/file_utils.py
+-rw-r--r--  2.0 unx     4580 b- defN 24-May-20 16:15 redbeard_cli/snowflake_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-20 16:15 redbeard_cli/commands/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-20 16:15 redbeard_cli/commands/init/__init__.py
+-rw-r--r--  2.0 unx     2398 b- defN 24-May-20 16:15 redbeard_cli/commands/init/clean_room_setup.py
+-rw-r--r--  2.0 unx     2259 b- defN 24-May-20 16:15 redbeard_cli/commands/init/cli.py
+-rw-r--r--  2.0 unx     3686 b- defN 24-May-20 16:15 redbeard_cli/commands/init/habu_setup.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-20 16:15 redbeard_cli/example/__init__.py
+-rw-r--r--  2.0 unx     5110 b- defN 24-May-20 16:15 redbeard_cli/example/dataset.py
+-rw-r--r--  2.0 unx     5678 b- defN 24-May-20 16:15 redbeard_cli/example/overlap_queries.py
+-rw-r--r--  2.0 unx     3449 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__1init_habu_installer.sql
+-rw-r--r--  2.0 unx    10653 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__create_new_dataset.sql
+-rw-r--r--  2.0 unx      772 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__handle_error.sql
+-rw-r--r--  2.0 unx     3403 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__handle_management_command.sql
+-rw-r--r--  2.0 unx    14184 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql
+-rw-r--r--  2.0 unx     2092 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__init_habu_shares.sql
+-rw-r--r--  2.0 unx     9526 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__new_data_connection.sql
+-rw-r--r--  2.0 unx    12640 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__new_question_run.sql
+-rw-r--r--  2.0 unx     4960 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__post_run_query.sql
+-rw-r--r--  2.0 unx     1232 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__process_request.sql
+-rw-r--r--  2.0 unx     4572 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__question_run_accept_result_share.sql
+-rw-r--r--  2.0 unx     5773 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__question_run_cleanup.sql
+-rw-r--r--  2.0 unx     6346 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__question_run_data_share.sql
+-rw-r--r--  2.0 unx     5663 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__question_run_result_share.sql
+-rw-r--r--  2.0 unx     6200 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql
+-rw-r--r--  2.0 unx     3173 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql
+-rw-r--r--  2.0 unx     8478 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__setup_streams_tasks.sql
+-rw-r--r--  2.0 unx      603 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/R__sp_logger.sql
+-rw-r--r--  2.0 unx      230 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/V1_0_0_create.sql
+-rw-r--r--  2.0 unx        0 b- defN 24-May-20 16:15 redbeard_cli/sqlfiles/__init__.py
+-rw-r--r--  2.0 unx     1380 b- defN 24-May-20 16:15 habu_snowflake_cli-4.5.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-20 16:15 habu_snowflake_cli-4.5.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       42 b- defN 24-May-20 16:15 habu_snowflake_cli-4.5.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       22 b- defN 24-May-20 16:15 habu_snowflake_cli-4.5.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3588 b- defN 24-May-20 16:15 habu_snowflake_cli-4.5.0.dist-info/RECORD
+37 files, 133257 bytes uncompressed, 33643 bytes compressed:  74.8%
```

## zipnote {}

```diff
@@ -90,23 +90,23 @@
 
 Filename: redbeard_cli/sqlfiles/V1_0_0_create.sql
 Comment: 
 
 Filename: redbeard_cli/sqlfiles/__init__.py
 Comment: 
 
-Filename: habu_snowflake_cli-4.4.1.dist-info/METADATA
+Filename: habu_snowflake_cli-4.5.0.dist-info/METADATA
 Comment: 
 
-Filename: habu_snowflake_cli-4.4.1.dist-info/WHEEL
+Filename: habu_snowflake_cli-4.5.0.dist-info/WHEEL
 Comment: 
 
-Filename: habu_snowflake_cli-4.4.1.dist-info/entry_points.txt
+Filename: habu_snowflake_cli-4.5.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: habu_snowflake_cli-4.4.1.dist-info/top_level.txt
+Filename: habu_snowflake_cli-4.5.0.dist-info/top_level.txt
 Comment: 
 
-Filename: habu_snowflake_cli-4.4.1.dist-info/RECORD
+Filename: habu_snowflake_cli-4.5.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## redbeard_cli/sqlfiles/R__new_data_connection.sql

```diff
@@ -101,14 +101,15 @@
                 var msg1 = "The validation of tables is going to be skipped."
                 snowflake.createStatement({
                     sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                     binds:[msg1, REQUEST_ID, Object.keys(this)[0]]
                 }).execute();
             }
 
+
             var deleteColumns = "DELETE FROM HABU_DATA_CONNECTIONS.DATA_CONNECTIONS.DATA_CONNECTION_COLUMNS WHERE DATA_CONNECTION_ID = '" + DATA_CONNECTION_ID + "'";
             snowflake.execute({
                 sqlText:  deleteColumns
             });
 
             var deleteConnections = "DELETE FROM HABU_DATA_CONNECTIONS.DATA_CONNECTIONS.DATA_CONNECTIONS WHERE ID = '" + DATA_CONNECTION_ID + "'";
             snowflake.execute({
```

## redbeard_cli/sqlfiles/R__new_question_run.sql

```diff
@@ -119,14 +119,24 @@
             return null;
         }
 
         // Install the New question run stored procedure
 
         try {
 
+            var rs = snowflake.execute({sqlText: "SELECT CURRENT_WAREHOUSE()"});
+            rs.next();
+            var warehouse_used = rs.getColumnValue(1);
+
+            msg = `Executing the question run report request using warehouse size - ${warehouse_used}`
+            snowflake.createStatement({
+                sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
+                binds:[msg, REQUEST_ID, Object.keys(this)[0]]
+            }).execute();
+
             var sf_clean_room_id = CLEAN_ROOM_ID.replace(/-/g, '').toUpperCase();
 
             var habuShareDb = "HABU_CR_" + sf_clean_room_id + "_HABU_SHARE"
 
             snowflake.execute({
                 sqlText: RESULT_TABLE_DDL
             });
```

## redbeard_cli/sqlfiles/R__question_run_cleanup.sql

```diff
@@ -27,25 +27,21 @@
                 var requestID = rs.getColumnValue(1);
                 var cleanRoomID = rs.getColumnValue(2);
                 var computeAccountId = rs.getColumnValue(3);
                 var statementHash = rs.getColumnValue(4);
                 var procedureName = rs.getColumnValue(5);
                 var cleanRoomVersion = rs.getColumnValue(6);
 
-                if (procedureName == null) {
-                    procedureName = '';
-                }
-
                 questionDataShareParams.push({
                     'requestID': requestID,
                     'cleanRoomID': cleanRoomID,
                     'computeAccountId': computeAccountId,
                     'statementHash': statementHash,
                     'procedureName': procedureName,
-                    'cleanRoomVersion': cleanRoomVersion,
+                    'cleanRoomVersion': cleanRoomVersion
                 })
                 snowflake.execute({
                         sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                         binds: ["IN_PROGRESS", requestID]
                 });
             }
 
@@ -77,15 +73,15 @@
         }
         return result;
     $$;
 
 CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.QUESTION_RUN_CLEANUP
     (REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR, PROCEDURE_SQL VARCHAR, CLEAN_ROOM_VERSION VARCHAR)
     RETURNS STRING
-    LANGUAGE JAVASCRIPT STRICT
+    LANGUAGE JAVASCRIPT
     EXECUTE AS OWNER AS
     $$
         // Installs run clean up procedure
 
         try {
 
             STATEMENT_HASHES = STATEMENT_HASH.split(",");
```

## redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql

```diff
@@ -71,13 +71,25 @@
         snowflake.execute({ sqlText: sqlcmd });
         snowflake.execute({
             sqlText: "ALTER SHARE HABU_CLEAN_ROOM_COMMON_SHARE ADD ACCOUNTS = :1 SHARE_RESTRICTIONS = " + SHARE_RESTRICTIONS,
             binds: [HABU_ACCOUNT]
         });
         sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_XLARGE_WH WAREHOUSE_SIZE = XLARGE INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
         snowflake.execute({ sqlText: sqlcmd });
+        sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_X2LARGE_WH WAREHOUSE_SIZE = X2LARGE INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
+        snowflake.execute({ sqlText: sqlcmd });
+        sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_X3LARGE_WH WAREHOUSE_SIZE = X3LARGE INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
+        snowflake.execute({ sqlText: sqlcmd });
+        sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_X4LARGE_WH WAREHOUSE_SIZE = X4LARGE INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
+        snowflake.execute({ sqlText: sqlcmd });
+        sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_XSMALL_WH WAREHOUSE_SIZE = XSMALL INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
+        snowflake.execute({ sqlText: sqlcmd });
+        sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_SNOWPARK_XLARGE_WH WAREHOUSE_SIZE = XLARGE WAREHOUSE_TYPE='SNOWPARK-OPTIMIZED' INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
+        snowflake.execute({ sqlText: sqlcmd });
+        sqlcmd = "CREATE WAREHOUSE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON_SNOWPARK_X2LARGE_WH WAREHOUSE_SIZE = X2LARGE WAREHOUSE_TYPE='SNOWPARK-OPTIMIZED' INITIALLY_SUSPENDED = TRUE AUTO_SUSPEND = 30 COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
+        snowflake.execute({ sqlText: sqlcmd });
         return "Setup of cleanroom common objects successful";
     $$;
 
 
 end;
```

## redbeard_cli/sqlfiles/R__setup_streams_tasks.sql

```diff
@@ -50,19 +50,14 @@
         AS CALL CLEAN_ROOM.HANDLE_QUESTION_RUN_RESULT_SHARE()"
     snowflake.execute({ sqlText: question_run_result_share_task });
     var question_run_accept_result_share_task = "CREATE OR REPLACE TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_ACCEPT_RESULT_SHARE_TASK \
         USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL' \
         AFTER CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK \
         AS CALL CLEAN_ROOM.HANDLE_QUESTION_RUN_ACCEPT_RESULT_SHARE()"
     snowflake.execute({ sqlText: question_run_accept_result_share_task });
-    var new_question_runs_task = "CREATE OR REPLACE TASK CLEAN_ROOM.HANDLE_NEW_QUESTION_RUNS_TASK \
-        WAREHOUSE = HABU_CLEAN_ROOM_COMMON_XLARGE_WH \
-        AFTER CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK \
-        AS CALL CLEAN_ROOM.HANDLE_NEW_QUESTION_RUNS()"
-    snowflake.execute({ sqlText: new_question_runs_task });
     var post_run_query_task = "CREATE OR REPLACE TASK CLEAN_ROOM.HANDLE_POST_RUN_QUERY_TASK \
         WAREHOUSE = HABU_CLEAN_ROOM_COMMON_XLARGE_WH \
         AFTER CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK \
         AS CALL CLEAN_ROOM.HANDLE_POST_RUN_QUERY()"
     snowflake.execute({ sqlText: post_run_query_task });
     mgmt_commands_task = "CREATE OR REPLACE TASK CLEAN_ROOM.HANDLE_MGMT_COMMANDS_TASK \
         USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL' \
@@ -78,21 +73,67 @@
     // TODO: fails with error - SQL compilation error: Query called from a stored procedure contains a function with side effects [SYSTEM$TASK_DEPENDENTS_ENABLE]
     // snowflake.execute({ sqlText: "SELECT SYSTEM$TASK_DEPENDENTS_ENABLE('CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK')" });
     // Since recursively resuming all the dependent task tied to root task is not working,
     // explicitly resuming all the tasks in reverse order. Children tasks muste be started before the root task.
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_POST_RUN_QUERY_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_ADD_DATA_CONNECTION_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_MGMT_COMMANDS_TASK RESUME" });
-    snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_NEW_QUESTION_RUNS_TASK RESUME" });
+    snowflake.execute({ sqlText: "DROP TASK IF EXISTS CLEAN_ROOM.HANDLE_NEW_QUESTION_RUNS_TASK" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_CLEANUP_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_RESULT_SHARE_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_ACCEPT_RESULT_SHARE_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_DATA_SHARE_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_NEW_DATASETS_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_NEW_CLEAN_ROOMS_TASK RESUME" });
+
+    const warehouseSizes = ['XSMALL', 'XLARGE', 'X2LARGE', 'X3LARGE', 'X4LARGE', 'SNOWPARK_XLARGE', 'SNOWPARK_X2LARGE'];
+
+    warehouseSizes.forEach(warehouseSize => {
+        var pendingMessageTaskName = `CHECK_QUESTION_RUN_REQUESTS_FOR_${warehouseSize}_TASK`;
+        var handlePendingMessageTaskName = `HANDLE_NEW_QUESTION_RUNS_WITH_${warehouseSize}_TASK`;
+
+         var new_question_runs_check_task = `CREATE OR REPLACE TASK CLEAN_ROOM.${pendingMessageTaskName} \
+            USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL' \
+            AFTER CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK \
+            AS CALL CLEAN_ROOM.PENDING_MESSAGE_COUNT_FOR_WAREHOUSE_TYPE('${warehouseSize}')`
+        snowflake.execute({ sqlText: new_question_runs_check_task });
+
+        var new_question_runs_handle_task = `CREATE OR REPLACE TASK CLEAN_ROOM.${handlePendingMessageTaskName} \
+            WAREHOUSE = HABU_CLEAN_ROOM_COMMON_${warehouseSize}_WH \
+            AFTER CLEAN_ROOM.${pendingMessageTaskName} \
+            WHEN SYSTEM$GET_PREDECESSOR_RETURN_VALUE() != '0' \
+            AS CALL CLEAN_ROOM.HANDLE_NEW_QUESTION_RUNS()`
+        snowflake.execute({ sqlText: new_question_runs_handle_task });
+
+        snowflake.execute({ sqlText: `ALTER TASK CLEAN_ROOM.${pendingMessageTaskName} RESUME` });
+        snowflake.execute({ sqlText: `ALTER TASK CLEAN_ROOM.${handlePendingMessageTaskName} RESUME` });
+    });
+
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK RESUME" });
+
 return "Setup of stream and tasks successful";
 $$;
 
+CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.PENDING_MESSAGE_COUNT_FOR_WAREHOUSE_TYPE(WAREHOUSE_SIZE VARCHAR)
+RETURNS STRING
+LANGUAGE JAVASCRIPT
+EXECUTE AS CALLER
+AS $$
+
+    var cnt_result = 0;
+    var sql_command = "select count(request_data:warehouse_size) as cnt \
+        from habu_clean_room_common.clean_room.clean_room_requests \
+        where request_type = 'NEW_QUESTION_RUN' and request_status = 'PENDING' \
+        and request_data:warehouse_size = '" + WAREHOUSE_SIZE + "'";
+    var stmt = snowflake.createStatement({sqlText: sql_command});
+    var rs = stmt.execute();
+    if(rs.next()) {
+       cnt_result = rs.getColumnValue(1);
+    }
+
+    snowflake.createStatement({sqlText:`call system$set_return_value('${cnt_result}');`}).execute();
+$$;
+
+
 
 end;
```

## Comparing `habu_snowflake_cli-4.4.1.dist-info/METADATA` & `habu_snowflake_cli-4.5.0.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 Metadata-Version: 2.1
 Name: habu-snowflake-cli
-Version: 4.4.1
+Version: 4.5.0
 Summary: Redbeard - Habu Snowflake CLI
 Home-page: https://github.com/deklareddotcom/redbeard
 Author: Habu Engineering
 Author-email: engineering@habu.com
 Requires-Python: >=3.7.10
 Description-Content-Type: text/markdown
 Requires-Dist: python-dotenv ~=1.0.0
 Requires-Dist: click ~=8.1.7
-Requires-Dist: snowflake-connector-python ~=3.5.0
+Requires-Dist: snowflake-connector-python ~=3.10.0
 Requires-Dist: pyyaml ~=6.0
 
 # redbeard
 Snowflake Clean Room Pattern Implementation
 
 ```shell
 % redbeard --help
```

## Comparing `habu_snowflake_cli-4.4.1.dist-info/RECORD` & `habu_snowflake_cli-4.5.0.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -12,26 +12,26 @@
 redbeard_cli/example/overlap_queries.py,sha256=eTjgpHD6Z0Bz7E-gHBrc0YUDlpe4oBXvjJO2XlPdvK4,5678
 redbeard_cli/sqlfiles/R__1init_habu_installer.sql,sha256=n82olM-HfQ0NX9a91xPAE0SCDqt1zYaEoPc5fzBbgOE,3449
 redbeard_cli/sqlfiles/R__create_new_dataset.sql,sha256=ZRa6O4GU39de3y_ZtF6ie2V-s8ucWrq9p22A96dDGkc,10653
 redbeard_cli/sqlfiles/R__handle_error.sql,sha256=O7F7KGxU7cTWReSXRrIl0FIVTgZsEPGBpWuhsQHJaJM,772
 redbeard_cli/sqlfiles/R__handle_management_command.sql,sha256=EGP9GNt8nE9lKynzqlGohBeH9HSyaAPl_5tyvrQ5N40,3403
 redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql,sha256=GQsrhfcpLzOQT0cpnS2cC7LHz6ZmX51bTvE6MJU1Ifo,14184
 redbeard_cli/sqlfiles/R__init_habu_shares.sql,sha256=eWiskB-Dc1J-flvL0YtBHUKEjuEolpMO_YsnyPH7HU8,2092
-redbeard_cli/sqlfiles/R__new_data_connection.sql,sha256=3lMpRC4XqZc7gjQLKAjFIviVudEFyrtWg-qj6LU-7C4,9525
-redbeard_cli/sqlfiles/R__new_question_run.sql,sha256=n3mmOAxuEE-7T8Hs2eXfD1uXrr1-jvoqVAAAR4xlQRM,12182
+redbeard_cli/sqlfiles/R__new_data_connection.sql,sha256=nBqF54aN1_a--MgAmOYbV34pMzY93myibOCowl5c5qk,9526
+redbeard_cli/sqlfiles/R__new_question_run.sql,sha256=qB0GyQO422UPEuIRMQk9d9BwyxBU5BFMz13FlGohLE4,12640
 redbeard_cli/sqlfiles/R__post_run_query.sql,sha256=gBHFYote4IXxXyAcQgQrxQvsWHTgcfGfHUQVmTyrE-k,4960
 redbeard_cli/sqlfiles/R__process_request.sql,sha256=92ww0gUZ2OCNlE7zfL8iv_jaGCVc4KtjcKir7HwM4ko,1232
 redbeard_cli/sqlfiles/R__question_run_accept_result_share.sql,sha256=5ZC303KRElku484gXcpui8FcRRptzPcXWl21CO7bjw4,4572
-redbeard_cli/sqlfiles/R__question_run_cleanup.sql,sha256=Hvqck9ZRze36gjJxtiigK1xGhKIsdtSrpFxqoYAjIeU,5885
+redbeard_cli/sqlfiles/R__question_run_cleanup.sql,sha256=HXnPEmXoO0OPTIjHF-BOlYbLWY5Ho97T3Co2RaQNdWg,5773
 redbeard_cli/sqlfiles/R__question_run_data_share.sql,sha256=2ZEzlnCHv6bWoug7ZzpfqzmqivVnGPytjB50bmKa3uY,6346
 redbeard_cli/sqlfiles/R__question_run_result_share.sql,sha256=hRPgDOu_QcUvFpCSJlVPublWHpOuIWKbOgcGI1unySo,5663
-redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql,sha256=pxOlGmEA6VPp5qgTIQ3GaEbuwiNOd_Rr64iZF6faWtc,4626
+redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql,sha256=4EsSy0BxbUbTlIy1k_r6or-45jv_vKJDItcsehB9y7U,6200
 redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql,sha256=A0TjYFN2kshUWA1tonnvjV3GaoWg1eoA1p2tv5_CRaE,3173
-redbeard_cli/sqlfiles/R__setup_streams_tasks.sql,sha256=qxvNWU_ghAOL1b47dI8d3hTbKBlTuYjxAgjre6SXjLY,6622
+redbeard_cli/sqlfiles/R__setup_streams_tasks.sql,sha256=gqMOvT_as3sIdzWmmbD20FmrhYi9y4cwbBejfx2hroA,8478
 redbeard_cli/sqlfiles/R__sp_logger.sql,sha256=qPlR74KPyCqwtPV2aTscBu5ibDHKFfFF2WpG1GFNVIE,603
 redbeard_cli/sqlfiles/V1_0_0_create.sql,sha256=wSHv2p4FLQaB86zT4Z6mJNY7c3-yBSPTnn5z3cJTau4,230
 redbeard_cli/sqlfiles/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-habu_snowflake_cli-4.4.1.dist-info/METADATA,sha256=hrHVWuyzqQHgRf57Cr_mXdcgYcYTHpR8TRVl8xA4ruY,1379
-habu_snowflake_cli-4.4.1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-habu_snowflake_cli-4.4.1.dist-info/entry_points.txt,sha256=9mLwEgYq-eMv3F-c_p2EuoHFvOcQV8H-ozKR7BIF3Og,42
-habu_snowflake_cli-4.4.1.dist-info/top_level.txt,sha256=n-bjqTpxh0D3sxTdlhDISfzTBZQR-i_qg9rHbFXL40A,22
-habu_snowflake_cli-4.4.1.dist-info/RECORD,,
+habu_snowflake_cli-4.5.0.dist-info/METADATA,sha256=gRRvCM1Ruh3R4QinJD9-VZrn4ZTAoAbDeWsVyd4pxgc,1380
+habu_snowflake_cli-4.5.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+habu_snowflake_cli-4.5.0.dist-info/entry_points.txt,sha256=9mLwEgYq-eMv3F-c_p2EuoHFvOcQV8H-ozKR7BIF3Og,42
+habu_snowflake_cli-4.5.0.dist-info/top_level.txt,sha256=n-bjqTpxh0D3sxTdlhDISfzTBZQR-i_qg9rHbFXL40A,22
+habu_snowflake_cli-4.5.0.dist-info/RECORD,,
```

