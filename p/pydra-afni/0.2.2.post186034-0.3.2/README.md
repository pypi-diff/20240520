# Comparing `tmp/pydra_afni-0.2.2.post186034.tar.gz` & `tmp/pydra_afni-0.3.2.tar.gz`

## Comparing `pydra_afni-0.2.2.post186034.tar` & `pydra_afni-0.3.2.tar`

### file list

```diff
@@ -1,359 +1,504 @@
--rw-r--r--   0        0        0       45 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/.coveragerc
--rw-r--r--   0        0        0      270 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/.flake8
--rw-r--r--   0        0        0       42 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/.gitattributes
--rw-r--r--   0        0        0      402 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/.pre-commit-config.yaml
--rw-r--r--   0        0        0       59 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/MANIFEST.in
--rw-r--r--   0        0        0      252 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/codecov.yml
--rw-r--r--   0        0        0     1502 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/setup.cfg
--rwxr-xr-x   0        0        0      665 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/setup.py
--rw-r--r--   0        0        0    70238 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/versioneer.py
--rw-r--r--   0        0        0    13468 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/.github/workflows/ci-cd.yaml
--rw-r--r--   0        0        0      634 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/docs/Makefile
--rw-r--r--   0        0        0     1851 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/docs/conf.py
--rw-r--r--   0        0        0      228 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/docs/index.rst
--rw-r--r--   0        0        0      760 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/docs/make.bat
--rwxr-xr-x   0        0        0     2419 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/generate
--rw-r--r--   0        0        0      166 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/requirements.txt
--rw-r--r--   0        0        0     7319 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/a_boverlap.yaml
--rw-r--r--   0        0        0    10919 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/a_boverlap_callables.py
--rw-r--r--   0        0        0     7296 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/afn_ito_nifti.yaml
--rw-r--r--   0        0        0     7755 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/afn_ito_nifti_callables.py
--rw-r--r--   0        0        0    11919 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/align_epi_anat_py.yaml
--rw-r--r--   0        0        0    13323 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/align_epi_anat_py_callables.py
--rw-r--r--   0        0        0    22675 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/allineate.yaml
--rw-r--r--   0        0        0    15364 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/allineate_callables.py
--rw-r--r--   0        0        0     8038 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/auto_tcorrelate.yaml
--rw-r--r--   0        0        0     7485 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/auto_tcorrelate_callables.py
--rw-r--r--   0        0        0    14540 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/auto_tlrc.yaml
--rw-r--r--   0        0        0     8416 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/auto_tlrc_callables.py
--rw-r--r--   0        0        0     7016 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/autobox.yaml
--rw-r--r--   0        0        0    12093 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/autobox_callables.py
--rw-r--r--   0        0        0     7513 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/automask.yaml
--rw-r--r--   0        0        0    11124 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/automask_callables.py
--rw-r--r--   0        0        0     7160 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/axialize.yaml
--rw-r--r--   0        0        0    10918 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/axialize_callables.py
--rw-r--r--   0        0        0     9314 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/bandpass.yaml
--rw-r--r--   0        0        0    10918 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/bandpass_callables.py
--rw-r--r--   0        0        0     8140 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/blur_in_mask.yaml
--rw-r--r--   0        0        0    10920 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/blur_in_mask_callables.py
--rw-r--r--   0        0        0     7366 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/blur_to_fwhm.yaml
--rw-r--r--   0        0        0    10920 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/blur_to_fwhm_callables.py
--rw-r--r--   0        0        0     7230 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/brick_stat.yaml
--rw-r--r--   0        0        0     6064 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/brick_stat_callables.py
--rw-r--r--   0        0        0    12892 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/bucket.yaml
--rw-r--r--   0        0        0    10916 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/bucket_callables.py
--rw-r--r--   0        0        0    10702 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/calc.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/calc_callables.py
--rw-r--r--   0        0        0     8097 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/cat.yaml
--rw-r--r--   0        0        0    10913 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/cat_callables.py
--rw-r--r--   0        0        0     7406 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/cat_matvec.yaml
--rw-r--r--   0        0        0    10919 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/cat_matvec_callables.py
--rw-r--r--   0        0        0     8175 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/center_mass.yaml
--rw-r--r--   0        0        0     6972 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/center_mass_callables.py
--rw-r--r--   0        0        0     6357 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/clip_level.yaml
--rw-r--r--   0        0        0     6066 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/clip_level_callables.py
--rw-r--r--   0        0        0     7269 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/convert_dset.yaml
--rw-r--r--   0        0        0      747 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/convert_dset_callables.py
--rw-r--r--   0        0        0    12650 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/copy.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/copy_callables.py
--rw-r--r--   0        0        0    17086 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/deconvolve.yaml
--rw-r--r--   0        0        0     9842 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/deconvolve_callables.py
--rw-r--r--   0        0        0     8378 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/degree_centrality.yaml
--rw-r--r--   0        0        0    10940 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/degree_centrality_callables.py
--rw-r--r--   0        0        0     6247 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/despike.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/despike_callables.py
--rw-r--r--   0        0        0     6798 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/detrend.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/detrend_callables.py
--rw-r--r--   0        0        0     8895 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/dot.yaml
--rw-r--r--   0        0        0    10913 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/dot_callables.py
--rw-r--r--   0        0        0     8716 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/ecm.yaml
--rw-r--r--   0        0        0    10913 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/ecm_callables.py
--rw-r--r--   0        0        0     7851 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/edge_3.yaml
--rw-r--r--   0        0        0    10915 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/edge_3_callables.py
--rw-r--r--   0        0        0     8046 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/eval.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/eval_callables.py
--rw-r--r--   0        0        0     7881 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fim.yaml
--rw-r--r--   0        0        0    10913 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fim_callables.py
--rw-r--r--   0        0        0     7291 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fourier.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fourier_callables.py
--rw-r--r--   0        0        0    12833 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fwh_mx.yaml
--rw-r--r--   0        0        0     8141 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fwh_mx_callables.py
--rw-r--r--   0        0        0     6461 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/gcor.yaml
--rw-r--r--   0        0        0      662 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/gcor_callables.py
--rw-r--r--   0        0        0     7008 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/hist.yaml
--rw-r--r--   0        0        0     6666 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/hist_callables.py
--rw-r--r--   0        0        0     7593 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/lfcd.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/lfcd_callables.py
--rw-r--r--   0        0        0    12617 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/local_bistat.yaml
--rw-r--r--   0        0        0    10921 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/local_bistat_callables.py
--rw-r--r--   0        0        0    16912 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/localstat.yaml
--rw-r--r--   0        0        0    10919 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/localstat_callables.py
--rw-r--r--   0        0        0     7995 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/mask_tool.yaml
--rw-r--r--   0        0        0    10918 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/mask_tool_callables.py
--rw-r--r--   0        0        0     6992 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/maskave.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/maskave_callables.py
--rw-r--r--   0        0        0    10041 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/means.yaml
--rw-r--r--   0        0        0    10915 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/means_callables.py
--rw-r--r--   0        0        0     7024 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/merge.yaml
--rw-r--r--   0        0        0    10915 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/merge_callables.py
--rw-r--r--   0        0        0    15064 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/net_corr.yaml
--rw-r--r--   0        0        0     9141 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/net_corr_callables.py
--rw-r--r--   0        0        0     7090 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/notes.yaml
--rw-r--r--   0        0        0      735 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/notes_callables.py
--rw-r--r--   0        0        0     7751 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_adjust.yaml
--rw-r--r--   0        0        0     1172 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_adjust_callables.py
--rw-r--r--   0        0        0     8217 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_apply.yaml
--rw-r--r--   0        0        0     6067 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_apply_callables.py
--rw-r--r--   0        0        0     8864 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_cat.yaml
--rw-r--r--   0        0        0     8812 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_cat_callables.py
--rw-r--r--   0        0        0     8756 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/one_d_tool_py.yaml
--rw-r--r--   0        0        0     1121 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/one_d_tool_py_callables.py
--rw-r--r--   0        0        0     7250 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/outlier_count.yaml
--rw-r--r--   0        0        0     1060 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/outlier_count_callables.py
--rw-r--r--   0        0        0     7132 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/quality_index.yaml
--rw-r--r--   0        0        0     6069 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/quality_index_callables.py
--rw-r--r--   0        0        0    81676 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/qwarp.yaml
--rw-r--r--   0        0        0    11553 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/qwarp_callables.py
--rw-r--r--   0        0        0    29137 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/qwarp_plus_minus.yaml
--rw-r--r--   0        0        0    11562 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/qwarp_plus_minus_callables.py
--rw-r--r--   0        0        0     9322 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/re_ho.yaml
--rw-r--r--   0        0        0     6643 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/re_ho_callables.py
--rw-r--r--   0        0        0    11375 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/refit.yaml
--rw-r--r--   0        0        0      735 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/refit_callables.py
--rw-r--r--   0        0        0    25627 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/remlfit.yaml
--rw-r--r--   0        0        0     3241 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/remlfit_callables.py
--rw-r--r--   0        0        0     7360 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/resample.yaml
--rw-r--r--   0        0        0    10918 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/resample_callables.py
--rw-r--r--   0        0        0     9042 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/retroicor.yaml
--rw-r--r--   0        0        0    10919 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/retroicor_callables.py
--rw-r--r--   0        0        0    12465 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/roi_stats.yaml
--rw-r--r--   0        0        0     6065 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/roi_stats_callables.py
--rw-r--r--   0        0        0     7628 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/seg.yaml
--rw-r--r--   0        0        0     6060 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/seg_callables.py
--rw-r--r--   0        0        0     6620 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/skull_strip.yaml
--rw-r--r--   0        0        0    10920 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/skull_strip_callables.py
--rw-r--r--   0        0        0     5635 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/svm_test.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/svm_test_callables.py
--rw-r--r--   0        0        0     7052 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/svm_train.yaml
--rw-r--r--   0        0        0    11312 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/svm_train_callables.py
--rw-r--r--   0        0        0     9229 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/synthesize.yaml
--rw-r--r--   0        0        0      840 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/synthesize_callables.py
--rw-r--r--   0        0        0     7880 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_cat.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_cat_callables.py
--rw-r--r--   0        0        0     8461 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_cat_sub_brick.yaml
--rw-r--r--   0        0        0    14005 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_cat_sub_brick_callables.py
--rw-r--r--   0        0        0     7327 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_corr_1d.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_corr_1d_callables.py
--rw-r--r--   0        0        0    10379 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_corr_map.yaml
--rw-r--r--   0        0        0    13502 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_corr_map_callables.py
--rw-r--r--   0        0        0     7706 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_correlate.yaml
--rw-r--r--   0        0        0    10920 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_correlate_callables.py
--rw-r--r--   0        0        0     7526 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_norm.yaml
--rw-r--r--   0        0        0    10915 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_norm_callables.py
--rw-r--r--   0        0        0    14987 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_project.yaml
--rw-r--r--   0        0        0    10918 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_project_callables.py
--rw-r--r--   0        0        0    21767 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_shift.yaml
--rw-r--r--   0        0        0    11046 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_shift_callables.py
--rw-r--r--   0        0        0     7920 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_smooth.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_smooth_callables.py
--rw-r--r--   0        0        0     6869 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_stat.yaml
--rw-r--r--   0        0        0    10915 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_stat_callables.py
--rw-r--r--   0        0        0     8055 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/to_3d.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/to_3d_callables.py
--rw-r--r--   0        0        0     9387 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/undump.yaml
--rw-r--r--   0        0        0    10916 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/undump_callables.py
--rw-r--r--   0        0        0    10361 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/unifize.yaml
--rw-r--r--   0        0        0    11123 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/unifize_callables.py
--rw-r--r--   0        0        0    14134 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/volreg.yaml
--rw-r--r--   0        0        0    11542 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/volreg_callables.py
--rw-r--r--   0        0        0    10787 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/warp.yaml
--rw-r--r--   0        0        0    12277 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/warp_callables.py
--rw-r--r--   0        0        0     6832 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/z_cut_up.yaml
--rw-r--r--   0        0        0    10916 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/z_cut_up_callables.py
--rw-r--r--   0        0        0     7374 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/zcat.yaml
--rw-r--r--   0        0        0    10914 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/zcat_callables.py
--rw-r--r--   0        0        0     9936 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/zeropad.yaml
--rw-r--r--   0        0        0    10917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/zeropad_callables.py
--rw-r--r--   0        0        0     1191 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/__init__.py
--rw-r--r--   0        0        0      422 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/_version.py
--rw-r--r--   0        0        0       62 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/latest.py
--rw-r--r--   0        0        0     3830 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/__init__.py
--rw-r--r--   0        0        0      256 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/_version.py
--rw-r--r--   0        0        0     2450 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/a_boverlap.py
--rw-r--r--   0        0        0     2539 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/afn_ito_nifti.py
--rw-r--r--   0        0        0     4876 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/align_epi_anat_py.py
--rw-r--r--   0        0        0    14815 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/allineate.py
--rw-r--r--   0        0        0     2715 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/auto_tcorrelate.py
--rw-r--r--   0        0        0     4408 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/auto_tlrc.py
--rw-r--r--   0        0        0     3480 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/autobox.py
--rw-r--r--   0        0        0     2338 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/automask.py
--rw-r--r--   0        0        0     2565 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/axialize.py
--rw-r--r--   0        0        0     5070 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/bandpass.py
--rw-r--r--   0        0        0     3224 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/blur_in_mask.py
--rw-r--r--   0        0        0     2630 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/blur_to_fwhm.py
--rw-r--r--   0        0        0     2940 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/brick_stat.py
--rw-r--r--   0        0        0     3447 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/bucket.py
--rw-r--r--   0        0        0     3268 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/calc.py
--rw-r--r--   0        0        0     3780 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/cat.py
--rw-r--r--   0        0        0     2462 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/cat_matvec.py
--rw-r--r--   0        0        0     3018 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/center_mass.py
--rw-r--r--   0        0        0     2168 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/clip_level.py
--rw-r--r--   0        0        0     1987 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/convert_dset.py
--rw-r--r--   0        0        0     2132 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/copy.py
--rw-r--r--   0        0        0    12507 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/deconvolve.py
--rw-r--r--   0        0        0     3221 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/degree_centrality.py
--rw-r--r--   0        0        0     1470 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/despike.py
--rw-r--r--   0        0        0     1522 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/detrend.py
--rw-r--r--   0        0        0     4069 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/dot.py
--rw-r--r--   0        0        0     4288 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/ecm.py
--rw-r--r--   0        0        0     3266 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/edge_3.py
--rw-r--r--   0        0        0     2788 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/eval.py
--rw-r--r--   0        0        0     2402 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/fim.py
--rw-r--r--   0        0        0     2179 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/fourier.py
--rw-r--r--   0        0        0     5067 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/fwh_mx.py
--rw-r--r--   0        0        0     2089 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/gcor.py
--rw-r--r--   0        0        0     2404 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/hist.py
--rw-r--r--   0        0        0     2364 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/lfcd.py
--rw-r--r--   0        0        0     4827 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/local_bistat.py
--rw-r--r--   0        0        0     7517 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/localstat.py
--rw-r--r--   0        0        0     3784 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/mask_tool.py
--rw-r--r--   0        0        0     1964 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/maskave.py
--rw-r--r--   0        0        0     2949 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/means.py
--rw-r--r--   0        0        0     1867 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/merge.py
--rw-r--r--   0        0        0     7978 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/net_corr.py
--rw-r--r--   0        0        0     2329 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/notes.py
--rw-r--r--   0        0        0     2109 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/nwarp_adjust.py
--rw-r--r--   0        0        0     3037 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/nwarp_apply.py
--rw-r--r--   0        0        0     2449 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/nwarp_cat.py
--rw-r--r--   0        0        0     4116 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/one_d_tool_py.py
--rw-r--r--   0        0        0     3298 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/outlier_count.py
--rw-r--r--   0        0        0     2883 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/quality_index.py
--rw-r--r--   0        0        0    32710 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/qwarp.py
--rw-r--r--   0        0        0    26977 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/qwarp_plus_minus.py
--rw-r--r--   0        0        0     4347 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/re_ho.py
--rw-r--r--   0        0        0     5373 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/refit.py
--rw-r--r--   0        0        0    14039 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/remlfit.py
--rw-r--r--   0        0        0     2556 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/resample.py
--rw-r--r--   0        0        0     3289 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/retroicor.py
--rw-r--r--   0        0        0     5920 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/roi_stats.py
--rw-r--r--   0        0        0     3476 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/seg.py
--rw-r--r--   0        0        0     1530 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/skull_strip.py
--rw-r--r--   0        0        0     2760 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/svm_test.py
--rw-r--r--   0        0        0     3616 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/svm_train.py
--rw-r--r--   0        0        0     3233 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/synthesize.py
--rw-r--r--   0        0        0     2158 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_cat.py
--rw-r--r--   0        0        0     2218 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_cat_sub_brick.py
--rw-r--r--   0        0        0     2926 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_corr_1d.py
--rw-r--r--   0        0        0     5668 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_corr_map.py
--rw-r--r--   0        0        0     2298 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_correlate.py
--rw-r--r--   0        0        0     2760 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_norm.py
--rw-r--r--   0        0        0     7968 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_project.py
--rw-r--r--   0        0        0     5438 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_shift.py
--rw-r--r--   0        0        0     3472 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_smooth.py
--rw-r--r--   0        0        0     1802 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_stat.py
--rw-r--r--   0        0        0     2313 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/to_3d.py
--rw-r--r--   0        0        0     3970 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/undump.py
--rw-r--r--   0        0        0     4860 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/unifize.py
--rw-r--r--   0        0        0     4345 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/volreg.py
--rw-r--r--   0        0        0     4135 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/warp.py
--rw-r--r--   0        0        0     1693 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/z_cut_up.py
--rw-r--r--   0        0        0     2611 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/zcat.py
--rw-r--r--   0        0        0     5017 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/zeropad.py
--rw-r--r--   0        0        0      811 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/conftest.py
--rw-r--r--   0        0        0      902 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_aboverlap.py
--rw-r--r--   0        0        0      834 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_afnitonifti.py
--rw-r--r--   0        0        0     1199 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_alignepianatpy.py
--rw-r--r--   0        0        0     1853 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_allineate.py
--rw-r--r--   0        0        0      680 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_autobox.py
--rw-r--r--   0        0        0      722 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_automask.py
--rw-r--r--   0        0        0      969 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_autotcorrelate.py
--rw-r--r--   0        0        0      730 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_autotlrc.py
--rw-r--r--   0        0        0      701 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_axialize.py
--rw-r--r--   0        0        0      917 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_bandpass.py
--rw-r--r--   0        0        0      874 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_blurinmask.py
--rw-r--r--   0        0        0      828 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_blurtofwhm.py
--rw-r--r--   0        0        0      799 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_brickstat.py
--rw-r--r--   0        0        0      625 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_bucket.py
--rw-r--r--   0        0        0     1309 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_calc.py
--rw-r--r--   0        0        0      698 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_cat.py
--rw-r--r--   0        0        0      633 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_catmatvec.py
--rw-r--r--   0        0        0      794 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_centermass.py
--rw-r--r--   0        0        0      713 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_cliplevel.py
--rw-r--r--   0        0        0      814 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_convertdset.py
--rw-r--r--   0        0        0     1298 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_copy.py
--rw-r--r--   0        0        0     1153 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_deconvolve.py
--rw-r--r--   0        0        0      943 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_degreecentrality.py
--rw-r--r--   0        0        0      652 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_despike.py
--rw-r--r--   0        0        0      688 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_detrend.py
--rw-r--r--   0        0        0      832 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_dot.py
--rw-r--r--   0        0        0      818 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_ecm.py
--rw-r--r--   0        0        0      711 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_edge3.py
--rw-r--r--   0        0        0      956 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_eval.py
--rw-r--r--   0        0        0      887 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_fim.py
--rw-r--r--   0        0        0      746 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_fourier.py
--rw-r--r--   0        0        0      782 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_fwhmx.py
--rw-r--r--   0        0        0      709 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_gcor.py
--rw-r--r--   0        0        0      715 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_hist.py
--rw-r--r--   0        0        0      831 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_lfcd.py
--rw-r--r--   0        0        0     1074 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_localbistat.py
--rw-r--r--   0        0        0     1005 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_localstat.py
--rw-r--r--   0        0        0      771 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_maskave.py
--rw-r--r--   0        0        0      700 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_masktool.py
--rw-r--r--   0        0        0     1081 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_means.py
--rw-r--r--   0        0        0      740 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_merge.py
--rw-r--r--   0        0        0     1063 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_netcorr.py
--rw-r--r--   0        0        0      777 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_notes.py
--rw-r--r--   0        0        0      766 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_nwarpadjust.py
--rw-r--r--   0        0        0      753 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_nwarpapply.py
--rw-r--r--   0        0        0      675 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_nwarpcat.py
--rw-r--r--   0        0        0      873 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_onedtoolpy.py
--rw-r--r--   0        0        0     1015 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_outliercount.py
--rw-r--r--   0        0        0      896 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_qualityindex.py
--rw-r--r--   0        0        0     3385 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_qwarp.py
--rw-r--r--   0        0        0     1184 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_qwarpplusminus.py
--rw-r--r--   0        0        0     1037 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_refit.py
--rw-r--r--   0        0        0      819 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_reho.py
--rw-r--r--   0        0        0     1341 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_remlfit.py
--rw-r--r--   0        0        0      813 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_resample.py
--rw-r--r--   0        0        0     1049 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_retroicor.py
--rw-r--r--   0        0        0     1031 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_roistats.py
--rw-r--r--   0        0        0      663 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_seg.py
--rw-r--r--   0        0        0      671 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_skullstrip.py
--rw-r--r--   0        0        0      464 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_svmtest.py
--rw-r--r--   0        0        0      557 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_svmtrain.py
--rw-r--r--   0        0        0      841 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_synthesize.py
--rw-r--r--   0        0        0      716 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcat.py
--rw-r--r--   0        0        0      734 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcatsubbrick.py
--rw-r--r--   0        0        0      777 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcorr1d.py
--rw-r--r--   0        0        0      872 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcorrelate.py
--rw-r--r--   0        0        0      892 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcorrmap.py
--rw-r--r--   0        0        0      724 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tnorm.py
--rw-r--r--   0        0        0      731 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_to3d.py
--rw-r--r--   0        0        0     1067 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tproject.py
--rw-r--r--   0        0        0     2065 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tshift.py
--rw-r--r--   0        0        0      764 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tsmooth.py
--rw-r--r--   0        0        0      756 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tstat.py
--rw-r--r--   0        0        0      784 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_undump.py
--rw-r--r--   0        0        0      742 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_unifize.py
--rw-r--r--   0        0        0     1267 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_volreg.py
--rw-r--r--   0        0        0     1186 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_warp.py
--rw-r--r--   0        0        0      688 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_zcat.py
--rw-r--r--   0        0        0      729 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_zcutup.py
--rw-r--r--   0        0        0      923 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_zeropad.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pydra/tasks/afni/v24_0_12/__init__.py
--rw-r--r--   0        0        0      845 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/conftest.py
--rw-r--r--   0        0        0      588 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats/LICENSE
--rw-r--r--   0        0        0      875 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats/README.rst
--rw-r--r--   0        0        0     1982 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats/pyproject.toml
--rw-r--r--   0        0        0      445 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats/fileformats/medimage_afni/__init__.py
--rw-r--r--   0        0        0      588 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/LICENSE
--rw-r--r--   0        0        0     1102 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/README.rst
--rw-r--r--   0        0        0     2031 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/pyproject.toml
--rw-r--r--   0        0        0     1317 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/fileformats/extras/medimage_afni/__init__.py
--rw-r--r--   0        0        0     1010 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/fileformats/extras/medimage_afni/tests/test_generate_sample_data.py
--rw-r--r--   0        0        0      632 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/specs/afni_preprocess_param.yml
--rw-r--r--   0        0        0     2059 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/.gitignore
--rw-r--r--   0        0        0      588 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/LICENSE
--rw-r--r--   0        0        0     6400 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/README.rst
--rw-r--r--   0        0        0     2012 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/pyproject.toml
--rw-r--r--   0        0        0     8985 2020-02-02 00:00:00.000000 pydra_afni-0.2.2.post186034/PKG-INFO
+-rw-r--r--   0        0        0       45 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/.coveragerc
+-rw-r--r--   0        0        0      270 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/.flake8
+-rw-r--r--   0        0        0      402 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/.pre-commit-config.yaml
+-rw-r--r--   0        0        0      252 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/codecov.yml
+-rw-r--r--   0        0        0     3170 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/conftest.py
+-rw-r--r--   0        0        0     1210 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/.github/workflows/auto-release.yaml
+-rw-r--r--   0        0        0    14114 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/.github/workflows/ci-cd.yaml
+-rw-r--r--   0        0        0      634 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/docs/Makefile
+-rw-r--r--   0        0        0     1851 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/docs/conf.py
+-rw-r--r--   0        0        0      228 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/docs/index.rst
+-rw-r--r--   0        0        0      760 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/docs/make.bat
+-rwxr-xr-x   0        0        0       96 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/generate
+-rw-r--r--   0        0        0      166 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/requirements.txt
+-rw-r--r--   0        0        0      498 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/package.yaml
+-rw-r--r--   0        0        0      548 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/classes/nipype.interfaces.afni.base.Info.yaml
+-rw-r--r--   0        0        0      881 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/classes/nipype.interfaces.base.core.PackageInfo.yaml
+-rw-r--r--   0        0        0     7046 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/a_boverlap.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/a_boverlap_callables.py
+-rw-r--r--   0        0        0     5149 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/aboverlap.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/aboverlap_callables.py
+-rw-r--r--   0        0        0     7212 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/afn_ito_nifti.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/afn_ito_nifti_callables.py
+-rw-r--r--   0        0        0     5254 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/afnitonifti.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/afnitonifti_callables.py
+-rw-r--r--   0        0        0    11605 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/align_epi_anat_py.yaml
+-rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/align_epi_anat_py_callables.py
+-rw-r--r--   0        0        0     8660 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/alignepianatpy.yaml
+-rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/alignepianatpy_callables.py
+-rw-r--r--   0        0        0    22417 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/allineate.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/allineate_callables.py
+-rw-r--r--   0        0        0     7863 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/auto_tcorrelate.yaml
+-rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/auto_tcorrelate_callables.py
+-rw-r--r--   0        0        0    14357 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/auto_tlrc.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/auto_tlrc_callables.py
+-rw-r--r--   0        0        0     6583 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/autobox.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/autobox_callables.py
+-rw-r--r--   0        0        0     7346 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/automask.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/automask_callables.py
+-rw-r--r--   0        0        0     5575 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/autotcorrelate.yaml
+-rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/autotcorrelate_callables.py
+-rw-r--r--   0        0        0     7435 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/autotlrc.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/autotlrc_callables.py
+-rw-r--r--   0        0        0     6952 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/axialize.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/axialize_callables.py
+-rw-r--r--   0        0        0     9139 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/bandpass.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/bandpass_callables.py
+-rw-r--r--   0        0        0     7965 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blur_in_mask.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blur_in_mask_callables.py
+-rw-r--r--   0        0        0     7191 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blur_to_fwhm.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blur_to_fwhm_callables.py
+-rw-r--r--   0        0        0     5562 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blurinmask.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blurinmask_callables.py
+-rw-r--r--   0        0        0     5186 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blurtofwhm.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blurtofwhm_callables.py
+-rw-r--r--   0        0        0     6992 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/brick_stat.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/brick_stat_callables.py
+-rw-r--r--   0        0        0     5195 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/brickstat.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/brickstat_callables.py
+-rw-r--r--   0        0        0    12693 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/bucket.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/bucket_callables.py
+-rw-r--r--   0        0        0    10453 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/calc.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/calc_callables.py
+-rw-r--r--   0        0        0     7901 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cat.yaml
+-rw-r--r--   0        0        0       67 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cat_callables.py
+-rw-r--r--   0        0        0     7196 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cat_matvec.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cat_matvec_callables.py
+-rw-r--r--   0        0        0     5242 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/catmatvec.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/catmatvec_callables.py
+-rw-r--r--   0        0        0     7980 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/center_mass.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/center_mass_callables.py
+-rw-r--r--   0        0        0     5578 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/centermass.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/centermass_callables.py
+-rw-r--r--   0        0        0     6117 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/clip_level.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/clip_level_callables.py
+-rw-r--r--   0        0        0     4712 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cliplevel.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cliplevel_callables.py
+-rw-r--r--   0        0        0     7210 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/convert_dset.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/convert_dset_callables.py
+-rw-r--r--   0        0        0     4928 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/convertdset.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/convertdset_callables.py
+-rw-r--r--   0        0        0    12414 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/copy.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/copy_callables.py
+-rw-r--r--   0        0        0    16871 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/deconvolve.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/deconvolve_callables.py
+-rw-r--r--   0        0        0     8182 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/degree_centrality.yaml
+-rw-r--r--   0        0        0       80 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/degree_centrality_callables.py
+-rw-r--r--   0        0        0     5739 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/degreecentrality.yaml
+-rw-r--r--   0        0        0       80 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/degreecentrality_callables.py
+-rw-r--r--   0        0        0     6072 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/despike.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/despike_callables.py
+-rw-r--r--   0        0        0     6623 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/detrend.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/detrend_callables.py
+-rw-r--r--   0        0        0     8671 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/dot.yaml
+-rw-r--r--   0        0        0       67 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/dot_callables.py
+-rw-r--r--   0        0        0     8520 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/ecm.yaml
+-rw-r--r--   0        0        0       67 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/ecm_callables.py
+-rw-r--r--   0        0        0     5537 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/edge3.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/edge3_callables.py
+-rw-r--r--   0        0        0     7651 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/edge_3.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/edge_3_callables.py
+-rw-r--r--   0        0        0     7842 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/eval.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/eval_callables.py
+-rw-r--r--   0        0        0     7661 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fim.yaml
+-rw-r--r--   0        0        0       67 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fim_callables.py
+-rw-r--r--   0        0        0     7116 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fourier.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fourier_callables.py
+-rw-r--r--   0        0        0    12515 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fwh_mx.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fwh_mx_callables.py
+-rw-r--r--   0        0        0    10454 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fwhmx.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fwhmx_callables.py
+-rw-r--r--   0        0        0     6213 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/gcor.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/gcor_callables.py
+-rw-r--r--   0        0        0     6841 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/hist.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/hist_callables.py
+-rw-r--r--   0        0        0     7397 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/lfcd.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/lfcd_callables.py
+-rw-r--r--   0        0        0    13620 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/local_bistat.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/local_bistat_callables.py
+-rw-r--r--   0        0        0     7142 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/localbistat.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/localbistat_callables.py
+-rw-r--r--   0        0        0    18613 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/localstat.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/localstat_callables.py
+-rw-r--r--   0        0        0     7820 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/mask_tool.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/mask_tool_callables.py
+-rw-r--r--   0        0        0     6817 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/maskave.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/maskave_callables.py
+-rw-r--r--   0        0        0     5877 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/masktool.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/masktool_callables.py
+-rw-r--r--   0        0        0     9795 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/means.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/means_callables.py
+-rw-r--r--   0        0        0     6830 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/merge.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/merge_callables.py
+-rw-r--r--   0        0        0    14751 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/net_corr.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/net_corr_callables.py
+-rw-r--r--   0        0        0     9580 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/netcorr.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/netcorr_callables.py
+-rw-r--r--   0        0        0     6915 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/notes.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/notes_callables.py
+-rw-r--r--   0        0        0     7576 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_adjust.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_adjust_callables.py
+-rw-r--r--   0        0        0     8042 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_apply.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_apply_callables.py
+-rw-r--r--   0        0        0     8649 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_cat.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_cat_callables.py
+-rw-r--r--   0        0        0     5621 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarpadjust.yaml
+-rw-r--r--   0        0        0       75 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarpadjust_callables.py
+-rw-r--r--   0        0        0     5641 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarpapply.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarpapply_callables.py
+-rw-r--r--   0        0        0     6855 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarpcat.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarpcat_callables.py
+-rw-r--r--   0        0        0     8548 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/one_d_tool_py.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/one_d_tool_py_callables.py
+-rw-r--r--   0        0        0     5809 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/onedtoolpy.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/onedtoolpy_callables.py
+-rw-r--r--   0        0        0     7075 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/outlier_count.yaml
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/outlier_count_callables.py
+-rw-r--r--   0        0        0     5300 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/outliercount.yaml
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/outliercount_callables.py
+-rw-r--r--   0        0        0     6957 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/quality_index.yaml
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/quality_index_callables.py
+-rw-r--r--   0        0        0     5254 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qualityindex.yaml
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qualityindex_callables.py
+-rw-r--r--   0        0        0    81384 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarp.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarp_callables.py
+-rw-r--r--   0        0        0    28970 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarp_plus_minus.yaml
+-rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarp_plus_minus_callables.py
+-rw-r--r--   0        0        0    23669 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarpplusminus.yaml
+-rw-r--r--   0        0        0       78 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarpplusminus_callables.py
+-rw-r--r--   0        0        0     9120 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/re_ho.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/re_ho_callables.py
+-rw-r--r--   0        0        0    11182 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/refit.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/refit_callables.py
+-rw-r--r--   0        0        0     6485 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/reho.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/reho_callables.py
+-rw-r--r--   0        0        0    25521 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/remlfit.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/remlfit_callables.py
+-rw-r--r--   0        0        0     7185 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/resample.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/resample_callables.py
+-rw-r--r--   0        0        0     8867 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/retroicor.yaml
+-rw-r--r--   0        0        0       73 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/retroicor_callables.py
+-rw-r--r--   0        0        0    13412 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/roi_stats.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/roi_stats_callables.py
+-rw-r--r--   0        0        0     7628 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/roistats.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/roistats_callables.py
+-rw-r--r--   0        0        0     7445 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/seg.yaml
+-rw-r--r--   0        0        0       67 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/seg_callables.py
+-rw-r--r--   0        0        0     6445 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/skull_strip.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/skull_strip_callables.py
+-rw-r--r--   0        0        0     4808 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/skullstrip.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/skullstrip_callables.py
+-rw-r--r--   0        0        0     5470 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svm_test.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svm_test_callables.py
+-rw-r--r--   0        0        0     6903 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svm_train.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svm_train_callables.py
+-rw-r--r--   0        0        0     3727 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svmtest.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svmtest_callables.py
+-rw-r--r--   0        0        0     4294 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svmtrain.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svmtrain_callables.py
+-rw-r--r--   0        0        0     9054 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/synthesize.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/synthesize_callables.py
+-rw-r--r--   0        0        0     7660 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_cat.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_cat_callables.py
+-rw-r--r--   0        0        0     8170 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_cat_sub_brick.yaml
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_cat_sub_brick_callables.py
+-rw-r--r--   0        0        0     7152 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_corr_1d.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_corr_1d_callables.py
+-rw-r--r--   0        0        0    10308 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_corr_map.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_corr_map_callables.py
+-rw-r--r--   0        0        0     7470 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_correlate.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_correlate_callables.py
+-rw-r--r--   0        0        0     7487 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_norm.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_norm_callables.py
+-rw-r--r--   0        0        0    14775 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_project.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_project_callables.py
+-rw-r--r--   0        0        0    21552 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_shift.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_shift_callables.py
+-rw-r--r--   0        0        0     7745 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_smooth.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_smooth_callables.py
+-rw-r--r--   0        0        0     6674 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_stat.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_stat_callables.py
+-rw-r--r--   0        0        0     5275 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcat.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcat_callables.py
+-rw-r--r--   0        0        0     5543 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcatsubbrick.yaml
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcatsubbrick_callables.py
+-rw-r--r--   0        0        0     5121 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcorr1d.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcorr1d_callables.py
+-rw-r--r--   0        0        0     5317 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcorrelate.yaml
+-rw-r--r--   0        0        0       74 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcorrelate_callables.py
+-rw-r--r--   0        0        0     6801 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcorrmap.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tcorrmap_callables.py
+-rw-r--r--   0        0        0     5343 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tnorm.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tnorm_callables.py
+-rw-r--r--   0        0        0     5092 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/to3d.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/to3d_callables.py
+-rw-r--r--   0        0        0     7738 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/to_3d.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/to_3d_callables.py
+-rw-r--r--   0        0        0     9815 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tproject.yaml
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tproject_callables.py
+-rw-r--r--   0        0        0    16468 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tshift.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tshift_callables.py
+-rw-r--r--   0        0        0     5740 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tsmooth.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tsmooth_callables.py
+-rw-r--r--   0        0        0     4780 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tstat.yaml
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/tstat_callables.py
+-rw-r--r--   0        0        0     9159 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/undump.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/undump_callables.py
+-rw-r--r--   0        0        0    10141 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/unifize.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/unifize_callables.py
+-rw-r--r--   0        0        0    13865 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/volreg.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/volreg_callables.py
+-rw-r--r--   0        0        0    10539 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/warp.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/warp_callables.py
+-rw-r--r--   0        0        0     6608 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/z_cut_up.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/z_cut_up_callables.py
+-rw-r--r--   0        0        0     7156 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zcat.yaml
+-rw-r--r--   0        0        0       68 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zcat_callables.py
+-rw-r--r--   0        0        0     4801 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zcutup.yaml
+-rw-r--r--   0        0        0       70 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zcutup_callables.py
+-rw-r--r--   0        0        0     9718 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zeropad.yaml
+-rw-r--r--   0        0        0       71 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zeropad_callables.py
+-rw-r--r--   0        0        0     1199 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/__init__.py
+-rw-r--r--   0        0        0      411 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/_version.py
+-rw-r--r--   0        0        0       56 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/latest.py
+-rw-r--r--   0        0        0     1893 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/__init__.py
+-rw-r--r--   0        0        0      241 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/_post_release.py
+-rw-r--r--   0        0        0     2449 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/base.py
+-rw-r--r--   0        0        0       99 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/__init__.py
+-rw-r--r--   0        0        0    12506 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/deconvolve.py
+-rw-r--r--   0        0        0    14552 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/remlfit.py
+-rw-r--r--   0        0        0     3264 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/synthesize.py
+-rw-r--r--   0        0        0      811 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/conftest.py
+-rw-r--r--   0        0        0     1319 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/test_deconvolve.py
+-rw-r--r--   0        0        0     2021 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/test_remlfit.py
+-rw-r--r--   0        0        0      895 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/test_synthesize.py
+-rw-r--r--   0        0        0       36 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/nipype_ports/__init__.py
+-rw-r--r--   0        0        0       30 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/nipype_ports/interfaces/__init__.py
+-rw-r--r--   0        0        0       30 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/nipype_ports/interfaces/base/__init__.py
+-rw-r--r--   0        0        0      992 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/nipype_ports/interfaces/base/core.py
+-rw-r--r--   0        0        0     1540 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/__init__.py
+-rw-r--r--   0        0        0     9629 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/align_epi_anat_py.py
+-rw-r--r--   0        0        0    15442 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/allineate.py
+-rw-r--r--   0        0        0     4469 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/auto_t_l_r_c.py
+-rw-r--r--   0        0        0     5276 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/auto_tcorrelate.py
+-rw-r--r--   0        0        0     4438 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/auto_tlrc.py
+-rw-r--r--   0        0        0     2368 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/automask.py
+-rw-r--r--   0        0        0     5100 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/bandpass.py
+-rw-r--r--   0        0        0     6309 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/blur_in_mask.py
+-rw-r--r--   0        0        0     2700 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/blur_to_f_w_h_m.py
+-rw-r--r--   0        0        0     2662 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/blur_to_fwhm.py
+-rw-r--r--   0        0        0     3747 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/clip_level.py
+-rw-r--r--   0        0        0     6287 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/degree_centrality.py
+-rw-r--r--   0        0        0     1504 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/despike.py
+-rw-r--r--   0        0        0     1554 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/detrend.py
+-rw-r--r--   0        0        0     4307 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/ecm.py
+-rw-r--r--   0        0        0     2407 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/fim.py
+-rw-r--r--   0        0        0     2207 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/fourier.py
+-rw-r--r--   0        0        0     2438 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/hist.py
+-rw-r--r--   0        0        0     2383 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/lfcd.py
+-rw-r--r--   0        0        0     2000 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/maskave.py
+-rw-r--r--   0        0        0     2970 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/means.py
+-rw-r--r--   0        0        0    16114 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/net_corr.py
+-rw-r--r--   0        0        0     6350 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/outlier_count.py
+-rw-r--r--   0        0        0     5636 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/quality_index.py
+-rw-r--r--   0        0        0    33156 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/qwarp.py
+-rw-r--r--   0        0        0    53975 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/qwarp_plus_minus.py
+-rw-r--r--   0        0        0     5791 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/r_o_i_stats.py
+-rw-r--r--   0        0        0     3329 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/retroicor.py
+-rw-r--r--   0        0        0     5768 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/roi_stats.py
+-rw-r--r--   0        0        0     3508 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/seg.py
+-rw-r--r--   0        0        0     2947 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/skull_strip.py
+-rw-r--r--   0        0        0     2967 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_corr_1_d.py
+-rw-r--r--   0        0        0     2964 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_corr_1d.py
+-rw-r--r--   0        0        0    12479 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_corr_map.py
+-rw-r--r--   0        0        0     4463 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_correlate.py
+-rw-r--r--   0        0        0     5355 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_norm.py
+-rw-r--r--   0        0        0    15778 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_project.py
+-rw-r--r--   0        0        0    10702 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_shift.py
+-rw-r--r--   0        0        0     6790 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_smooth.py
+-rw-r--r--   0        0        0     4596 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/volreg.py
+-rw-r--r--   0        0        0     4169 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/warp.py
+-rw-r--r--   0        0        0      811 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/conftest.py
+-rw-r--r--   0        0        0      708 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_align_epi_anat_py.py
+-rw-r--r--   0        0        0     1114 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_alignepianatpy.py
+-rw-r--r--   0        0        0     2164 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_allineate.py
+-rw-r--r--   0        0        0      538 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_auto_t_l_r_c.py
+-rw-r--r--   0        0        0      626 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_auto_tcorrelate.py
+-rw-r--r--   0        0        0      781 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_automask.py
+-rw-r--r--   0        0        0     1028 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_autotcorrelate.py
+-rw-r--r--   0        0        0      752 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_autotlrc.py
+-rw-r--r--   0        0        0      976 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_bandpass.py
+-rw-r--r--   0        0        0      544 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_blur_in_mask.py
+-rw-r--r--   0        0        0      511 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_blur_to_f_w_h_m.py
+-rw-r--r--   0        0        0      933 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_blurinmask.py
+-rw-r--r--   0        0        0      887 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_blurtofwhm.py
+-rw-r--r--   0        0        0      464 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_clip_level.py
+-rw-r--r--   0        0        0      772 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_cliplevel.py
+-rw-r--r--   0        0        0      659 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_degree_centrality.py
+-rw-r--r--   0        0        0     1028 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_degreecentrality.py
+-rw-r--r--   0        0        0      711 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_despike.py
+-rw-r--r--   0        0        0      747 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_detrend.py
+-rw-r--r--   0        0        0      940 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_ecm.py
+-rw-r--r--   0        0        0      995 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_fim.py
+-rw-r--r--   0        0        0      805 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_fourier.py
+-rw-r--r--   0        0        0      774 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_hist.py
+-rw-r--r--   0        0        0      951 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_lfcd.py
+-rw-r--r--   0        0        0      830 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_maskave.py
+-rw-r--r--   0        0        0     1207 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_means.py
+-rw-r--r--   0        0        0      644 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_net_corr.py
+-rw-r--r--   0        0        0     1220 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_netcorr.py
+-rw-r--r--   0        0        0      476 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_outlier_count.py
+-rw-r--r--   0        0        0     1022 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_outliercount.py
+-rw-r--r--   0        0        0      476 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_quality_index.py
+-rw-r--r--   0        0        0      955 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qualityindex.py
+-rw-r--r--   0        0        0     3551 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qwarp.py
+-rw-r--r--   0        0        0      574 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qwarp_plus_minus.py
+-rw-r--r--   0        0        0     1303 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qwarpplusminus.py
+-rw-r--r--   0        0        0      644 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_r_o_i_stats.py
+-rw-r--r--   0        0        0     1108 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_retroicor.py
+-rw-r--r--   0        0        0     1047 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_roistats.py
+-rw-r--r--   0        0        0      685 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_seg.py
+-rw-r--r--   0        0        0      468 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_skull_strip.py
+-rw-r--r--   0        0        0      730 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_skullstrip.py
+-rw-r--r--   0        0        0      538 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_corr1_d.py
+-rw-r--r--   0        0        0      509 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_corr_map.py
+-rw-r--r--   0        0        0      628 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_correlate.py
+-rw-r--r--   0        0        0      477 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_norm.py
+-rw-r--r--   0        0        0      622 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_project.py
+-rw-r--r--   0        0        0     1794 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_shift.py
+-rw-r--r--   0        0        0      485 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_smooth.py
+-rw-r--r--   0        0        0      836 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tcorr1d.py
+-rw-r--r--   0        0        0      982 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tcorrelate.py
+-rw-r--r--   0        0        0     1654 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tcorrmap.py
+-rw-r--r--   0        0        0      729 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tnorm.py
+-rw-r--r--   0        0        0     1189 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tproject.py
+-rw-r--r--   0        0        0     2087 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tshift.py
+-rw-r--r--   0        0        0      823 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tsmooth.py
+-rw-r--r--   0        0        0     1524 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_volreg.py
+-rw-r--r--   0        0        0     1320 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_warp.py
+-rw-r--r--   0        0        0      134 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/__init__.py
+-rw-r--r--   0        0        0     2815 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/s_v_m_test.py
+-rw-r--r--   0        0        0     3671 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/s_v_m_train.py
+-rw-r--r--   0        0        0     2795 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/svm_test.py
+-rw-r--r--   0        0        0     3651 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/svm_train.py
+-rw-r--r--   0        0        0      811 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/tests/conftest.py
+-rw-r--r--   0        0        0       54 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/tests/test_s_v_m_test.py
+-rw-r--r--   0        0        0       54 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/tests/test_s_v_m_train.py
+-rw-r--r--   0        0        0      522 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/tests/test_svmtest.py
+-rw-r--r--   0        0        0      615 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/tests/test_svmtrain.py
+-rw-r--r--   0        0        0     1425 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/__init__.py
+-rw-r--r--   0        0        0     4712 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/a_boverlap.py
+-rw-r--r--   0        0        0     2684 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/a_f_n_ito_n_i_f_t_i.py
+-rw-r--r--   0        0        0     2642 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/afn_ito_nifti.py
+-rw-r--r--   0        0        0     2162 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/autobox.py
+-rw-r--r--   0        0        0     2571 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/axialize.py
+-rw-r--r--   0        0        0     5131 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/brick_stat.py
+-rw-r--r--   0        0        0     3475 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/bucket.py
+-rw-r--r--   0        0        0     3369 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/calc.py
+-rw-r--r--   0        0        0     3792 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/cat.py
+-rw-r--r--   0        0        0     4926 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/cat_matvec.py
+-rw-r--r--   0        0        0     6003 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/center_mass.py
+-rw-r--r--   0        0        0     3722 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/convert_dset.py
+-rw-r--r--   0        0        0     2244 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/copy.py
+-rw-r--r--   0        0        0     4063 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/dot.py
+-rw-r--r--   0        0        0     6385 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/edge_3.py
+-rw-r--r--   0        0        0     2802 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/eval.py
+-rw-r--r--   0        0        0     4560 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/f_w_h_mx.py
+-rw-r--r--   0        0        0     4537 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/fwh_mx.py
+-rw-r--r--   0        0        0     1858 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/gcor.py
+-rw-r--r--   0        0        0     9284 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/local_bistat.py
+-rw-r--r--   0        0        0     7440 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/localstat.py
+-rw-r--r--   0        0        0     7433 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/mask_tool.py
+-rw-r--r--   0        0        0     1872 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/merge.py
+-rw-r--r--   0        0        0     2384 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/notes.py
+-rw-r--r--   0        0        0     4049 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/nwarp_adjust.py
+-rw-r--r--   0        0        0     5970 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/nwarp_apply.py
+-rw-r--r--   0        0        0     4797 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/nwarp_cat.py
+-rw-r--r--   0        0        0     8015 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/one_d_tool_py.py
+-rw-r--r--   0        0        0     8544 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/re_ho.py
+-rw-r--r--   0        0        0     5402 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/refit.py
+-rw-r--r--   0        0        0     2581 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/resample.py
+-rw-r--r--   0        0        0     4148 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/t_cat.py
+-rw-r--r--   0        0        0     4371 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/t_cat_sub_brick.py
+-rw-r--r--   0        0        0     3434 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/t_stat.py
+-rw-r--r--   0        0        0     2323 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/to_3_d.py
+-rw-r--r--   0        0        0     2315 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/to_3d.py
+-rw-r--r--   0        0        0     3966 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/undump.py
+-rw-r--r--   0        0        0     4901 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/unifize.py
+-rw-r--r--   0        0        0     3229 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/z_cut_up.py
+-rw-r--r--   0        0        0     2608 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/zcat.py
+-rw-r--r--   0        0        0     5006 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/zeropad.py
+-rw-r--r--   0        0        0      811 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/conftest.py
+-rw-r--r--   0        0        0      600 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_a_boverlap.py
+-rw-r--r--   0        0        0      579 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_a_f_n_ito_n_i_f_t_i.py
+-rw-r--r--   0        0        0      963 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_aboverlap.py
+-rw-r--r--   0        0        0      875 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_afnitonifti.py
+-rw-r--r--   0        0        0      734 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_autobox.py
+-rw-r--r--   0        0        0      810 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_axialize.py
+-rw-r--r--   0        0        0      541 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_brick_stat.py
+-rw-r--r--   0        0        0      815 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_brickstat.py
+-rw-r--r--   0        0        0      648 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_bucket.py
+-rw-r--r--   0        0        0     1454 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_calc.py
+-rw-r--r--   0        0        0      813 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_cat.py
+-rw-r--r--   0        0        0      435 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_cat_matvec.py
+-rw-r--r--   0        0        0      784 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_catmatvec.py
+-rw-r--r--   0        0        0      586 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_center_mass.py
+-rw-r--r--   0        0        0      951 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_centermass.py
+-rw-r--r--   0        0        0      547 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_convert_dset.py
+-rw-r--r--   0        0        0      903 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_convertdset.py
+-rw-r--r--   0        0        0     1382 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_copy.py
+-rw-r--r--   0        0        0      935 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_dot.py
+-rw-r--r--   0        0        0     1134 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_edge3.py
+-rw-r--r--   0        0        0     1068 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_eval.py
+-rw-r--r--   0        0        0      451 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_f_w_h_mx.py
+-rw-r--r--   0        0        0      836 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_fwhmx.py
+-rw-r--r--   0        0        0      763 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_gcor.py
+-rw-r--r--   0        0        0      683 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_local_bistat.py
+-rw-r--r--   0        0        0     1140 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_localbistat.py
+-rw-r--r--   0        0        0     1073 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_localstat.py
+-rw-r--r--   0        0        0      494 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_mask_tool.py
+-rw-r--r--   0        0        0      754 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_masktool.py
+-rw-r--r--   0        0        0      856 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_merge.py
+-rw-r--r--   0        0        0      884 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_notes.py
+-rw-r--r--   0        0        0      469 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarp_adjust.py
+-rw-r--r--   0        0        0      552 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarp_apply.py
+-rw-r--r--   0        0        0      446 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarp_cat.py
+-rw-r--r--   0        0        0      820 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarpadjust.py
+-rw-r--r--   0        0        0      813 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarpapply.py
+-rw-r--r--   0        0        0      690 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarpcat.py
+-rw-r--r--   0        0        0      573 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_one_d_tool_py.py
+-rw-r--r--   0        0        0      982 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_onedtoolpy.py
+-rw-r--r--   0        0        0      540 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_re_ho.py
+-rw-r--r--   0        0        0     1091 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_refit.py
+-rw-r--r--   0        0        0      941 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_reho.py
+-rw-r--r--   0        0        0      867 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_resample.py
+-rw-r--r--   0        0        0      517 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_t_cat.py
+-rw-r--r--   0        0        0      582 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_t_cat_sub_brick.py
+-rw-r--r--   0        0        0      443 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_t_stat.py
+-rw-r--r--   0        0        0      819 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_tcat.py
+-rw-r--r--   0        0        0      794 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_tcatsubbrick.py
+-rw-r--r--   0        0        0      542 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_to3_d.py
+-rw-r--r--   0        0        0      792 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_to3d.py
+-rw-r--r--   0        0        0      775 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_tstat.py
+-rw-r--r--   0        0        0      883 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_undump.py
+-rw-r--r--   0        0        0      890 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_unifize.py
+-rw-r--r--   0        0        0      530 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_z_cut_up.py
+-rw-r--r--   0        0        0      792 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_zcat.py
+-rw-r--r--   0        0        0      830 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_zcutup.py
+-rw-r--r--   0        0        0     1027 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_zeropad.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pydra/tasks/afni/v24_1/__init__.py
+-rw-r--r--   0        0        0      845 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/conftest.py
+-rw-r--r--   0        0        0      588 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats/LICENSE
+-rw-r--r--   0        0        0     1455 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats/README.rst
+-rw-r--r--   0        0        0     1996 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats/pyproject.toml
+-rw-r--r--   0        0        0      527 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats/fileformats/medimage_afni/__init__.py
+-rw-r--r--   0        0        0      588 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats-extras/LICENSE
+-rw-r--r--   0        0        0     1097 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats-extras/README.rst
+-rw-r--r--   0        0        0     2037 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats-extras/pyproject.toml
+-rw-r--r--   0        0        0     1423 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats-extras/fileformats/extras/medimage_afni/__init__.py
+-rw-r--r--   0        0        0     1126 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/related-packages/fileformats-extras/fileformats/extras/medimage_afni/tests/test_generate_sample_data.py
+-rw-r--r--   0        0        0     1924 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/.gitignore
+-rw-r--r--   0        0        0      588 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/LICENSE
+-rw-r--r--   0        0        0     6093 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/README.rst
+-rw-r--r--   0        0        0     2032 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/pyproject.toml
+-rw-r--r--   0        0        0     8695 2020-02-02 00:00:00.000000 pydra_afni-0.3.2/PKG-INFO
```

### Comparing `pydra_afni-0.2.2.post186034/.github/workflows/ci-cd.yaml` & `pydra_afni-0.3.2/.github/workflows/ci-cd.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -12,276 +12,249 @@
   pull_request:
     branches: [ main, develop ]
   release:
     types: [published]
   repository_dispatch:
     types: [create-post-release]
 
+permissions:
+  contents: read
+  pages: write
+  id-token: write
+
 jobs:
 
   nipype-conv:
     runs-on: ubuntu-latest
     steps:
 
     - name: Checkout
       uses: actions/checkout@v4
 
     - name: Revert version to most recent version tag on upstream update
       if: github.event_name == 'repository_dispatch'
       run: git checkout $(git tag -l | grep 'v.*' | tail -n 1 | awk -F post '{print $1}')
- 
+
     - name: Set up Python
       uses: actions/setup-python@v5
+      with:
+        python-version: '3.11'
 
     - name: Install build dependencies
       run: python -m pip install --upgrade pip
 
     - name: Install requirements
-      run: python -m pip install ./related-packages/fileformats -r ./nipype-auto-conv/requirements.txt
+      run: python -m pip install -r ./nipype-auto-conv/requirements.txt ./related-packages/fileformats
 
     - name: Run automatic Nipype > Pydra conversion
       run: ./nipype-auto-conv/generate
 
-    - uses: actions/upload-artifact@v3
+    - uses: actions/upload-artifact@v4
       with:
         name: converted-nipype
         path: pydra/tasks/afni/auto
 
   devcheck:
     needs: [nipype-conv]
     runs-on: ubuntu-latest
     strategy:
       matrix:
-        python-version: ['3.8', '3.11']  # Check oldest and newest versions
+        python-version: ['3.8', '3.12']  # Check oldest and newest versions
         pip-flags: ['', '--editable']
         pydra:
         - 'pydra'
         - '--editable git+https://github.com/nipype/pydra.git#egg=pydra'
     steps:
     - name: Checkout
       uses: actions/checkout@v4
 
-    - name: Revert version to most recent version tag on upstream update
+    - name: Revert version to most recent version tag on Nipype or Nipype2Pydra update
       if: github.event_name == 'repository_dispatch'
       run: git checkout $(git tag -l | grep 'v.*' | tail -n 1 | awk -F post '{print $1}')
 
-    - name: Download tasks converted from Nipype 
-      uses: actions/download-artifact@v3
+    - name: Download tasks converted from Nipype
+      uses: actions/download-artifact@v4
       with:
         name: converted-nipype
         path: pydra/tasks/afni/auto
 
     - name: Strip auto package from gitignore so it is included in package
       run: |
         sed -i '/\/pydra\/tasks\/afni\/auto/d' .gitignore
-        sed -i '/^_version.py/d' .gitignore
+        sed -i '/^_version.py/d' .gitignore         
 
     - name: Set up Python ${{ matrix.python-version }}
       uses: actions/setup-python@v5
       with:
         python-version: ${{ matrix.python-version }}
 
     - name: Install build dependencies
       run: |
         python -m pip install --upgrade pip
- 
+
     - name: Install Pydra
       run: |
         pushd $HOME
         pip install ${{ matrix.pydra }}
         popd
         python -c "import pydra as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
 
     - name: Install task package
       run: |
         pip install "./related-packages/fileformats[dev]" "related-packages/fileformats-extras[dev]"
         pip install ${{ matrix.pip-flags }} ".[dev]"
         python -c "import pydra.tasks.afni as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
+        python -c "import pydra.tasks.afni.auto as m; print(f'{m.__name__} @ {m.__file__}')"
         python -c "import pydra as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
         python -c "import fileformats.medimage_afni as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
         python -c "import fileformats.extras.medimage_afni as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
   
   fileformats-test:
     runs-on: ubuntu-latest
     strategy:
       matrix:
-        python-version: ['3.8', '3.11']
+        python-version: ['3.8', '3.12']
     steps:
-
-    - uses: actions/checkout@v4
-
-    - name: Revert version to most recent version tag on upstream update
+    - uses: actions/checkout@v3
+    - name: Revert version to most recent tag on upstream update
       if: github.event_name == 'repository_dispatch'
-      run: git checkout $(git tag -l | grep 'v.*' | tail -n 1 | awk -F post '{print $1}')
-
+      run: git checkout $(git tag -l | tail -n 1 | awk -F post '{print $1}')
     - name: Set up Python ${{ matrix.python-version }}
-      uses: actions/setup-python@v5
+      uses: actions/setup-python@v4
       with:
         python-version: ${{ matrix.python-version }}
-
     - name: Install build dependencies
       run: |
         python -m pip install --upgrade pip
-
     - name: Install task package
       run: |
         pip install "./related-packages/fileformats[test]" "./related-packages/fileformats-extras[test]"
         python -c "import fileformats.medimage_afni as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
-
     - name: Test fileformats with pytest
-      run: |
-        pytest ./related-packages -sv --cov fileformats.medimage_afni --cov fileformats.extras.medimage_afni --cov-report xml .
-
+      run: >-
+        pytest ./related-packages -sv --cov fileformats.medimage_afni
+        --cov fileformats.extras.medimage_afni --cov-report xml .
 
   test:
-    needs: [nipype-conv, fileformats-test]
+    needs: [nipype-conv]
     runs-on: ubuntu-22.04
     strategy:
       matrix:
-        python-version: ['3.8', '3.11']
+        python-version: ['3.8', '3.12']
     steps:
-    
     - name: Removed unnecessary tools to free space
       run: |
         sudo rm -rf /usr/share/dotnet
-        sudo rm -rf "$AGENT_TOOLSDIRECTORY"
+        sudo rm -rf "$AGENT_TOOLSDIRECTORY"      
 
-    - name: Checkout repo
-      uses: actions/checkout@v4
-
-    - name: Revert version to most recent version tag on upstream update
+    - uses: actions/checkout@v4
+    - name: Revert version to most recent tag on upstream update
       if: github.event_name == 'repository_dispatch'
       run: git checkout $(git tag -l | grep 'v.*' | tail -n 1 | awk -F post '{print $1}')
 
-    - name: Install AFNI
-      run: |
-        curl -O https://raw.githubusercontent.com/afni/afni/master/src/other_builds/OS_notes.linux_ubuntu_22_64_a_admin.txt
-        curl -O https://raw.githubusercontent.com/afni/afni/master/src/other_builds/OS_notes.linux_ubuntu_22_64_b_user.tcsh
-        sudo bash OS_notes.linux_ubuntu_22_64_a_admin.txt 2>&1 | tee o.ubuntu_22_a.txt
-    
-    - name: Download tasks converted from Nipype 
-      uses: actions/download-artifact@v3
+    - name: Download tasks converted from Nipype
+      uses: actions/download-artifact@v4
       with:
         name: converted-nipype
         path: pydra/tasks/afni/auto
-
-    - name: Show the contents of the auto-generated tasks
-      run: tree pydra
-
+    - name: Show package contents
+      run: tree ./pydra
     - name: Strip auto package from gitignore so it is included in package
       run: |
         sed -i '/\/pydra\/tasks\/afni\/auto/d' .gitignore
-
     - name: Set up Python ${{ matrix.python-version }}
       uses: actions/setup-python@v5
       with:
         python-version: ${{ matrix.python-version }}
 
     - name: Install build dependencies
       run: |
         python -m pip install --upgrade pip
 
     - name: Install task package
       run: |
         pip install "./related-packages/fileformats" "./related-packages/fileformats-extras" ".[test]"
         python -c "import pydra.tasks.afni as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
+        python -c "import pydra.tasks.afni.auto as m; print(f'{m.__name__} @ {m.__file__}')"
         python -c "import pydra as m; print(f'{m.__name__} {m.__version__} @ {m.__file__}')"
-
     - name: Test with pytest
       run: |
         pytest -sv ./pydra/tasks/afni --cov pydra.tasks.afni --cov-report xml
-
-    - name: Upload to CodeCov
-      uses: codecov/codecov-action@v3
+    - uses: codecov/codecov-action@v3
       if: ${{ always() }}
       with:
         files: coverage.xml,./fileformats/coverage.xml
         name: pydra-afni
 
-
   deploy-fileformats:
-    needs: [devcheck, test, fileformats-test]
+    needs: [devcheck, test]
     runs-on: ubuntu-latest
     steps:
-
-    - uses: actions/checkout@v4
+    - uses: actions/checkout@v3
       with:
         submodules: recursive
-        fetch-depth: 0
-
+        fetch-depth: 0 
     - name: Set up Python
-      uses: actions/setup-python@v5
+      uses: actions/setup-python@v4
       with:
         python-version: '3.11'
-
     - name: Install build tools
       run: python -m pip install build twine
-
     - name: Build source and wheel distributions
       run: python -m build ./related-packages/fileformats
-
     - name: Check distributions
       run: twine check ./related-packages/fileformats/dist/*
-
     - name: Check for PyPI token on tag
       id: deployable
-      if: github.event_name == 'release' || github.event_name == 'repository_dispatch'
+      if: github.event_name == 'release'
       env:
         PYPI_API_TOKEN: "${{ secrets.PYPI_FILEFORMATS_API_TOKEN }}"
       run: if [ -n "$PYPI_API_TOKEN" ]; then echo "DEPLOY=true" >> $GITHUB_OUTPUT; fi
-
     - name: Upload to PyPI
       if: steps.deployable.outputs.DEPLOY
       uses: pypa/gh-action-pypi-publish@release/v1
       with:
         user: __token__
         password: ${{ secrets.PYPI_FILEFORMATS_API_TOKEN }}
         packages-dir: ./related-packages/fileformats/dist 
 
   deploy-fileformats-extras:
     needs: [deploy-fileformats]
     runs-on: ubuntu-latest
     steps:
-
-    - uses: actions/checkout@v4
+    - uses: actions/checkout@v3
       with:
         submodules: recursive
-        fetch-depth: 0
-
+        fetch-depth: 0 
     - name: Set up Python
-      uses: actions/setup-python@v5
+      uses: actions/setup-python@v4
       with:
         python-version: '3.11'
-
     - name: Install build tools
       run: python -m pip install build twine
-
     - name: Build source and wheel distributions
       run: python -m build ./related-packages/fileformats-extras
-
     - name: Check distributions
       run: twine check ./related-packages/fileformats-extras/dist/*
-
     - name: Check for PyPI token on tag
       id: deployable
-      if: github.event_name == 'release' || github.event_name == 'repository_dispatch'
+      if: github.event_name == 'release'
       env:
         PYPI_API_TOKEN: "${{ secrets.PYPI_FILEFORMATS_EXTRAS_API_TOKEN }}"
       run: if [ -n "$PYPI_API_TOKEN" ]; then echo "DEPLOY=true" >> $GITHUB_OUTPUT; fi
-
     - name: Upload to PyPI
       if: steps.deployable.outputs.DEPLOY
       uses: pypa/gh-action-pypi-publish@release/v1
       with:
         user: __token__
         password: ${{ secrets.PYPI_FILEFORMATS_EXTRAS_API_TOKEN }}
         packages-dir: ./related-packages/fileformats-extras/dist 
 
   deploy:
-    needs: [nipype-conv, test, deploy-fileformats, deploy-fileformats-extras]
+    needs: [deploy-fileformats-extras]
     runs-on: ubuntu-latest
     steps:
 
     - name: Checkout repository
       uses: actions/checkout@v4
       with:
         submodules: recursive
@@ -298,23 +271,22 @@
         git fetch --tags
         echo "TAG=$(git tag -l | grep 'v.*' | tail -n 1 | awk -F post '{print $1}')" >> $GITHUB_OUTPUT
 
     - name: Revert to latest tag
       if: github.event_name == 'repository_dispatch'
       run: git checkout ${{ steps.latest_tag.outputs.TAG }}
 
-    - name: Download tasks converted from Nipype 
-      uses: actions/download-artifact@v3
+    - name: Download tasks converted from Nipype
+      uses: actions/download-artifact@v4
       with:
         name: converted-nipype
         path: pydra/tasks/afni/auto
 
     - name: Show the contents of the auto-generated tasks
-      run: tree pydra
-
+      run: tree pydra 
     - name: Set up Python
       uses: actions/setup-python@v5
       with:
         python-version: '3.11'
 
     - name: Install build tools
       run: python -m pip install build twine
@@ -322,21 +294,20 @@
     - name: Strip auto package from gitignore so it is included in package
       run: |
         sed -i '/\/pydra\/tasks\/afni\/auto/d' .gitignore
         cat .gitignore
 
     - name: Install task package to calculate post-release tag
       run: |
-        pip install "./related-packages/fileformats" "./related-packages/fileformats-extras" ".[test]"
-        tree /opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/pydra/
+        pip install ".[test]"
 
     - name: Generate post-release tag based on Nipype and Nipype2Pydra versions
       id: post_release_tag
       run: |
-        POST=$(python -c "from pydra.tasks.afni.auto._version import *; print(post_release)")
+        POST=$(python -c "from pydra.tasks.afni.auto._post_release import *; print(post_release)")
         echo "TAG=${{ steps.latest_tag.outputs.TAG }}post${POST}" >> $GITHUB_OUTPUT
 
     - name: Add auto directory to git repo
       if: github.event_name == 'release' || github.event_name == 'repository_dispatch'
       run: |
         git add pydra/tasks/afni/auto
         git commit -am"added auto-generated version to make new tag for package version"
@@ -354,22 +325,22 @@
 
     - name: Build source and wheel distributions
       run: python -m build .
 
     - name: Check distributions
       run: twine check dist/*
 
-    - uses: actions/upload-artifact@v3
+    - uses: actions/upload-artifact@v4
       with:
         name: distributions
         path: dist/
 
     - name: Check for PyPI token on tag
       id: deployable
-      if: github.event_name == 'release' || github.event_name == 'repository_dispatch'
+      if: github.event_name == 'release'
       env:
         PYPI_API_TOKEN: "${{ secrets.PYPI_API_TOKEN }}"
       run: if [ -n "$PYPI_API_TOKEN" ]; then echo "DEPLOY=true" >> $GITHUB_OUTPUT; fi
 
     - name: Upload to PyPI
       if: steps.deployable.outputs.DEPLOY
       uses: pypa/gh-action-pypi-publish@release/v1
@@ -382,13 +353,54 @@
       uses: actions/create-release@v1
       env:
         GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # This token is provided by Actions, you do not need to create your own token
       with:
         tag_name: ${{ steps.post_release_tag.outputs.TAG }}
         release_name: Release ${{ steps.post_release_tag.outputs.TAG }}
         draft: false
-        prerelease: false        
+        prerelease: false
+
+  # docs:
+  #   needs: deploy
+  #   environment:
+  #     name: github-pages
+  #     url: ${{ steps.deployment.outputs.page_url }}
+  #   runs-on: ubuntu-latest
+  #   steps:
+  #     - uses: actions/checkout@v4
+  #     - uses: actions/setup-python@v5
+  #       with:
+  #         python-version: '3.x'
+
+  #     - name: Download tasks converted from Nipype
+  #       uses: actions/download-artifact@v4
+  #       with:
+  #         name: converted-nipype
+  #         path: pydra/tasks/freesurfer/auto
+
+  #     - name: Install dependencies
+  #       run: python -m pip install related-packages/fileformats .[doc]
+
+  #     - name: Build docs
+  #       run: |
+  #         pushd docs
+  #         make html
+  #         popd
+
+  #     - name: Upload artifact
+  #       uses: actions/upload-pages-artifact@v3
+  #       with:
+  #         path: 'docs/build/html'
+
+  #     - name: Setup GitHub Pages
+  #       if: github.event_name == 'release' || github.event_name == 'repository_dispatch'
+  #       uses: actions/configure-pages@v4
+
+  #     - name: Deploy to GitHub Pages
+  #       if: github.event_name == 'release' || github.event_name == 'repository_dispatch'
+  #       id: deployment
+  #       uses: actions/deploy-pages@v4
 
 # Deploy on tags if PYPI_API_TOKEN is defined in the repository secrets.
 # Secrets are not accessible in the if: condition [0], so set an output variable [1]
 # [0] https://github.community/t/16928
 # [1] https://docs.github.com/en/actions/reference/workflow-commands-for-github-actions#setting-an-output-parameter
```

### Comparing `pydra_afni-0.2.2.post186034/docs/Makefile` & `pydra_afni-0.3.2/docs/Makefile`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/docs/conf.py` & `pydra_afni-0.3.2/docs/conf.py`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/docs/make.bat` & `pydra_afni-0.3.2/docs/make.bat`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/a_boverlap.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/a_boverlap.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -3,150 +3,151 @@
 #
 # Please fill-in/edit the fields below where appropriate
 #
 # Docs
 # ----
 # Output (to screen) is a count of various things about how
 #     the automasks of datasets A and B overlap or don't overlap.
-#
+# 
 #     For complete details, see the `3dABoverlap Documentation.
 #     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dABoverlap.html>`_
-#
+# 
 #     Examples
 #     --------
 #     >>> from nipype.interfaces import afni
 #     >>> aboverlap = afni.ABoverlap()
 #     >>> aboverlap.inputs.in_file_a = 'functional.nii'
 #     >>> aboverlap.inputs.in_file_b = 'structural.nii'
 #     >>> aboverlap.inputs.out_file =  'out.mask_ae_overlap.txt'
 #     >>> aboverlap.cmdline
 #     '3dABoverlap functional.nii structural.nii  |& tee out.mask_ae_overlap.txt'
 #     >>> res = aboverlap.run()  # doctest: +SKIP
-#
-#
+# 
+#     
 task_name: ABoverlap
 nipype_name: ABoverlap
 nipype_module: nipype.interfaces.afni.utils
 inputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
-    # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
-    # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
-    # from the nipype interface, but you may want to be more specific, particularly
-    # for file types, where specifying the format also specifies the file that will be
-    # passed to the field in the automatically generated unittests.
+  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
+  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
+  # from the nipype interface, but you may want to be more specific, particularly
+  # for file types, where specifying the format also specifies the file that will be
+  # passed to the field in the automatically generated unittests.
     in_file_a: medimage/nifti1
     # type=file|default=<undefined>: input file A
     in_file_b: medimage/nifti1
     # type=file|default=<undefined>: input file B
-    out_file: Path
+    out_file: text/text-file
     # type=file: output file
     # type=file|default=<undefined>: collect output to a file
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
-    # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
-    # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
-    # from the nipype interface, but you may want to be more specific, particularly
-    # for file types, where specifying the format also specifies the file that will be
-    # passed to the field in the automatically generated unittests.
+  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
+  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
+  # from the nipype interface, but you may want to be more specific, particularly
+  # for file types, where specifying the format also specifies the file that will be
+  # passed to the field in the automatically generated unittests.
     out_file: text/text-file
     # type=file: output file
     # type=file|default=<undefined>: collect output to a file
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
-  - inputs:
-      # dict[str, str] - values to provide to inputs fields in the task initialisation
-      # (if not specified, will try to choose a sensible value)
-      in_file_a:
-      # type=file|default=<undefined>: input file A
-      in_file_b:
-      # type=file|default=<undefined>: input file B
-      # out_file:
-      # type=file: output file
-      # type=file|default=<undefined>: collect output to a file
-      no_automask: "False"
-      # type=bool|default=False: consider input datasets as masks
-      quiet: "False"
-      # type=bool|default=False: be as quiet as possible (without being entirely mute)
-      verb: "False"
-      # type=bool|default=False: print out some progress reports (to stderr)
-      num_threads: 1
-      # type=int|default=1: set number of threads
-      outputtype:
-      # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
-    imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-    # consisting of 'module', 'name', and optionally 'alias' keys
-    expected_outputs:
-    # dict[str, str] - expected values for selected outputs, noting that tests will typically
-    # be terminated before they complete for time-saving reasons, and therefore
-    # these values will be ignored, when running in CI
-    timeout: 10
-    # int - the value to set for the timeout in the generated test,
-    # after which the test will be considered to have been initialised
-    # successfully. Set to 0 to disable the timeout (warning, this could
-    # lead to the unittests taking a very long time to complete)
-    xfail: true
-    # bool - whether the unittest is expected to fail or not. Set to false
-    # when you are satisfied with the edits you have made to this file
-  - inputs:
-      # dict[str, str] - values to provide to inputs fields in the task initialisation
-      # (if not specified, will try to choose a sensible value)
-      in_file_a:
-      # type=file|default=<undefined>: input file A
-      in_file_b:
-      # type=file|default=<undefined>: input file B
-      # out_file:
-      # type=file: output file
-      # type=file|default=<undefined>: collect output to a file
-    imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-    # consisting of 'module', 'name', and optionally 'alias' keys
-    expected_outputs:
-    # dict[str, str] - expected values for selected outputs, noting that tests will typically
-    # be terminated before they complete for time-saving reasons, and therefore
-    # these values will be ignored, when running in CI
-    timeout: 10
-    # int - the value to set for the timeout in the generated test,
-    # after which the test will be considered to have been initialised
-    # successfully. Set to 0 to disable the timeout (warning, this could
-    # lead to the unittests taking a very long time to complete)
-    xfail: true
-    # bool - whether the unittest is expected to fail or not. Set to false
-    # when you are satisfied with the edits you have made to this file
+- inputs:
+  # dict[str, str] - values to provide to inputs fields in the task initialisation
+  # (if not specified, will try to choose a sensible value)
+    in_file_a:
+    # type=file|default=<undefined>: input file A
+    in_file_b:
+    # type=file|default=<undefined>: input file B
+    out_file:
+    # type=file: output file
+    # type=file|default=<undefined>: collect output to a file
+    no_automask:
+    # type=bool|default=False: consider input datasets as masks
+    quiet:
+    # type=bool|default=False: be as quiet as possible (without being entirely mute)
+    verb:
+    # type=bool|default=False: print out some progress reports (to stderr)
+    num_threads:
+    # type=int|default=1: set number of threads
+    outputtype:
+    # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
+    args:
+    # type=str|default='': Additional parameters to the command
+    environ:
+    # type=dict|default={}: Environment variables
+  imports:
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+  # consisting of 'module', 'name', and optionally 'alias' keys
+  expected_outputs:
+  # dict[str, str] - expected values for selected outputs, noting that tests will typically
+  # be terminated before they complete for time-saving reasons, and therefore
+  # these values will be ignored, when running in CI
+  timeout: 10
+  # int - the value to set for the timeout in the generated test, 
+  # after which the test will be considered to have been initialised 
+  # successfully. Set to 0 to disable the timeout (warning, this could
+  # lead to the unittests taking a very long time to complete)
+  xfail: true
+  # bool - whether the unittest is expected to fail or not. Set to false
+  # when you are satisfied with the edits you have made to this file
+- inputs:
+  # dict[str, str] - values to provide to inputs fields in the task initialisation
+  # (if not specified, will try to choose a sensible value)
+    in_file_a:
+    # type=file|default=<undefined>: input file A
+    in_file_b:
+    # type=file|default=<undefined>: input file B
+    out_file:
+    # type=file: output file
+    # type=file|default=<undefined>: collect output to a file
+  imports:
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+  # consisting of 'module', 'name', and optionally 'alias' keys
+  expected_outputs:
+  # dict[str, str] - expected values for selected outputs, noting that tests will typically
+  # be terminated before they complete for time-saving reasons, and therefore
+  # these values will be ignored, when running in CI
+  timeout: 10
+  # int - the value to set for the timeout in the generated test, 
+  # after which the test will be considered to have been initialised 
+  # successfully. Set to 0 to disable the timeout (warning, this could
+  # lead to the unittests taking a very long time to complete)
+  xfail: true
+  # bool - whether the unittest is expected to fail or not. Set to false
+  # when you are satisfied with the edits you have made to this file
 doctests:
-  - cmdline: 3dABoverlap functional.nii structural.nii |& tee out.mask_ae_overlap.txt
-    # str - the expected cmdline output
-    inputs:
-      # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
-      # If the field is of file-format type and the value is None, then the
-      # '.mock()' method of the corresponding class is used instead.
-      in_file_a:
-      # type=file|default=<undefined>: input file A
-      in_file_b:
-      # type=file|default=<undefined>: input file B
-      out_file: ' "out.mask_ae_overlap.txt"'
-      # type=file: output file
-      # type=file|default=<undefined>: collect output to a file
-    imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-    # consisting of 'module', 'name', and optionally 'alias' keys
-    directive:
-    # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
+- cmdline: 3dABoverlap functional.nii structural.nii |& tee out.mask_ae_overlap.txt
+  # str - the expected cmdline output
+  inputs:
+  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
+  # If the field is of file-format type and the value is None, then the
+  # '.mock()' method of the corresponding class is used instead.
+    in_file_a:
+    # type=file|default=<undefined>: input file A
+    in_file_b:
+    # type=file|default=<undefined>: input file B
+    out_file:
+    # type=file: output file
+    # type=file|default=<undefined>: collect output to a file
+  imports:
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+  # consisting of 'module', 'name', and optionally 'alias' keys
+  directive:
+  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/afn_ito_nifti.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/afn_ito_nifti.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -34,20 +34,17 @@
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
     in_file: medimage-afni/three-d
     # type=file|default=<undefined>: input file to 3dAFNItoNIFTI
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -69,29 +66,33 @@
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_file:
       # type=file|default=<undefined>: input file to 3dAFNItoNIFTI
-      #out_file:
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
-      pure: "False"
+      pure:
       # type=bool|default=False: Do NOT write an AFNI extension field into the output file. Only use this option if needed. You can also use the 'nifti_tool' program to strip extensions from a file.
-      denote: "False"
+      denote:
       # type=bool|default=False: When writing the AFNI extension field, remove text notes that might contain subject identifying information.
-      oldid: "False"
+      oldid:
       # type=bool|default=False: Give the new dataset the input datasets AFNI ID code.
-      newid: "False"
+      newid:
       # type=bool|default=False: Give the new dataset a new AFNI ID code, to distinguish it from the input dataset.
-      num_threads: 1
+      num_threads:
       # type=int|default=1: set number of threads
-      outputtype: "'NIFTI'"
+      outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
+      args:
+      # type=str|default='': Additional parameters to the command
+      environ:
+      # type=dict|default={}: Environment variables
     imports:
     # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
@@ -104,15 +105,15 @@
     # bool - whether the unittest is expected to fail or not. Set to false
     # when you are satisfied with the edits you have made to this file
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_file:
       # type=file|default=<undefined>: input file to 3dAFNItoNIFTI
-      #out_file:
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
     imports:
     # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
@@ -131,15 +132,15 @@
     # str - the expected cmdline output
     inputs:
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       in_file:
       # type=file|default=<undefined>: input file to 3dAFNItoNIFTI
-      out_file: ' "afni_output.nii"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/align_epi_anat_py.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/align_epi_anat_py.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -66,50 +66,47 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    anat: medimage/nifti1
-    # type=file|default=<undefined>: name of structural dataset
     in_file: medimage/nifti1
     # type=file|default=<undefined>: EPI dataset to align
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    anat: medimage/nifti1
+    # type=file|default=<undefined>: name of structural dataset
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    anat_al_mat: generic/file
-    # type=file: matrix to align anatomy to the EPI
     anat_al_orig: generic/file
     # type=file: A version of the anatomy that is aligned to the EPI
-    epi_al_mat: generic/file
-    # type=file: matrix to align EPI to anatomy
     epi_al_orig: generic/file
     # type=file: A version of the EPI dataset aligned to the anatomy
-    epi_al_tlrc_mat: generic/file
-    # type=file: matrix to volume register and align epito anatomy and put into standard space
-    epi_reg_al_mat: generic/file
-    # type=file: matrix to volume register and align epi to anatomy
     epi_tlrc_al: generic/file
     # type=file: A version of the EPI dataset aligned to a standard template
+    anat_al_mat: generic/file
+    # type=file: matrix to align anatomy to the EPI
+    epi_al_mat: generic/file
+    # type=file: matrix to align EPI to anatomy
     epi_vr_al_mat: generic/file
     # type=file: matrix to volume register EPI
+    epi_reg_al_mat: generic/file
+    # type=file: matrix to volume register and align epi to anatomy
+    epi_al_tlrc_mat: generic/file
+    # type=file: matrix to volume register and align epito anatomy and put into standard space
     epi_vr_motion: generic/file
     # type=file: motion parameters from EPI time-seriesregistration (tsh included in name if slicetiming correction is also included).
     skullstrip: generic/file
     # type=file: skull-stripped (not aligned) volume
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
@@ -121,42 +118,40 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: EPI dataset to align
     anat:
     # type=file|default=<undefined>: name of structural dataset
-    epi_base: 
-    #Blank is mapped to None
+    epi_base:
     # type=traitcompound|default=None: the epi base used in alignmentshould be one of (0/mean/median/max/subbrick#)
-    anat2epi: "False"
+    anat2epi:
     # type=bool|default=False: align anatomical to EPI dataset (default)
-    epi2anat: "False"
+    epi2anat:
     # type=bool|default=False: align EPI to anatomical dataset
     save_skullstrip:
     # type=bool|default=False: save skull-stripped (not aligned)
-    suffix: "'_al'"
+    suffix:
     # type=str|default='_al': append suffix to the original anat/epi dataset to usein the resulting dataset names (default is "_al")
-    epi_strip: "'3dSkullStrip'"
+    epi_strip:
     # type=enum|default='3dSkullStrip'|allowed['3dAutomask','3dSkullStrip','None']: method to mask brain in EPI datashould be one of[3dSkullStrip]/3dAutomask/None)
-    volreg: "'on'"
+    volreg:
     # type=enum|default='on'|allowed['off','on']: do volume registration on EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'
-    tshift: "'on'"
+    tshift:
     # type=enum|default='on'|allowed['off','on']: do time shifting of EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'
-    outputtype: "'AFNI'"
+    outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
-    ###delete the following 3:###
-    #py27_path:
+    py27_path:
     # type=traitcompound|default='python2': 
-    #args:
+    args:
     # type=str|default='': Additional parameters to the command
-    #environ:
+    environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -180,15 +175,15 @@
     volreg: '"off"'
     # type=enum|default='on'|allowed['off','on']: do volume registration on EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'
     tshift: '"off"'
     # type=enum|default='on'|allowed['off','on']: do time shifting of EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'
     save_skullstrip: 'True'
     # type=bool|default=False: save skull-stripped (not aligned)
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -216,11 +211,11 @@
     volreg: '"off"'
     # type=enum|default='on'|allowed['off','on']: do volume registration on EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'
     tshift: '"off"'
     # type=enum|default='on'|allowed['off','on']: do time shifting of EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'
     save_skullstrip: 'True'
     # type=bool|default=False: save skull-stripped (not aligned)
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/allineate.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/allineate.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -47,74 +47,71 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    allcostx: Path
-    # type=file: Compute and print ALL available cost functionals for the un-warped inputs
-    # type=file|default=<undefined>: Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dAllineate
-    in_matrix: datascience/text-matrix
-    # type=file|default=<undefined>: matrix to align input file
-    in_param_file: generic/file
-    # type=file|default=<undefined>: Read warp parameters from file and apply them to the source dataset, and produce a new dataset
-    master: generic/file
-    # type=file|default=<undefined>: Write the output dataset on the same grid as this file.
-    out_file: Path
+    reference: medimage/nifti1
+    # type=file|default=<undefined>: file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.
+    out_file: medimage/nifti1
     # type=file: output image file name
     # type=file|default=<undefined>: output file from 3dAllineate
-    out_matrix: Path
-    # type=file: matrix to align input file
-    # type=file|default=<undefined>: Save the transformation matrix for each volume.
-    out_param_file: Path
+    out_param_file: generic/file
     # type=file: warp parameters
     # type=file|default=<undefined>: Save the warp parameters in ASCII (.1D) format.
-    out_weight_file: Path
+    in_param_file: generic/file
+    # type=file|default=<undefined>: Read warp parameters from file and apply them to the source dataset, and produce a new dataset
+    out_matrix: generic/file
+    # type=file: matrix to align input file
+    # type=file|default=<undefined>: Save the transformation matrix for each volume.
+    in_matrix: datascience/text-matrix
+    # type=file|default=<undefined>: matrix to align input file
+    allcostx: text/text-file
+    # type=file: Compute and print ALL available cost functionals for the un-warped inputs
+    # type=file|default=<undefined>: Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced
+    weight_file: generic/file
+    # type=file|default=<undefined>: Set the weighting for each voxel in the base dataset; larger weights mean that voxel count more in the cost function. Must be defined on the same grid as the base dataset
+    out_weight_file: generic/file
     # type=file: weight volume
     # type=file|default=<undefined>: Write the weight volume to disk as a dataset
-    reference: medimage/nifti1
-    # type=file|default=<undefined>: file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.
     source_mask: generic/file
     # type=file|default=<undefined>: mask the input dataset
-    weight_file: generic/file
-    # type=file|default=<undefined>: Set the weighting for each voxel in the base dataset; larger weights mean that voxel count more in the cost function. Must be defined on the same grid as the base dataset
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    master: generic/file
+    # type=file|default=<undefined>: Write the output dataset on the same grid as this file.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    allcostx: text/text-file
-    # type=file: Compute and print ALL available cost functionals for the un-warped inputs
-    # type=file|default=<undefined>: Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced
     out_file: medimage/nifti1
     # type=file: output image file name
     # type=file|default=<undefined>: output file from 3dAllineate
     out_matrix: generic/file
     # type=file: matrix to align input file
     # type=file|default=<undefined>: Save the transformation matrix for each volume.
     out_param_file: generic/file
     # type=file: warp parameters
     # type=file|default=<undefined>: Save the warp parameters in ASCII (.1D) format.
     out_weight_file: generic/file
     # type=file: weight volume
     # type=file|default=<undefined>: Write the weight volume to disk as a dataset
+    allcostx: text/text-file
+    # type=file: Compute and print ALL available cost functionals for the un-warped inputs
+    # type=file|default=<undefined>: Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -232,15 +229,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -251,21 +248,21 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dAllineate
-    out_file: '"functional_allineate.nii"'
+    out_file:
     # type=file: output image file name
     # type=file|default=<undefined>: output file from 3dAllineate
     in_matrix:
     # type=file|default=<undefined>: matrix to align input file
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -278,19 +275,19 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dAllineate
     reference:
     # type=file|default=<undefined>: file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.
-    allcostx: '"out.allcostX.txt"'
+    allcostx:
     # type=file: Compute and print ALL available cost functionals for the un-warped inputs
     # type=file|default=<undefined>: Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -306,15 +303,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dAllineate
     reference:
     # type=file|default=<undefined>: file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.
     nwarp_fixmot: '["X", "Y"]'
     # type=list|default=[]: To fix motion along directions.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -329,39 +326,39 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dAllineate
-    out_file: '"functional_allineate.nii"'
+    out_file:
     # type=file: output image file name
     # type=file|default=<undefined>: output file from 3dAllineate
     in_matrix:
     # type=file|default=<undefined>: matrix to align input file
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dAllineate -source functional.nii -base structural.nii -allcostx |& tee out.allcostX.txt
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dAllineate
     reference:
     # type=file|default=<undefined>: file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.
-    allcostx: '"out.allcostX.txt"'
+    allcostx:
     # type=file: Compute and print ALL available cost functionals for the un-warped inputs
     # type=file|default=<undefined>: Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dAllineate -source functional.nii -nwarp_fixmotX -nwarp_fixmotY -prefix functional_allineate -base structural.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -370,11 +367,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dAllineate
     reference:
     # type=file|default=<undefined>: file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.
     nwarp_fixmot: '["X", "Y"]'
     # type=list|default=[]: To fix motion along directions.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/auto_tcorrelate.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/auto_tcorrelate.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -41,20 +41,17 @@
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: timeseries x space (volume or surface) file
     mask: medimage/nifti1
     # type=file|default=<undefined>: mask of voxels
     mask_source: generic/file
     # type=file|default=<undefined>: mask for source voxels
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -98,15 +95,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -126,15 +123,15 @@
     eta2: 'True'
     # type=bool|default=False: eta^2 similarity
     mask:
     # type=file|default=<undefined>: mask of voxels
     mask_only_targets: 'True'
     # type=bool|default=False: use mask only on targets voxels
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -158,11 +155,11 @@
     eta2: 'True'
     # type=bool|default=False: eta^2 similarity
     mask:
     # type=file|default=<undefined>: mask of voxels
     mask_only_targets: 'True'
     # type=bool|default=False: use mask only on targets voxels
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/auto_tlrc.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/auto_tlrc.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -34,17 +34,14 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: Original anatomical volume (+orig).The skull is removed by this scriptunless instructed otherwise (-no_ss).
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -76,15 +73,15 @@
     no_ss:
     # type=bool|default=False: Do not strip skull of input data set (because skull has already been removed or because template still has the skull) NOTE: The ``-no_ss`` option is not all that optional. Here is a table of when you should and should not use ``-no_ss``    +------------------+------------+---------------+   | Dataset          | Template                   |   +==================+============+===============+   |                  | w/ skull   | wo/ skull     |   +------------------+------------+---------------+   | WITH skull       | ``-no_ss`` | xxx           |   +------------------+------------+---------------+   | WITHOUT skull    | No Cigar   | ``-no_ss``    |   +------------------+------------+---------------+  Template means: Your template of choice Dset. means: Your anatomical dataset ``-no_ss`` means: Skull stripping should not be attempted on Dset xxx means: Don't put anything, the script will strip Dset No Cigar means: Don't try that combination, it makes no sense.
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -100,15 +97,15 @@
     in_file:
     # type=file|default=<undefined>: Original anatomical volume (+orig).The skull is removed by this scriptunless instructed otherwise (-no_ss).
     no_ss: 'True'
     # type=bool|default=False: Do not strip skull of input data set (because skull has already been removed or because template still has the skull) NOTE: The ``-no_ss`` option is not all that optional. Here is a table of when you should and should not use ``-no_ss``    +------------------+------------+---------------+   | Dataset          | Template                   |   +==================+============+===============+   |                  | w/ skull   | wo/ skull     |   +------------------+------------+---------------+   | WITH skull       | ``-no_ss`` | xxx           |   +------------------+------------+---------------+   | WITHOUT skull    | No Cigar   | ``-no_ss``    |   +------------------+------------+---------------+  Template means: Your template of choice Dset. means: Your anatomical dataset ``-no_ss`` means: Skull stripping should not be attempted on Dset xxx means: Don't put anything, the script will strip Dset No Cigar means: Don't try that combination, it makes no sense.
     base: '"TT_N27+tlrc"'
     # type=str|default='': Reference anatomical volume. Usually this volume is in some standard space like TLRC or MNI space and with afni dataset view of (+tlrc). Preferably, this reference volume should have had the skull removed but that is not mandatory. AFNI's distribution contains several templates. For a longer list, use "whereami -show_templates" TT_N27+tlrc --> Single subject, skull stripped volume. This volume is also known as N27_SurfVol_NoSkull+tlrc elsewhere in AFNI and SUMA land. (www.loni.ucla.edu, www.bic.mni.mcgill.ca) This template has a full set of FreeSurfer (surfer.nmr.mgh.harvard.edu) surface models that can be used in SUMA. For details, see Talairach-related link: https://afni.nimh.nih.gov/afni/suma TT_icbm452+tlrc --> Average volume of 452 normal brains. Skull Stripped. (www.loni.ucla.edu) TT_avg152T1+tlrc --> Average volume of 152 normal brains. Skull Stripped.(www.bic.mni.mcgill.ca) TT_EPI+tlrc --> EPI template from spm2, masked as TT_avg152T1 TT_avg152 and TT_EPI volume sources are from SPM's distribution. (www.fil.ion.ucl.ac.uk/spm/) If you do not specify a path for the template, the script will attempt to locate the template AFNI's binaries directory. NOTE: These datasets have been slightly modified from their original size to match the standard TLRC dimensions (Jean Talairach and Pierre Tournoux Co-Planar Stereotaxic Atlas of the Human Brain Thieme Medical Publishers, New York, 1988). That was done for internal consistency in AFNI. You may use the original form of these volumes if you choose but your TLRC coordinates will not be consistent with AFNI's TLRC database (San Antonio Talairach Daemon database), for example.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -128,11 +125,11 @@
     in_file:
     # type=file|default=<undefined>: Original anatomical volume (+orig).The skull is removed by this scriptunless instructed otherwise (-no_ss).
     no_ss: 'True'
     # type=bool|default=False: Do not strip skull of input data set (because skull has already been removed or because template still has the skull) NOTE: The ``-no_ss`` option is not all that optional. Here is a table of when you should and should not use ``-no_ss``    +------------------+------------+---------------+   | Dataset          | Template                   |   +==================+============+===============+   |                  | w/ skull   | wo/ skull     |   +------------------+------------+---------------+   | WITH skull       | ``-no_ss`` | xxx           |   +------------------+------------+---------------+   | WITHOUT skull    | No Cigar   | ``-no_ss``    |   +------------------+------------+---------------+  Template means: Your template of choice Dset. means: Your anatomical dataset ``-no_ss`` means: Skull stripping should not be attempted on Dset xxx means: Don't put anything, the script will strip Dset No Cigar means: Don't try that combination, it makes no sense.
     base: '"TT_N27+tlrc"'
     # type=str|default='': Reference anatomical volume. Usually this volume is in some standard space like TLRC or MNI space and with afni dataset view of (+tlrc). Preferably, this reference volume should have had the skull removed but that is not mandatory. AFNI's distribution contains several templates. For a longer list, use "whereami -show_templates" TT_N27+tlrc --> Single subject, skull stripped volume. This volume is also known as N27_SurfVol_NoSkull+tlrc elsewhere in AFNI and SUMA land. (www.loni.ucla.edu, www.bic.mni.mcgill.ca) This template has a full set of FreeSurfer (surfer.nmr.mgh.harvard.edu) surface models that can be used in SUMA. For details, see Talairach-related link: https://afni.nimh.nih.gov/afni/suma TT_icbm452+tlrc --> Average volume of 452 normal brains. Skull Stripped. (www.loni.ucla.edu) TT_avg152T1+tlrc --> Average volume of 152 normal brains. Skull Stripped.(www.bic.mni.mcgill.ca) TT_EPI+tlrc --> EPI template from spm2, masked as TT_avg152T1 TT_avg152 and TT_EPI volume sources are from SPM's distribution. (www.fil.ion.ucl.ac.uk/spm/) If you do not specify a path for the template, the script will attempt to locate the template AFNI's binaries directory. NOTE: These datasets have been slightly modified from their original size to match the standard TLRC dimensions (Jean Talairach and Pierre Tournoux Co-Planar Stereotaxic Atlas of the Human Brain Thieme Medical Publishers, New York, 1988). That was done for internal consistency in AFNI. You may use the original form of these volumes if you choose but your TLRC coordinates will not be consistent with AFNI's TLRC database (San Antonio Talairach Daemon database), for example.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/autobox.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_stat.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -1,53 +1,52 @@
 # This file is used to manually specify the semi-automatic conversion of
-# 'nipype.interfaces.afni.utils.Autobox' from Nipype to Pydra.
+# 'nipype.interfaces.afni.utils.TStat' from Nipype to Pydra.
 #
 # Please fill-in/edit the fields below where appropriate
 #
 # Docs
 # ----
-# Computes size of a box that fits around the volume.
-#     Also can be used to crop the volume to that box.
+# Compute voxel-wise statistics using AFNI 3dTstat command
 # 
-#     For complete details, see the `3dAutobox Documentation.
-#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dAutobox.html>`_
+#     For complete details, see the `3dTstat Documentation.
+#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dTstat.html>`_
 # 
 #     Examples
 #     --------
 #     >>> from nipype.interfaces import afni
-#     >>> abox = afni.Autobox()
-#     >>> abox.inputs.in_file = 'structural.nii'
-#     >>> abox.inputs.padding = 5
-#     >>> abox.cmdline
-#     '3dAutobox -input structural.nii -prefix structural_autobox -npad 5'
-#     >>> res = abox.run()  # doctest: +SKIP
+#     >>> tstat = afni.TStat()
+#     >>> tstat.inputs.in_file = 'functional.nii'
+#     >>> tstat.inputs.args = '-mean'
+#     >>> tstat.inputs.out_file = 'stats'
+#     >>> tstat.cmdline
+#     '3dTstat -mean -prefix stats functional.nii'
+#     >>> res = tstat.run()  # doctest: +SKIP
 # 
 #     
-task_name: Autobox
-nipype_name: Autobox
+task_name: TStat
+nipype_name: TStat
 nipype_module: nipype.interfaces.afni.utils
 inputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
-    # type=file|default=<undefined>: input file
-    out_file: Path
+    # type=file|default=<undefined>: input file to 3dTstat
+    out_file: generic/file
     # type=file: output file
-    # type=file|default=<undefined>: 
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    # type=file|default=<undefined>: output image file name
+    mask: generic/file
+    # type=file|default=<undefined>: mask file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -55,57 +54,45 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     out_file: generic/file
     # type=file: output file
-    # type=file|default=<undefined>: 
+    # type=file|default=<undefined>: output image file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
-    x_max: x_max_callable
-    # type=int: 
-    x_min: x_min_callable
-    # type=int: 
-    y_max: y_max_callable
-    # type=int: 
-    y_min: y_min_callable
-    # type=int: 
-    z_max: z_max_callable
-    # type=int: 
-    z_min: z_min_callable
-    # type=int: 
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
-    # type=file|default=<undefined>: input file
-    padding:
-    # type=int|default=0: Number of extra voxels to pad on each side of box
+    # type=file|default=<undefined>: input file to 3dTstat
     out_file:
     # type=file: output file
-    # type=file|default=<undefined>: 
-    no_clustering:
-    # type=bool|default=False: Don't do any clustering to find box. Any non-zero voxel will be preserved in the cropped volume. The default method uses some clustering to find the cropping box, and will clip off small isolated blobs.
+    # type=file|default=<undefined>: output image file name
+    mask:
+    # type=file|default=<undefined>: mask file
+    options:
+    # type=str|default='': selected statistical output
     num_threads:
     # type=int|default=1: set number of threads
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -115,41 +102,47 @@
   xfail: true
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
-    # type=file|default=<undefined>: input file
-    padding: '5'
-    # type=int|default=0: Number of extra voxels to pad on each side of box
+    # type=file|default=<undefined>: input file to 3dTstat
+    args: '"-mean"'
+    # type=str|default='': Additional parameters to the command
+    out_file:
+    # type=file: output file
+    # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
   # after which the test will be considered to have been initialised 
   # successfully. Set to 0 to disable the timeout (warning, this could
   # lead to the unittests taking a very long time to complete)
   xfail: true
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 doctests:
-- cmdline: 3dAutobox -input structural.nii -prefix structural_autobox -npad 5
+- cmdline: 3dTstat -mean -prefix stats functional.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
-    # type=file|default=<undefined>: input file
-    padding: '5'
-    # type=int|default=0: Number of extra voxels to pad on each side of box
+    # type=file|default=<undefined>: input file to 3dTstat
+    args: '"-mean"'
+    # type=str|default='': Additional parameters to the command
+    out_file:
+    # type=file: output file
+    # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/automask.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/automask.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -32,44 +32,41 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    brain_file: Path
-    # type=file: brain file (skull stripped)
-    # type=file|default=<undefined>: output file from 3dAutomask
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dAutomask
-    out_file: Path
+    out_file: generic/file
     # type=file: mask file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    brain_file: generic/file
+    # type=file: brain file (skull stripped)
+    # type=file|default=<undefined>: output file from 3dAutomask
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    brain_file: generic/file
-    # type=file: brain file (skull stripped)
-    # type=file|default=<undefined>: output file from 3dAutomask
     out_file: generic/file
     # type=file: mask file
     # type=file|default=<undefined>: output image file name
+    brain_file: generic/file
+    # type=file: brain file (skull stripped)
+    # type=file|default=<undefined>: output file from 3dAutomask
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -96,15 +93,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -120,15 +117,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dAutomask
     dilate: '1'
     # type=int|default=0: dilate the mask outwards
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -148,11 +145,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dAutomask
     dilate: '1'
     # type=int|default=0: dilate the mask outwards
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/axialize.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/axialize.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -34,20 +34,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3daxialize
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -91,15 +88,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -110,19 +107,19 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3daxialize
-    out_file: '"axialized.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -137,15 +134,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3daxialize
-    out_file: '"axialized.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/bandpass.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/bandpass.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -36,26 +36,23 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dBandpass
+    out_file: generic/file
+    # type=file: output file
+    # type=file|default=<undefined>: output file from 3dBandpass
     mask: generic/file
     # type=file|default=<undefined>: mask file
-    orthogonalize_dset: generic/file
-    # type=file|default=<undefined>: Orthogonalize each voxel to the corresponding voxel time series in dataset 'fset', which must have the same spatial and temporal grid structure as the main input dataset. At present, only one '-dsort' option is allowed.
     orthogonalize_file: generic/file+list-of
     # type=inputmultiobject|default=[]: Also orthogonalize input to columns in f.1D. Multiple '-ort' options are allowed.
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: output file from 3dBandpass
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    orthogonalize_dset: generic/file
+    # type=file|default=<undefined>: Orthogonalize each voxel to the corresponding voxel time series in dataset 'fset', which must have the same spatial and temporal grid structure as the main input dataset. At present, only one '-dsort' option is allowed.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -117,15 +114,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -141,15 +138,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dBandpass
     highpass: '0.005'
     # type=float|default=0.0: highpass
     lowpass: '0.1'
     # type=float|default=0.0: lowpass
   imports: &id001
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   - module: nipype.testing
     name: ' example_data'
     alias:
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
@@ -172,11 +169,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dBandpass
     highpass: '0.005'
     # type=float|default=0.0: highpass
     lowpass: '0.1'
     # type=float|default=0.0: lowpass
   imports: *id001
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/blur_in_mask.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blur_in_mask.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -34,24 +34,21 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dSkullStrip
+    out_file: generic/file
+    # type=file: output file
+    # type=file|default=<undefined>: output to the file
     mask: medimage/nifti1
     # type=file|default=<undefined>: Mask dataset, if desired.  Blurring will occur only within the mask. Voxels NOT in the mask will be set to zero in the output.
     multimask: generic/file
     # type=file|default=<undefined>: Multi-mask dataset -- each distinct nonzero value in dataset will be treated as a separate mask for blurring purposes.
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: output to the file
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -99,15 +96,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -123,15 +120,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dSkullStrip
     mask:
     # type=file|default=<undefined>: Mask dataset, if desired.  Blurring will occur only within the mask. Voxels NOT in the mask will be set to zero in the output.
     fwhm: '5.0'
     # type=float|default=0.0: fwhm kernel size
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -151,11 +148,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dSkullStrip
     mask:
     # type=file|default=<undefined>: Mask dataset, if desired.  Blurring will occur only within the mask. Voxels NOT in the mask will be set to zero in the output.
     fwhm: '5.0'
     # type=float|default=0.0: fwhm kernel size
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/blur_to_fwhm.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/blur_to_fwhm.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -32,26 +32,23 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    blurmaster: generic/file
-    # type=file|default=<undefined>: The dataset whose smoothness controls the process.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: The dataset that will be smoothed
+    blurmaster: generic/file
+    # type=file|default=<undefined>: The dataset whose smoothness controls the process.
     mask: generic/file
     # type=file|default=<undefined>: Mask dataset, if desired. Voxels NOT in mask will be set to zero in output.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -95,15 +92,15 @@
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -117,15 +114,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: The dataset that will be smoothed
     fwhm: '2.5'
     # type=float|default=0.0: Blur until the 3D FWHM reaches this value (in mm)
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -143,11 +140,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: The dataset that will be smoothed
     fwhm: '2.5'
     # type=float|default=0.0: Blur until the 3D FWHM reaches this value (in mm)
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/brick_stat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/brick_stat.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -37,17 +37,14 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dmaskave
     mask: medimage/nifti-gz
     # type=file|default=<undefined>: -mask dset = use dset as mask to include/exclude voxels
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -56,16 +53,14 @@
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
-    min_val: min_val_callable
-    # type=float: output
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
@@ -89,15 +84,15 @@
     percentile:
     # type=tuple|default=(0.0, 0.0, 0.0): p0 ps p1 write the percentile values starting at p0% and ending at p1% at a step of ps%. only one sub-brick is accepted.
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -113,15 +108,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dmaskave
     mask:
     # type=file|default=<undefined>: -mask dset = use dset as mask to include/exclude voxels
     min: 'True'
     # type=bool|default=False: print the minimum value in dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -141,11 +136,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dmaskave
     mask:
     # type=file|default=<undefined>: -mask dset = use dset as mask to include/exclude voxels
     min: 'True'
     # type=bool|default=False: print the minimum value in dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/bucket.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/bucket.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -42,20 +42,17 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: 
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -89,15 +86,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -108,19 +105,19 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file: '[(''functional.nii'',"{2..$}"), (''functional.nii'',"{1}")]'
     # type=list|default=[]: List of tuples of input datasets and subbrick selection strings as described in more detail in the following afni help string Input dataset specified using one of these forms: ``prefix+view``, ``prefix+view.HEAD``, or ``prefix+view.BRIK``. You can also add a sub-brick selection list after the end of the dataset name.  This allows only a subset of the sub-bricks to be included into the output (by default, all of the input dataset is copied into the output).  A sub-brick selection list looks like one of the following forms::      fred+orig[5]                     ==> use only sub-brick #5     fred+orig[5,9,17]                ==> use #5, #9, and #17     fred+orig[5..8]     or [5-8]     ==> use #5, #6, #7, and #8     fred+orig[5..13(2)] or [5-13(2)] ==> use #5, #7, #9, #11, and #13  Sub-brick indexes start at 0.  You can use the character '$' to indicate the last sub-brick in a dataset; for example, you can select every third sub-brick by using the selection list ``fred+orig[0..$(3)]`` N.B.: The sub-bricks are output in the order specified, which may not be the order in the original datasets.  For example, using ``fred+orig[0..$(2),1..$(2)]`` will cause the sub-bricks in fred+orig to be output into the new dataset in an interleaved fashion. Using ``fred+orig[$..0]`` will reverse the order of the sub-bricks in the output. N.B.: Bucket datasets have multiple sub-bricks, but do NOT have a time dimension.  You can input sub-bricks from a 3D+time dataset into a bucket dataset.  You can use the '3dinfo' program to see how many sub-bricks a 3D+time or a bucket dataset contains. N.B.: In non-bucket functional datasets (like the 'fico' datasets output by FIM, or the 'fitt' datasets output by 3dttest), sub-brick ``[0]`` is the 'intensity' and sub-brick [1] is the statistical parameter used as a threshold.  Thus, to create a bucket dataset using the intensity from dataset A and the threshold from dataset B, and calling the output dataset C, you would type::      3dbucket -prefix C -fbuc 'A+orig[0]' -fbuc 'B+orig[1]  
-    out_file: '"vr_base"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: 
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -135,15 +132,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file: '[(''functional.nii'',"{2..$}"), (''functional.nii'',"{1}")]'
     # type=list|default=[]: List of tuples of input datasets and subbrick selection strings as described in more detail in the following afni help string Input dataset specified using one of these forms: ``prefix+view``, ``prefix+view.HEAD``, or ``prefix+view.BRIK``. You can also add a sub-brick selection list after the end of the dataset name.  This allows only a subset of the sub-bricks to be included into the output (by default, all of the input dataset is copied into the output).  A sub-brick selection list looks like one of the following forms::      fred+orig[5]                     ==> use only sub-brick #5     fred+orig[5,9,17]                ==> use #5, #9, and #17     fred+orig[5..8]     or [5-8]     ==> use #5, #6, #7, and #8     fred+orig[5..13(2)] or [5-13(2)] ==> use #5, #7, #9, #11, and #13  Sub-brick indexes start at 0.  You can use the character '$' to indicate the last sub-brick in a dataset; for example, you can select every third sub-brick by using the selection list ``fred+orig[0..$(3)]`` N.B.: The sub-bricks are output in the order specified, which may not be the order in the original datasets.  For example, using ``fred+orig[0..$(2),1..$(2)]`` will cause the sub-bricks in fred+orig to be output into the new dataset in an interleaved fashion. Using ``fred+orig[$..0]`` will reverse the order of the sub-bricks in the output. N.B.: Bucket datasets have multiple sub-bricks, but do NOT have a time dimension.  You can input sub-bricks from a 3D+time dataset into a bucket dataset.  You can use the '3dinfo' program to see how many sub-bricks a 3D+time or a bucket dataset contains. N.B.: In non-bucket functional datasets (like the 'fico' datasets output by FIM, or the 'fitt' datasets output by 3dttest), sub-brick ``[0]`` is the 'intensity' and sub-brick [1] is the statistical parameter used as a threshold.  Thus, to create a bucket dataset using the intensity from dataset A and the threshold from dataset B, and calling the output dataset C, you would type::      3dbucket -prefix C -fbuc 'A+orig[0]' -fbuc 'B+orig[1]  
-    out_file: '"vr_base"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: 
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/calc.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/calc.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -50,22 +50,19 @@
   # passed to the field in the automatically generated unittests.
     in_file_a: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dcalc
     in_file_b: medimage/nifti1
     # type=file|default=<undefined>: operand file to 3dcalc
     in_file_c: generic/file
     # type=file|default=<undefined>: operand file to 3dcalc
-    other: generic/file
-    # type=file|default=<undefined>: other options
-    out_file: Path
+    out_file: medimage-afni/all1,medimage/nifti-gz
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    other: generic/file
+    # type=file|default=<undefined>: other options
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -115,15 +112,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -138,21 +135,21 @@
   # (if not specified, will try to choose a sensible value)
     in_file_a:
     # type=file|default=<undefined>: input file to 3dcalc
     in_file_b:
     # type=file|default=<undefined>: operand file to 3dcalc
     expr: '"a*b"'
     # type=str|default='': expr
-    out_file: ' "functional_calc.nii.gz"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -165,21 +162,21 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file_a:
     # type=file|default=<undefined>: input file to 3dcalc
     expr: '"1"'
     # type=str|default='': expr
-    out_file: '"rm.epi.all1"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     overwrite: 'True'
     # type=bool|default=False: overwrite output
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -198,37 +195,37 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file_a:
     # type=file|default=<undefined>: input file to 3dcalc
     in_file_b:
     # type=file|default=<undefined>: operand file to 3dcalc
     expr: '"a*b"'
     # type=str|default='': expr
-    out_file: ' "functional_calc.nii.gz"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dcalc -a functional.nii -expr "1" -prefix rm.epi.all1 -overwrite
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file_a:
     # type=file|default=<undefined>: input file to 3dcalc
     expr: '"1"'
     # type=str|default='': expr
-    out_file: '"rm.epi.all1"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     overwrite: 'True'
     # type=bool|default=False: overwrite output
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/cat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cat.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -36,20 +36,17 @@
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
     in_files: medimage-afni/one-d+list-of
     # type=list|default=[]:
-    out_file: Path
+    out_file: medimage-afni/one-d
     # type=file: output file
     # type=file|default='catout.1d': output (concatenated) file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -103,15 +100,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -124,19 +121,19 @@
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       sel: '"''[0,2]''"'
       # type=str|default='': Apply the same column/row selection string to all filenames on the command line.
       in_files:
       # type=list|default=[]:
-      out_file: '"catout.1d"'
+      out_file:
       # type=file: output file
       # type=file|default='catout.1d': output (concatenated) file name
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -153,15 +150,15 @@
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       sel: '"''[0,2]''"'
       # type=str|default='': Apply the same column/row selection string to all filenames on the command line.
       in_files:
       # type=list|default=[]:
-      out_file: '"catout.1d"'
+      out_file:
       # type=file: output file
       # type=file|default='catout.1d': output (concatenated) file name
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/cat_matvec.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/cat_matvec.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -31,20 +31,17 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    out_file: Path
+    out_file: medimage-afni/one-d
     # type=file: output file
     # type=file|default=<undefined>: File to write concattenated matvecs to
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -84,15 +81,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -103,19 +100,19 @@
     # bool - whether the unittest is expected to fail or not. Set to false
     # when you are satisfied with the edits you have made to this file
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_file: '[("structural.BRIK::WARP_DATA","I")]'
       # type=list|default=[]: list of tuples of mfiles and associated opkeys
-      out_file: '"warp.anat.Xat.1D"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: File to write concattenated matvecs to
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -130,15 +127,15 @@
     # str - the expected cmdline output
     inputs:
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       in_file: '[("structural.BRIK::WARP_DATA","I")]'
       # type=list|default=[]: list of tuples of mfiles and associated opkeys
-      out_file: '"warp.anat.Xat.1D"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: File to write concattenated matvecs to
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/center_mass.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/center_mass.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -38,42 +38,39 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    cm_file: Path
-    # type=file: file with the center of mass coordinates
-    # type=file|default=<undefined>: File to write center of mass to
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dCM
+    cm_file: text/text-file
+    # type=file: file with the center of mass coordinates
+    # type=file|default=<undefined>: File to write center of mass to
     mask_file: generic/file
     # type=file|default=<undefined>: Only voxels with nonzero values in the provided mask will be averaged.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    out_file: generic/file
+    # type=file: output file
     cm_file: text/text-file
     # type=file: file with the center of mass coordinates
     # type=file|default=<undefined>: File to write center of mass to
-    out_file: generic/file
-    # type=file: output file
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -87,27 +84,27 @@
     # type=file: file with the center of mass coordinates
     # type=file|default=<undefined>: File to write center of mass to
     mask_file:
     # type=file|default=<undefined>: Only voxels with nonzero values in the provided mask will be averaged.
     automask:
     # type=bool|default=False: Generate the mask automatically
     set_cm:
-    # type=tuple|default=(<traits.trait_types.Float object at 0x1155a4250>, <traits.trait_types.Float object at 0x1155a4350>, <traits.trait_types.Float object at 0x1155a43d0>): After computing the center of mass, set the origin fields in the header so that the center of mass will be at (x,y,z) in DICOM coords.
+    # type=tuple|default=(<traits.trait_types.Float object at 0x1123203d0>, <traits.trait_types.Float object at 0x112320430>, <traits.trait_types.Float object at 0x112320490>): After computing the center of mass, set the origin fields in the header so that the center of mass will be at (x,y,z) in DICOM coords.
     local_ijk:
     # type=bool|default=False: Output values as (i,j,k) in local orientation
     roi_vals:
     # type=list|default=[]: Compute center of mass for each blob with voxel value of v0, v1, v2, etc. This option is handy for getting ROI centers of mass.
     all_rois:
     # type=bool|default=False: Don't bother listing the values of ROIs you want: The program will find all of them and produce a full list
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -118,21 +115,21 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dCM
-    cm_file: '"cm.txt"'
+    cm_file:
     # type=file: file with the center of mass coordinates
     # type=file|default=<undefined>: File to write center of mass to
     roi_vals: '[2, 10]'
     # type=list|default=[]: Compute center of mass for each blob with voxel value of v0, v1, v2, etc. This option is handy for getting ROI centers of mass.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -147,17 +144,17 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dCM
-    cm_file: '"cm.txt"'
+    cm_file:
     # type=file: file with the center of mass coordinates
     # type=file|default=<undefined>: File to write center of mass to
     roi_vals: '[2, 10]'
     # type=list|default=[]: Compute center of mass for each blob with voxel value of v0, v1, v2, etc. This option is handy for getting ROI centers of mass.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/clip_level.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/clip_level.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -31,21 +31,18 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    grad: generic/file
-    # type=file|default=<undefined>: Also compute a 'gradual' clip level as a function of voxel position, and output that to a dataset.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dClipLevel
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    grad: generic/file
+    # type=file|default=<undefined>: Also compute a 'gradual' clip level as a function of voxel position, and output that to a dataset.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -54,16 +51,14 @@
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
-    clip_val: clip_val_callable
-    # type=float: output
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
@@ -77,15 +72,15 @@
     grad:
     # type=file|default=<undefined>: Also compute a 'gradual' clip level as a function of voxel position, and output that to a dataset.
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -97,15 +92,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dClipLevel
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -121,11 +116,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dClipLevel
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/convert_dset.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/convert_dset.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -2,146 +2,143 @@
 # 'nipype.interfaces.afni.utils.ConvertDset' from Nipype to Pydra.
 #
 # Please fill-in/edit the fields below where appropriate
 #
 # Docs
 # ----
 # Converts a surface dataset from one format to another.
-# 
+#
 #     For complete details, see the `ConvertDset Documentation.
 #     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/ConvertDset.html>`_
-# 
+#
 #     Examples
 #     --------
 #     >>> from nipype.interfaces import afni
 #     >>> convertdset = afni.ConvertDset()
 #     >>> convertdset.inputs.in_file = 'lh.pial_converted.gii'
 #     >>> convertdset.inputs.out_type = 'niml_asc'
 #     >>> convertdset.inputs.out_file = 'lh.pial_converted.niml.dset'
 #     >>> convertdset.cmdline
 #     'ConvertDset -o_niml_asc -input lh.pial_converted.gii -prefix lh.pial_converted.niml.dset'
 #     >>> res = convertdset.run()  # doctest: +SKIP
-# 
-#     
+#
+#
 task_name: ConvertDset
 nipype_name: ConvertDset
 nipype_module: nipype.interfaces.afni.utils
 inputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
-  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
-  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
-  # from the nipype interface, but you may want to be more specific, particularly
-  # for file types, where specifying the format also specifies the file that will be
-  # passed to the field in the automatically generated unittests.
+    # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
+    # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
+    # from the nipype interface, but you may want to be more specific, particularly
+    # for file types, where specifying the format also specifies the file that will be
+    # passed to the field in the automatically generated unittests.
     in_file: medimage/gifti
     # type=file|default=<undefined>: input file to ConvertDset
-    out_file: Path
+    out_file: medimage-afni/dset
     # type=file: output file
     # type=file|default=<undefined>: output file for ConvertDset
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
-  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
-  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
-  # from the nipype interface, but you may want to be more specific, particularly
-  # for file types, where specifying the format also specifies the file that will be
-  # passed to the field in the automatically generated unittests.
+    # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
+    # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
+    # from the nipype interface, but you may want to be more specific, particularly
+    # for file types, where specifying the format also specifies the file that will be
+    # passed to the field in the automatically generated unittests.
     out_file: medimage-afni/dset
     # type=file: output file
     # type=file|default=<undefined>: output file for ConvertDset
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
-- inputs:
-  # dict[str, str] - values to provide to inputs fields in the task initialisation
-  # (if not specified, will try to choose a sensible value)
-    in_file:
-    # type=file|default=<undefined>: input file to ConvertDset
-    out_file:
-    # type=file: output file
-    # type=file|default=<undefined>: output file for ConvertDset
-    out_type:
-    # type=enum|default='niml'|allowed['1D','1Dp','1Dpt','gii','gii_asc','gii_b64','gii_b64gz','niml','niml_asc','niml_bi']: output type
-    num_threads:
-    # type=int|default=1: set number of threads
-    outputtype:
-    # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
-    args:
-    # type=str|default='': Additional parameters to the command
-    environ:
-    # type=dict|default={}: Environment variables
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  expected_outputs:
-  # dict[str, str] - expected values for selected outputs, noting that tests will typically
-  # be terminated before they complete for time-saving reasons, and therefore
-  # these values will be ignored, when running in CI
-  timeout: 10
-  # int - the value to set for the timeout in the generated test, 
-  # after which the test will be considered to have been initialised 
-  # successfully. Set to 0 to disable the timeout (warning, this could
-  # lead to the unittests taking a very long time to complete)
-  xfail: true
-  # bool - whether the unittest is expected to fail or not. Set to false
-  # when you are satisfied with the edits you have made to this file
-- inputs:
-  # dict[str, str] - values to provide to inputs fields in the task initialisation
-  # (if not specified, will try to choose a sensible value)
-    in_file:
-    # type=file|default=<undefined>: input file to ConvertDset
-    out_type: '"niml_asc"'
-    # type=enum|default='niml'|allowed['1D','1Dp','1Dpt','gii','gii_asc','gii_b64','gii_b64gz','niml','niml_asc','niml_bi']: output type
-    out_file: '"lh.pial_converted.niml.dset"'
-    # type=file: output file
-    # type=file|default=<undefined>: output file for ConvertDset
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  expected_outputs:
-  # dict[str, str] - expected values for selected outputs, noting that tests will typically
-  # be terminated before they complete for time-saving reasons, and therefore
-  # these values will be ignored, when running in CI
-  timeout: 10
-  # int - the value to set for the timeout in the generated test, 
-  # after which the test will be considered to have been initialised 
-  # successfully. Set to 0 to disable the timeout (warning, this could
-  # lead to the unittests taking a very long time to complete)
-  xfail: true
-  # bool - whether the unittest is expected to fail or not. Set to false
-  # when you are satisfied with the edits you have made to this file
+  - inputs:
+      # dict[str, str] - values to provide to inputs fields in the task initialisation
+      # (if not specified, will try to choose a sensible value)
+      in_file:
+      # type=file|default=<undefined>: input file to ConvertDset
+      out_file:
+      # type=file: output file
+      # type=file|default=<undefined>: output file for ConvertDset
+      out_type:
+      # type=enum|default='niml'|allowed['1D','1Dp','1Dpt','gii','gii_asc','gii_b64','gii_b64gz','niml','niml_asc','niml_bi']: output type
+      num_threads:
+      # type=int|default=1: set number of threads
+      outputtype:
+      # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
+      args:
+      # type=str|default='': Additional parameters to the command
+      environ:
+      # type=dict|default={}: Environment variables
+    imports:
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+    # consisting of 'module', 'name', and optionally 'alias' keys
+    expected_outputs:
+    # dict[str, str] - expected values for selected outputs, noting that tests will typically
+    # be terminated before they complete for time-saving reasons, and therefore
+    # these values will be ignored, when running in CI
+    timeout: 10
+    # int - the value to set for the timeout in the generated test,
+    # after which the test will be considered to have been initialised
+    # successfully. Set to 0 to disable the timeout (warning, this could
+    # lead to the unittests taking a very long time to complete)
+    xfail: true
+    # bool - whether the unittest is expected to fail or not. Set to false
+    # when you are satisfied with the edits you have made to this file
+  - inputs:
+      # dict[str, str] - values to provide to inputs fields in the task initialisation
+      # (if not specified, will try to choose a sensible value)
+      in_file:
+      # type=file|default=<undefined>: input file to ConvertDset
+      out_type: '"niml_asc"'
+      # type=enum|default='niml'|allowed['1D','1Dp','1Dpt','gii','gii_asc','gii_b64','gii_b64gz','niml','niml_asc','niml_bi']: output type
+      out_file:
+      # type=file: output file
+      # type=file|default=<undefined>: output file for ConvertDset
+    imports:
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+    # consisting of 'module', 'name', and optionally 'alias' keys
+    expected_outputs:
+    # dict[str, str] - expected values for selected outputs, noting that tests will typically
+    # be terminated before they complete for time-saving reasons, and therefore
+    # these values will be ignored, when running in CI
+    timeout: 10
+    # int - the value to set for the timeout in the generated test,
+    # after which the test will be considered to have been initialised
+    # successfully. Set to 0 to disable the timeout (warning, this could
+    # lead to the unittests taking a very long time to complete)
+    xfail: true
+    # bool - whether the unittest is expected to fail or not. Set to false
+    # when you are satisfied with the edits you have made to this file
 doctests:
-- cmdline: ConvertDset -o_niml_asc -input lh.pial_converted.gii -prefix lh.pial_converted.niml.dset
-  # str - the expected cmdline output
-  inputs:
-  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
-  # If the field is of file-format type and the value is None, then the
-  # '.mock()' method of the corresponding class is used instead.
-    in_file:
-    # type=file|default=<undefined>: input file to ConvertDset
-    out_type: '"niml_asc"'
-    # type=enum|default='niml'|allowed['1D','1Dp','1Dpt','gii','gii_asc','gii_b64','gii_b64gz','niml','niml_asc','niml_bi']: output type
-    out_file: '"lh.pial_converted.niml.dset"'
-    # type=file: output file
-    # type=file|default=<undefined>: output file for ConvertDset
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  directive:
-  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
+  - cmdline: ConvertDset -o_niml_asc -input lh.pial_converted.gii -prefix lh.pial_converted.niml.dset
+    # str - the expected cmdline output
+    inputs:
+      # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
+      # If the field is of file-format type and the value is None, then the
+      # '.mock()' method of the corresponding class is used instead.
+      in_file:
+      # type=file|default=<undefined>: input file to ConvertDset
+      out_type: '"niml_asc"'
+      # type=enum|default='niml'|allowed['1D','1Dp','1Dpt','gii','gii_asc','gii_b64','gii_b64gz','niml','niml_asc','niml_bi']: output type
+      out_file:
+      # type=file: output file
+      # type=file|default=<undefined>: output file for ConvertDset
+    imports:
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+    # consisting of 'module', 'name', and optionally 'alias' keys
+    directive:
+    # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/copy.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/copy.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -52,20 +52,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dcopy
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -101,15 +98,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -121,15 +118,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dcopy
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -141,15 +138,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports: &id001
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   - module: copy
     name: deepcopy
     alias:
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
@@ -164,15 +161,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     outputtype: '"NIFTI_GZ"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -181,19 +178,19 @@
   # lead to the unittests taking a very long time to complete)
   xfail: true
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
-    out_file: '"new_func.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -209,51 +206,51 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dcopy
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dcopy functional.nii functional_copy.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports: *id001
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dcopy functional.nii functional_copy.nii.gz
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     outputtype: '"NIFTI_GZ"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dcopy functional.nii new_func.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
-    out_file: '"new_func.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/deconvolve.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/deconvolve.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -37,57 +37,54 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    STATmask: generic/file
-    # type=file|default=<undefined>: build a mask from provided file, and use this mask for the purpose of reporting truncation-to float issues AND for computing the FDR curves. The actual results ARE not masked with this option (only with 'mask' or 'automask' options).
-    censor: generic/file
-    # type=file|default=<undefined>: filename of censor .1D time series. This is a file of 1s and 0s, indicating which time points are to be included (1) and which are to be excluded (0).
     in_files: medimage/nifti1+list-of
     # type=inputmultiobject|default=[]: filenames of 3D+time input datasets. More than one filename can be given and the datasets will be auto-catenated in time. You can input a 1D time series file here, but the time axis should run along the ROW direction, not the COLUMN direction as in the 'input1D' option.
     input1D: generic/file
     # type=file|default=<undefined>: filename of single (fMRI) .1D time series where time runs down the column.
     mask: generic/file
     # type=file|default=<undefined>: filename of 3D mask dataset; only data time series from within the mask will be analyzed; results for voxels outside the mask will be set to zero.
-    out_file: Path
-    # type=file: output statistics file
-    # type=file|default=<undefined>: output statistics file
-    x1D: Path
+    STATmask: generic/file
+    # type=file|default=<undefined>: build a mask from provided file, and use this mask for the purpose of reporting truncation-to float issues AND for computing the FDR curves. The actual results ARE not masked with this option (only with 'mask' or 'automask' options).
+    censor: generic/file
+    # type=file|default=<undefined>: filename of censor .1D time series. This is a file of 1s and 0s, indicating which time points are to be included (1) and which are to be excluded (0).
+    x1D: medimage-afni/one-d
     # type=file: save out X matrix
     # type=file|default=<undefined>: specify name for saved X matrix
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: medimage/nifti1
+    # type=file: output statistics file
+    # type=file|default=<undefined>: output statistics file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    cbucket: generic/file
-    # type=file: output regression coefficients file (if generated)
-    # type=str|default='': Name for dataset in which to save the regression coefficients (no statistics). This dataset will be used in a -xrestore run [not yet implemented] instead of the bucket dataset, if possible.
     out_file: medimage/nifti1
     # type=file: output statistics file
     # type=file|default=<undefined>: output statistics file
     reml_script: generic/file
     # type=file: automatically generated script to run 3dREMLfit
     x1D: medimage-afni/one-d
     # type=file: save out X matrix
     # type=file|default=<undefined>: specify name for saved X matrix
+    cbucket: generic/file
+    # type=file: output regression coefficients file (if generated)
+    # type=str|default='': Name for dataset in which to save the regression coefficients (no statistics). This dataset will be used in a -xrestore run [not yet implemented] instead of the bucket dataset, if possible.
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -189,15 +186,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -208,30 +205,30 @@
     # bool - whether the unittest is expected to fail or not. Set to false
     # when you are satisfied with the edits you have made to this file
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_files:
       # type=inputmultiobject|default=[]: filenames of 3D+time input datasets. More than one filename can be given and the datasets will be auto-catenated in time. You can input a 1D time series file here, but the time axis should run along the ROW direction, not the COLUMN direction as in the 'input1D' option.
-      out_file: '"output.nii"'
+      out_file:
       # type=file: output statistics file
       # type=file|default=<undefined>: output statistics file
-      x1D: '"output.1D"'
+      x1D:
       # type=file: save out X matrix
       # type=file|default=<undefined>: specify name for saved X matrix
       stim_times: stim_times
       # type=list|default=[]: generate a response model from a set of stimulus times given in file.
       stim_label: '[(1, "Houses")]'
       # type=list|default=[]: label for kth input stimulus (e.g., Label1)
       gltsym: '["SYM: +Houses"]'
       # type=list|default=[]: general linear tests (i.e., contrasts) using symbolic conventions (e.g., '+Label1 -Label2')
       glt_label: '[(1, "Houses")]'
       # type=list|default=[]: general linear test (i.e., contrast) labels
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -246,26 +243,26 @@
     # str - the expected cmdline output
     inputs:
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       in_files:
       # type=inputmultiobject|default=[]: filenames of 3D+time input datasets. More than one filename can be given and the datasets will be auto-catenated in time. You can input a 1D time series file here, but the time axis should run along the ROW direction, not the COLUMN direction as in the 'input1D' option.
-      out_file: '"output.nii"'
+      out_file:
       # type=file: output statistics file
       # type=file|default=<undefined>: output statistics file
-      x1D: '"output.1D"'
+      x1D:
       # type=file: save out X matrix
       # type=file|default=<undefined>: specify name for saved X matrix
       stim_times: stim_times
       # type=list|default=[]: generate a response model from a set of stimulus times given in file.
       stim_label: '[(1, "Houses")]'
       # type=list|default=[]: label for kth input stimulus (e.g., Label1)
       gltsym: '["SYM: +Houses"]'
       # type=list|default=[]: general linear tests (i.e., contrasts) using symbolic conventions (e.g., '+Label1 -Label2')
       glt_label: '[(1, "Houses")]'
       # type=list|default=[]: general linear test (i.e., contrast) labels
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/degree_centrality.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/degree_centrality.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -38,20 +38,17 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dDegreeCentrality
     mask: medimage/nifti1
     # type=file|default=<undefined>: mask file to mask input data
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -103,15 +100,15 @@
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -126,19 +123,19 @@
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dDegreeCentrality
     mask:
     # type=file|default=<undefined>: mask file to mask input data
     sparsity: '1 # keep the top one percent of connections'
     # type=float|default=0.0: only take the top percent of connections
-    out_file: '"out.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -157,15 +154,15 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dDegreeCentrality
     mask:
     # type=file|default=<undefined>: mask file to mask input data
     sparsity: '1 # keep the top one percent of connections'
     # type=float|default=0.0: only take the top percent of connections
-    out_file: '"out.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/despike.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/despike.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -32,20 +32,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dDespike
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -79,15 +76,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -99,15 +96,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dDespike
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -123,11 +120,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dDespike
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/detrend.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/detrend.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -35,20 +35,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dDetrend
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -82,15 +79,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -106,15 +103,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dDetrend
     args: '"-polort 2"'
     # type=str|default='': Additional parameters to the command
     outputtype: '"AFNI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -134,11 +131,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dDetrend
     args: '"-polort 2"'
     # type=str|default='': Additional parameters to the command
     outputtype: '"AFNI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/dot.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/dot.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -36,24 +36,21 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    in_files: medimage/nifti1+list-of
+    in_files: medimage/nifti+list-of
     # type=list|default=[]: list of input files, possibly with subbrick selectors
-    mask: generic/file
-    # type=file|default=<undefined>: Use this dataset as a mask
-    out_file: Path
+    out_file: text/text-file
     # type=file: output file
     # type=file|default=<undefined>: collect output to a file
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    mask: generic/file
+    # type=file|default=<undefined>: Use this dataset as a mask
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -81,15 +78,15 @@
       # type=list|default=[]: list of input files, possibly with subbrick selectors
       out_file:
       # type=file: output file
       # type=file|default=<undefined>: collect output to a file
       mask:
       # type=file|default=<undefined>: Use this dataset as a mask
       mrange:
-      # type=tuple|default=(<traits.trait_types.Float object at 0x1155a6bd0>, <traits.trait_types.Float object at 0x1155a6ad0>): Means to further restrict the voxels from 'mset' so thatonly those mask values within this range (inclusive) willbe used.
+      # type=tuple|default=(<traits.trait_types.Float object at 0x112320d60>, <traits.trait_types.Float object at 0x112320dc0>): Means to further restrict the voxels from 'mset' so thatonly those mask values within this range (inclusive) willbe used.
       demean:
       # type=bool|default=False: Remove the mean from each volume prior to computing the correlation
       docor:
       # type=bool|default=False: Return the correlation coefficient (default).
       dodot:
       # type=bool|default=False: Return the dot product (unscaled).
       docoef:
@@ -111,15 +108,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -132,19 +129,19 @@
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_files:
       # type=list|default=[]: list of input files, possibly with subbrick selectors
       dodice: "True"
       # type=bool|default=False: Return the Dice coefficient (the Sorensen-Dice index).
-      out_file: '"out.mask_ae_dice.txt"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: collect output to a file
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -161,15 +158,15 @@
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       in_files:
       # type=list|default=[]: list of input files, possibly with subbrick selectors
       dodice: "True"
       # type=bool|default=False: Return the Dice coefficient (the Sorensen-Dice index).
-      out_file: '"out.mask_ae_dice.txt"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: collect output to a file
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/ecm.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/ecm.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -38,20 +38,17 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dECM
     mask: medimage/nifti1
     # type=file|default=<undefined>: mask file to mask input data
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -111,15 +108,15 @@
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -134,19 +131,19 @@
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dECM
     mask:
     # type=file|default=<undefined>: mask file to mask input data
     sparsity: '0.1 # keep top 0.1% of connections'
     # type=float|default=0.0: only take the top percent of connections
-    out_file: '"out.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -165,15 +162,15 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dECM
     mask:
     # type=file|default=<undefined>: mask file to mask input data
     sparsity: '0.1 # keep top 0.1% of connections'
     # type=float|default=0.0: only take the top percent of connections
-    out_file: '"out.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/edge_3.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/edge_3.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -35,20 +35,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dedge3
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -94,15 +91,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -113,21 +110,21 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dedge3
-    out_file: '"edges.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     datum: '"byte"'
     # type=enum|default='byte'|allowed['byte','float','short']: specify data type for output. Valid types are 'byte', 'short' and 'float'.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -142,17 +139,17 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dedge3
-    out_file: '"edges.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     datum: '"byte"'
     # type=enum|default='byte'|allowed['byte','float','short']: specify data type for output. Valid types are 'byte', 'short' and 'float'.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/eval.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/eval.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -41,22 +41,19 @@
     # passed to the field in the automatically generated unittests.
     in_file_a: medimage-afni/one-d
     # type=file|default=<undefined>: input file to 1deval
     in_file_b: medimage-afni/one-d
     # type=file|default=<undefined>: operand file to 1deval
     in_file_c: generic/file
     # type=file|default=<undefined>: operand file to 1deval
-    other: generic/file
-    # type=file|default=<undefined>: other options
-    out_file: Path
+    out_file: medimage-afni/one-d
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    other: generic/file
+    # type=file|default=<undefined>: other options
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -106,15 +103,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -131,19 +128,19 @@
       # type=file|default=<undefined>: input file to 1deval
       in_file_b:
       # type=file|default=<undefined>: operand file to 1deval
       expr: '"a*b"'
       # type=str|default='': expr
       out1D: "True"
       # type=bool|default=False: output in 1D
-      out_file: ' "data_calc.1D"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -164,15 +161,15 @@
       # type=file|default=<undefined>: input file to 1deval
       in_file_b:
       # type=file|default=<undefined>: operand file to 1deval
       expr: '"a*b"'
       # type=str|default='': expr
       out1D: "True"
       # type=bool|default=False: output in 1D
-      out_file: ' "data_calc.1D"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fim.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fim.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -35,24 +35,21 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    ideal_file: medimage-afni/one-d
-    # type=file|default=<undefined>: ideal time series file name
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dfim+
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    ideal_file: medimage-afni/one-d
+    # type=file|default=<undefined>: ideal time series file name
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -92,15 +89,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -113,23 +110,23 @@
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_file:
       # type=file|default=<undefined>: input file to 3dfim+
       ideal_file:
       # type=file|default=<undefined>: ideal time series file name
-      out_file: '"functional_corr.nii"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
       out: '"Correlation"'
       # type=str|default='': Flag to output the specified parameter
       fim_thr: "0.0009"
       # type=float|default=0.0: fim internal mask threshold value
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -146,19 +143,19 @@
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       in_file:
       # type=file|default=<undefined>: input file to 3dfim+
       ideal_file:
       # type=file|default=<undefined>: ideal time series file name
-      out_file: '"functional_corr.nii"'
+      out_file:
       # type=file: output file
       # type=file|default=<undefined>: output image file name
       out: '"Correlation"'
       # type=str|default='': Flag to output the specified parameter
       fim_thr: "0.0009"
       # type=float|default=0.0: fim internal mask threshold value
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fourier.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fourier.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -36,20 +36,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dFourier
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -89,15 +86,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -115,15 +112,15 @@
     retrend: 'True'
     # type=bool|default=False: Any mean and linear trend are removed before filtering. This will restore the trend after filtering.
     highpass: '0.005'
     # type=float|default=0.0: highpass
     lowpass: '0.1'
     # type=float|default=0.0: lowpass
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -145,11 +142,11 @@
     retrend: 'True'
     # type=bool|default=False: Any mean and linear trend are removed before filtering. This will restore the trend after filtering.
     highpass: '0.005'
     # type=float|default=0.0: highpass
     lowpass: '0.1'
     # type=float|default=0.0: lowpass
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/fwh_mx.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/fwh_mx.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -111,59 +111,52 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset
-    mask: generic/file
-    # type=file|default=<undefined>: use only voxels that are nonzero in mask
-    out_detrend: Path
-    # type=file: output file, detrended
-    # type=file|default=<undefined>: Save the detrended file into a dataset
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output file
-    out_subbricks: Path
+    out_subbricks: generic/file
     # type=file: output file (subbricks)
     # type=file|default=<undefined>: output file listing the subbricks FWHM
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    mask: generic/file
+    # type=file|default=<undefined>: use only voxels that are nonzero in mask
+    out_detrend: generic/file
+    # type=file: output file, detrended
+    # type=file|default=<undefined>: Save the detrended file into a dataset
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_acf: generic/file
-    # type=file: output acf file
-    out_detrend: generic/file
-    # type=file: output file, detrended
-    # type=file|default=<undefined>: Save the detrended file into a dataset
     out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output file
     out_subbricks: generic/file
     # type=file: output file (subbricks)
     # type=file|default=<undefined>: output file listing the subbricks FWHM
+    out_detrend: generic/file
+    # type=file: output file, detrended
+    # type=file|default=<undefined>: Save the detrended file into a dataset
+    out_acf: generic/file
+    # type=file: output acf file
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
-    acf_param: acf_param_callable
-    # type=traitcompound: fitted ACF model parameters
-    fwhm: fwhm_callable
-    # type=traitcompound: FWHM along each axis
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
@@ -200,15 +193,15 @@
     acf:
     # type=traitcompound|default=False: computes the spatial autocorrelation
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -220,15 +213,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -244,11 +237,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/gcor.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/gcor.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -38,17 +38,14 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset to compute the GCOR over
     mask: generic/file
     # type=file|default=<undefined>: mask dataset, for restricting the computation
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -57,16 +54,14 @@
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
-    out: out_callable
-    # type=float: global correlation value
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
@@ -80,15 +75,15 @@
     no_demean:
     # type=bool|default=False: do not (need to) demean as first step
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -102,15 +97,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset to compute the GCOR over
     nfirst: '4'
     # type=int|default=0: specify number of initial TRs to ignore
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -128,11 +123,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset to compute the GCOR over
     nfirst: '4'
     # type=int|default=0: specify number of initial TRs to ignore
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/hist.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/hist.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -33,25 +33,22 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dHist
-    mask: generic/file
-    # type=file|default=<undefined>: matrix to align input file
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: Write histogram to niml file with this prefix
-    out_show: Path
+    out_show: generic/file
     # type=file: output visual histogram
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    mask: generic/file
+    # type=file|default=<undefined>: matrix to align input file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -99,15 +96,15 @@
     bin_width:
     # type=float|default=0.0: bin width
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -119,15 +116,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dHist
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -143,11 +140,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dHist
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/lfcd.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/lfcd.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -37,20 +37,17 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dLFCD
     mask: medimage/nifti1
     # type=file|default=<undefined>: mask file to mask input data
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -94,15 +91,15 @@
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -117,19 +114,19 @@
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dLFCD
     mask:
     # type=file|default=<undefined>: mask file to mask input data
     thresh: '0.8 # keep all connections with corr >= 0.8'
     # type=float|default=0.0: threshold to exclude connections where corr <= thresh
-    out_file: '"out.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -148,15 +145,15 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dLFCD
     mask:
     # type=file|default=<undefined>: mask file to mask input data
     thresh: '0.8 # keep all connections with corr >= 0.8'
     # type=float|default=0.0: threshold to exclude connections where corr <= thresh
-    out_file: '"out.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/local_bistat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/local_bistat.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -39,24 +39,23 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file1: medimage/nifti1
     # type=file|default=<undefined>: Filename of the first image
     in_file2: medimage/nifti1
     # type=file|default=<undefined>: Filename of the second image
+    stat: generic/file+list-of
+    # type=inputmultiobject|default=[]: Statistics to compute. Possible names are:    * pearson  = Pearson correlation coefficient   * spearman = Spearman correlation coefficient   * quadrant = Quadrant correlation coefficient   * mutinfo  = Mutual Information   * normuti  = Normalized Mutual Information   * jointent = Joint entropy   * hellinger= Hellinger metric   * crU      = Correlation ratio (Unsymmetric)   * crM      = Correlation ratio (symmetrized by Multiplication)   * crA      = Correlation ratio (symmetrized by Addition)   * L2slope  = slope of least-squares (L2) linear regression of                the data from dataset1 vs. the dataset2                (i.e., d2 = a + b*d1 ==> this is 'b')   * L1slope  = slope of least-absolute-sum (L1) linear                regression of the data from dataset1 vs.                the dataset2   * num      = number of the values in the region:                with the use of -mask or -automask,                the size of the region around any given                voxel will vary; this option lets you                map that size.   * ALL      = all of the above, in that order  More than one option can be used.
     mask_file: generic/file
     # type=file|default=<undefined>: mask image file name. Voxels NOT in the mask will not be used in the neighborhood of any voxel. Also, a voxel NOT in the mask will have its statistic(s) computed as zero (0).
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: Output dataset.
     weight_file: generic/file
     # type=file|default=<undefined>: File name of an image to use as a weight.  Only applies to 'pearson' statistics.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: generic/file
+    # type=file: output file
+    # type=file|default=<undefined>: Output dataset.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -102,15 +101,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -125,20 +124,20 @@
   # (if not specified, will try to choose a sensible value)
     in_file1:
     # type=file|default=<undefined>: Filename of the first image
     in_file2:
     # type=file|default=<undefined>: Filename of the second image
     neighborhood: ("SPHERE", 1.2)
     # type=traitcompound|default=None: The region around each voxel that will be extracted for the statistics calculation. Possible regions are: 'SPHERE', 'RHDD' (rhombic dodecahedron), 'TOHD' (truncated octahedron) with a given radius in mm or 'RECT' (rectangular block) with dimensions to specify in mm.
-    stat: '"pearson"'
+    stat:
     # type=inputmultiobject|default=[]: Statistics to compute. Possible names are:    * pearson  = Pearson correlation coefficient   * spearman = Spearman correlation coefficient   * quadrant = Quadrant correlation coefficient   * mutinfo  = Mutual Information   * normuti  = Normalized Mutual Information   * jointent = Joint entropy   * hellinger= Hellinger metric   * crU      = Correlation ratio (Unsymmetric)   * crM      = Correlation ratio (symmetrized by Multiplication)   * crA      = Correlation ratio (symmetrized by Addition)   * L2slope  = slope of least-squares (L2) linear regression of                the data from dataset1 vs. the dataset2                (i.e., d2 = a + b*d1 ==> this is 'b')   * L1slope  = slope of least-absolute-sum (L1) linear                regression of the data from dataset1 vs.                the dataset2   * num      = number of the values in the region:                with the use of -mask or -automask,                the size of the region around any given                voxel will vary; this option lets you                map that size.   * ALL      = all of the above, in that order  More than one option can be used.
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -157,16 +156,16 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file1:
     # type=file|default=<undefined>: Filename of the first image
     in_file2:
     # type=file|default=<undefined>: Filename of the second image
     neighborhood: ("SPHERE", 1.2)
     # type=traitcompound|default=None: The region around each voxel that will be extracted for the statistics calculation. Possible regions are: 'SPHERE', 'RHDD' (rhombic dodecahedron), 'TOHD' (truncated octahedron) with a given radius in mm or 'RECT' (rectangular block) with dimensions to specify in mm.
-    stat: '"pearson"'
+    stat:
     # type=inputmultiobject|default=[]: Statistics to compute. Possible names are:    * pearson  = Pearson correlation coefficient   * spearman = Spearman correlation coefficient   * quadrant = Quadrant correlation coefficient   * mutinfo  = Mutual Information   * normuti  = Normalized Mutual Information   * jointent = Joint entropy   * hellinger= Hellinger metric   * crU      = Correlation ratio (Unsymmetric)   * crM      = Correlation ratio (symmetrized by Multiplication)   * crA      = Correlation ratio (symmetrized by Addition)   * L2slope  = slope of least-squares (L2) linear regression of                the data from dataset1 vs. the dataset2                (i.e., d2 = a + b*d1 ==> this is 'b')   * L1slope  = slope of least-absolute-sum (L1) linear                regression of the data from dataset1 vs.                the dataset2   * num      = number of the values in the region:                with the use of -mask or -automask,                the size of the region around any given                voxel will vary; this option lets you                map that size.   * ALL      = all of the above, in that order  More than one option can be used.
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/localstat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/localstat.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -38,22 +38,21 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset
+    stat: generic/file+list-of
+    # type=inputmultiobject|default=[]: statistics to compute. Possible names are:   * mean   = average of the values  * stdev  = standard deviation  * var    = variance (stdev\*stdev)  * cvar   = coefficient of variation = stdev/fabs(mean)  * median = median of the values  * MAD    = median absolute deviation  * min    = minimum  * max    = maximum  * absmax = maximum of the absolute values  * num    = number of the values in the region:             with the use of -mask or -automask,             the size of the region around any given             voxel will vary; this option lets you             map that size.  It may be useful if you             plan to compute a t-statistic (say) from             the mean and stdev outputs.  * sum    = sum of the values in the region  * FWHM   = compute (like 3dFWHM) image smoothness             inside each voxel's neighborhood.  Results             are in 3 sub-bricks: FWHMx, FHWMy, and FWHMz.             Places where an output is -1 are locations             where the FWHM value could not be computed             (e.g., outside the mask).  * FWHMbar= Compute just the average of the 3 FWHM values             (normally would NOT do this with FWHM also).  * perc:P0:P1:Pstep =             Compute percentiles between P0 and P1 with a             step of Pstep.             Default P1 is equal to P0 and default P2 = 1  * rank   = rank of the voxel's intensity  * frank  = rank / number of voxels in neighborhood  * P2skew = Pearson's second skewness coefficient              3 \* (mean - median) / stdev  * ALL    = all of the above, in that order             (except for FWHMbar and perc).  * mMP2s  = Exactly the same output as:             median, MAD, P2skew,             but a little faster  * mmMP2s = Exactly the same output as:             mean, median, MAD, P2skew  More than one option can be used.
     mask_file: medimage/nifti-gz
     # type=file|default=<undefined>: Mask image file name. Voxels NOT in the mask will not be used in the neighborhood of any voxel. Also, a voxel NOT in the mask will have its statistic(s) computed as zero (0) unless the parameter 'nonmask' is set to true.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: Output dataset.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -109,15 +108,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -132,22 +131,22 @@
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset
     mask_file:
     # type=file|default=<undefined>: Mask image file name. Voxels NOT in the mask will not be used in the neighborhood of any voxel. Also, a voxel NOT in the mask will have its statistic(s) computed as zero (0) unless the parameter 'nonmask' is set to true.
     neighborhood: ("SPHERE", 45)
     # type=traitcompound|default=None: The region around each voxel that will be extracted for the statistics calculation. Possible regions are: 'SPHERE', 'RHDD' (rhombic dodecahedron), 'TOHD' (truncated octahedron) with a given radius in mm or 'RECT' (rectangular block) with dimensions to specify in mm.
-    stat: '"mean"'
+    stat:
     # type=inputmultiobject|default=[]: statistics to compute. Possible names are:   * mean   = average of the values  * stdev  = standard deviation  * var    = variance (stdev\*stdev)  * cvar   = coefficient of variation = stdev/fabs(mean)  * median = median of the values  * MAD    = median absolute deviation  * min    = minimum  * max    = maximum  * absmax = maximum of the absolute values  * num    = number of the values in the region:             with the use of -mask or -automask,             the size of the region around any given             voxel will vary; this option lets you             map that size.  It may be useful if you             plan to compute a t-statistic (say) from             the mean and stdev outputs.  * sum    = sum of the values in the region  * FWHM   = compute (like 3dFWHM) image smoothness             inside each voxel's neighborhood.  Results             are in 3 sub-bricks: FWHMx, FHWMy, and FWHMz.             Places where an output is -1 are locations             where the FWHM value could not be computed             (e.g., outside the mask).  * FWHMbar= Compute just the average of the 3 FWHM values             (normally would NOT do this with FWHM also).  * perc:P0:P1:Pstep =             Compute percentiles between P0 and P1 with a             step of Pstep.             Default P1 is equal to P0 and default P2 = 1  * rank   = rank of the voxel's intensity  * frank  = rank / number of voxels in neighborhood  * P2skew = Pearson's second skewness coefficient              3 \* (mean - median) / stdev  * ALL    = all of the above, in that order             (except for FWHMbar and perc).  * mMP2s  = Exactly the same output as:             median, MAD, P2skew,             but a little faster  * mmMP2s = Exactly the same output as:             mean, median, MAD, P2skew  More than one option can be used.
     nonmask: 'True'
     # type=bool|default=False: Voxels not in the mask WILL have their local statistics computed from all voxels in their neighborhood that ARE in the mask. For instance, this option can be used to compute the average local white matter time series, even at non-WM voxels.
     outputtype: '"NIFTI_GZ"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -166,18 +165,18 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset
     mask_file:
     # type=file|default=<undefined>: Mask image file name. Voxels NOT in the mask will not be used in the neighborhood of any voxel. Also, a voxel NOT in the mask will have its statistic(s) computed as zero (0) unless the parameter 'nonmask' is set to true.
     neighborhood: ("SPHERE", 45)
     # type=traitcompound|default=None: The region around each voxel that will be extracted for the statistics calculation. Possible regions are: 'SPHERE', 'RHDD' (rhombic dodecahedron), 'TOHD' (truncated octahedron) with a given radius in mm or 'RECT' (rectangular block) with dimensions to specify in mm.
-    stat: '"mean"'
+    stat:
     # type=inputmultiobject|default=[]: statistics to compute. Possible names are:   * mean   = average of the values  * stdev  = standard deviation  * var    = variance (stdev\*stdev)  * cvar   = coefficient of variation = stdev/fabs(mean)  * median = median of the values  * MAD    = median absolute deviation  * min    = minimum  * max    = maximum  * absmax = maximum of the absolute values  * num    = number of the values in the region:             with the use of -mask or -automask,             the size of the region around any given             voxel will vary; this option lets you             map that size.  It may be useful if you             plan to compute a t-statistic (say) from             the mean and stdev outputs.  * sum    = sum of the values in the region  * FWHM   = compute (like 3dFWHM) image smoothness             inside each voxel's neighborhood.  Results             are in 3 sub-bricks: FWHMx, FHWMy, and FWHMz.             Places where an output is -1 are locations             where the FWHM value could not be computed             (e.g., outside the mask).  * FWHMbar= Compute just the average of the 3 FWHM values             (normally would NOT do this with FWHM also).  * perc:P0:P1:Pstep =             Compute percentiles between P0 and P1 with a             step of Pstep.             Default P1 is equal to P0 and default P2 = 1  * rank   = rank of the voxel's intensity  * frank  = rank / number of voxels in neighborhood  * P2skew = Pearson's second skewness coefficient              3 \* (mean - median) / stdev  * ALL    = all of the above, in that order             (except for FWHMbar and perc).  * mMP2s  = Exactly the same output as:             median, MAD, P2skew,             but a little faster  * mmMP2s = Exactly the same output as:             mean, median, MAD, P2skew  More than one option can be used.
     nonmask: 'True'
     # type=bool|default=False: Voxels not in the mask WILL have their local statistics computed from all voxels in their neighborhood that ARE in the mask. For instance, this option can be used to compute the average local white matter time series, even at non-WM voxels.
     outputtype: '"NIFTI_GZ"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/mask_tool.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/mask_tool.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -33,20 +33,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1+list-of
     # type=inputmultiobject|default=[]: input file or files to 3dmask_tool
-    out_file: Path
+    out_file: generic/file
     # type=file: mask file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -100,15 +97,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -122,15 +119,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=inputmultiobject|default=[]: input file or files to 3dmask_tool
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -148,11 +145,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=inputmultiobject|default=[]: input file or files to 3dmask_tool
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/maskave.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/maskave.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -35,22 +35,19 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dmaskave
-    mask: medimage/nifti1
-    # type=file|default=<undefined>: matrix to align input file
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    mask: medimage/nifti1
+    # type=file|default=<undefined>: matrix to align input file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -88,15 +85,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -112,15 +109,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dmaskave
     mask:
     # type=file|default=<undefined>: matrix to align input file
     quiet: 'True'
     # type=bool|default=False: matrix to align input file
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -140,11 +137,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dmaskave
     mask:
     # type=file|default=<undefined>: matrix to align input file
     quiet: 'True'
     # type=bool|default=False: matrix to align input file
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/means.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/means.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -45,20 +45,17 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file_a: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dMean
     in_file_b: medimage/nifti1
     # type=file|default=<undefined>: another input file to 3dMean
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -112,15 +109,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -133,19 +130,19 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file_a:
     # type=file|default=<undefined>: input file to 3dMean
     in_file_b:
     # type=file|default=<undefined>: another input file to 3dMean
-    out_file: ' "output.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -156,21 +153,21 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file_a:
     # type=file|default=<undefined>: input file to 3dMean
-    out_file: ' "output.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     datum: '"short"'
     # type=str|default='': Sets the data type of the output dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -187,33 +184,33 @@
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file_a:
     # type=file|default=<undefined>: input file to 3dMean
     in_file_b:
     # type=file|default=<undefined>: another input file to 3dMean
-    out_file: ' "output.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dMean -datum short -prefix output.nii im1.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file_a:
     # type=file|default=<undefined>: input file to 3dMean
-    out_file: ' "output.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     datum: '"short"'
     # type=str|default='': Sets the data type of the output dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/merge.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/merge.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -35,20 +35,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_files: medimage/nifti1+list-of
     # type=inputmultiobject|default=[]: 
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -86,15 +83,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -109,19 +106,19 @@
   # (if not specified, will try to choose a sensible value)
     in_files:
     # type=inputmultiobject|default=[]: 
     blurfwhm: '4'
     # type=int|default=0: FWHM blur value (mm)
     doall: 'True'
     # type=bool|default=False: apply options to all sub-bricks in dataset
-    out_file: '"e7.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -140,15 +137,15 @@
   # '.mock()' method of the corresponding class is used instead.
     in_files:
     # type=inputmultiobject|default=[]: 
     blurfwhm: '4'
     # type=int|default=0: FWHM blur value (mm)
     doall: 'True'
     # type=bool|default=False: apply options to all sub-bricks in dataset
-    out_file: '"e7.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/net_corr.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/net_corr.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -43,36 +43,31 @@
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input time series file (4D data set)
     in_rois: medimage/nifti1
     # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
     mask: medimage/nifti1
     # type=file|default=<undefined>: can include a whole brain mask within which to calculate correlation. Otherwise, data should be masked already
-    out_file: Path
-    # type=file|default=<undefined>: output file name part
     weight_ts: generic/file
     # type=file|default=<undefined>: input a 1D file WTS of weights that will be applied multiplicatively to each ROI's average time series. WTS can be a column- or row-file of values, but it must have the same length as the input time series volume. If the initial average time series was A[n] for n=0,..,(N-1) time points, then applying a set of weights W[n] of the same length from WTS would produce a new time series:  B[n] = A[n] * W[n]
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: medimage-afni/n-corr
+    # type=file|default=<undefined>: output file name part
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_corr_maps: generic/file+list-of
-    # type=list: output correlation maps in Pearson and/or Z-scores
     out_corr_matrix: generic/file
     # type=file: output correlation matrix between ROIs written to a text file with .netcc suffix
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
@@ -121,15 +116,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -150,18 +145,18 @@
     # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
     ts_wb_corr: 'True'
     # type=bool|default=False: switch to create a set of whole brain correlation maps. Performs whole brain correlation for each ROI's average time series; this will automatically create a directory for each network that contains the set of whole brain correlation maps (Pearson 'r's). The directories are labelled as above for '-ts_indiv' Within each directory, the files are labelled WB_CORR_ROI_001+orig, WB_CORR_ROI_002+orig, etc., with the numbers given by the actual ROI integer labels
     ts_wb_Z: 'True'
     # type=bool|default=False: same as above in '-ts_wb_corr', except that the maps have been Fisher transformed to Z-scores the relation: Z=atanh(r). To avoid infinities in the transform, Pearson values are effectively capped at |r| = 0.999329 (where |Z| = 4.0). Files are labelled WB_Z_ROI_001+orig, etc
     fish_z: 'True'
     # type=bool|default=False: switch to also output a matrix of Fisher Z-transform values for the corr coefs (r): Z = atanh(r) , (with Z=4 being output along matrix diagonals where r=1, as the r-to-Z conversion is ceilinged at Z = atanh(r=0.999329) = 4, which is still *quite* a high Pearson-r value
-    out_file: '"sub0.tp1.ncorr"'
+    out_file:
     # type=file|default=<undefined>: output file name part
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -186,14 +181,14 @@
     # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
     ts_wb_corr: 'True'
     # type=bool|default=False: switch to create a set of whole brain correlation maps. Performs whole brain correlation for each ROI's average time series; this will automatically create a directory for each network that contains the set of whole brain correlation maps (Pearson 'r's). The directories are labelled as above for '-ts_indiv' Within each directory, the files are labelled WB_CORR_ROI_001+orig, WB_CORR_ROI_002+orig, etc., with the numbers given by the actual ROI integer labels
     ts_wb_Z: 'True'
     # type=bool|default=False: same as above in '-ts_wb_corr', except that the maps have been Fisher transformed to Z-scores the relation: Z=atanh(r). To avoid infinities in the transform, Pearson values are effectively capped at |r| = 0.999329 (where |Z| = 4.0). Files are labelled WB_Z_ROI_001+orig, etc
     fish_z: 'True'
     # type=bool|default=False: switch to also output a matrix of Fisher Z-transform values for the corr coefs (r): Z = atanh(r) , (with Z=4 being output along matrix diagonals where r=1, as the r-to-Z conversion is ceilinged at Z = atanh(r=0.999329) = 4, which is still *quite* a high Pearson-r value
-    out_file: '"sub0.tp1.ncorr"'
+    out_file:
     # type=file|default=<undefined>: output file name part
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/notes.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/notes.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -34,20 +34,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage-afni/head
     # type=file|default=<undefined>: input file to 3dNotes
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -91,15 +88,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -115,15 +112,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dNotes
     add: '"This note is added."'
     # type=str|default='': note to add
     add_history: '"This note is added to history."'
     # type=str|default='': note to add to history
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -143,11 +140,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dNotes
     add: '"This note is added."'
     # type=str|default='': note to add
     add_history: '"This note is added to history."'
     # type=str|default='': note to add to history
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_adjust.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_adjust.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -35,24 +35,21 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    warps: medimage/nifti-gz+list-of
+    # type=inputmultiobject|default=[]: List of input 3D warp datasets
     in_files: generic/file+list-of
     # type=inputmultiobject|default=[]: List of input 3D datasets to be warped by the adjusted warp datasets.  There must be exactly as many of these datasets as there are input warps.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: Output mean dataset, only needed if in_files are also given. The output dataset will be on the common grid shared by the source datasets.
-    warps: medimage/nifti-gz+list-of
-    # type=inputmultiobject|default=[]: List of input 3D warp datasets
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -88,15 +85,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -108,15 +105,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     warps:
     # type=inputmultiobject|default=[]: List of input 3D warp datasets
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -132,11 +129,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     warps:
     # type=inputmultiobject|default=[]: List of input 3D warp datasets
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_apply.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_apply.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -36,20 +36,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     master: generic/file
     # type=file|default=<undefined>: the name of the master dataset, which defines the output grid
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -95,15 +92,15 @@
     verb:
     # type=bool|default=False: be extra verbose :)
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -119,15 +116,15 @@
     in_file: '"Fred+orig"'
     # type=traitcompound|default=None: the name of the dataset to be warped can be multiple datasets
     master:
     # type=file|default=<undefined>: the name of the master dataset, which defines the output grid
     warp: '"''Fred_WARP+tlrc Fred.Xaff12.1D''"'
     # type=string|default='': the name of the warp dataset. multiple warps can be concatenated (make sure they exist)
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -147,11 +144,11 @@
     in_file: '"Fred+orig"'
     # type=traitcompound|default=None: the name of the dataset to be warped can be multiple datasets
     master:
     # type=file|default=<undefined>: the name of the master dataset, which defines the output grid
     warp: '"''Fred_WARP+tlrc Fred.Xaff12.1D''"'
     # type=string|default='': the name of the warp dataset. multiple warps can be concatenated (make sure they exist)
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/nwarp_cat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/nwarp_cat.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -65,20 +65,17 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -122,15 +119,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -141,19 +138,19 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_files: '["Q25_warp+tlrc.HEAD", ("IDENT", "structural.nii")]'
     # type=list|default=[]: list of tuples of 3D warps and associated functions
-    out_file: '"Fred_total_WARP"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -168,15 +165,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_files: '["Q25_warp+tlrc.HEAD", ("IDENT", "structural.nii")]'
     # type=list|default=[]: list of tuples of 3D warps and associated functions
-    out_file: '"Fred_total_WARP"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/one_d_tool_py.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/one_d_tool_py.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -29,22 +29,19 @@
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
     in_file: medimage-afni/one-d
     # type=file|default=<undefined>: input file to OneDTool
-    out_file: Path
+    out_file: medimage-afni/one-d
     # type=file: output of 1D_tool.py
     # type=file|default=<undefined>: write the current 1D data to FILE
     show_cormat_warnings: generic/file
     # type=file|default=<undefined>: Write cormat warnings to a file
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -78,15 +75,15 @@
       # type=bool|default=False: demean each run (new mean of each run = 0.0)
       out_file:
       # type=file: output of 1D_tool.py
       # type=file|default=<undefined>: write the current 1D data to FILE
       show_censor_count:
       # type=bool|default=False: display the total number of censored TRs  Note : if input is a valid xmat.1D dataset, then the count will come from the header.  Otherwise the input is assumed to be a binary censorfile, and zeros are simply counted.
       censor_motion:
-      # type=tuple|default=(<traits.trait_types.Float object at 0x1155ce990>, <nipype.interfaces.base.traits_extension.File object at 0x1155cea50>): Tuple of motion limit and outfile prefix. need to also set set_nruns -r set_run_lengths
+      # type=tuple|default=(<traits.trait_types.Float object at 0x111924a00>, <nipype.interfaces.base.traits_extension.File object at 0x1119248b0>): Tuple of motion limit and outfile prefix. need to also set set_nruns -r set_run_lengths
       censor_prev_TR:
       # type=bool|default=False: for each censored TR, also censor previous
       show_trs_uncensored:
       # type=enum|default='comma'|allowed['comma','encoded','space','verbose']: display a list of TRs which were not censored in the specified style
       show_cormat_warnings:
       # type=file|default=<undefined>: Write cormat warnings to a file
       show_indices_interest:
@@ -98,15 +95,15 @@
       py27_path:
       # type=traitcompound|default='python2':
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -121,19 +118,19 @@
       # (if not specified, will try to choose a sensible value)
       in_file:
       # type=file|default=<undefined>: input file to OneDTool
       set_nruns: "3"
       # type=int|default=0: treat the input data as if it has nruns
       demean: "True"
       # type=bool|default=False: demean each run (new mean of each run = 0.0)
-      out_file: '"motion_dmean.1D"'
+      out_file:
       # type=file: output of 1D_tool.py
       # type=file|default=<undefined>: write the current 1D data to FILE
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -152,15 +149,15 @@
       # '.mock()' method of the corresponding class is used instead.
       in_file:
       # type=file|default=<undefined>: input file to OneDTool
       set_nruns: "3"
       # type=int|default=0: treat the input data as if it has nruns
       demean: "True"
       # type=bool|default=False: demean each run (new mean of each run = 0.0)
-      out_file: '"motion_dmean.1D"'
+      out_file:
       # type=file: output of 1D_tool.py
       # type=file|default=<undefined>: write the current 1D data to FILE
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/outlier_count.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/outlier_count.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -35,40 +35,37 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset
     mask: generic/file
     # type=file|default=<undefined>: only count voxels within the given mask
-    out_file: Path
-    # type=file: capture standard output
-    # type=file|default=<undefined>: capture standard output
     outliers_file: generic/file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: generic/file
+    # type=file: capture standard output
+    # type=file|default=<undefined>: capture standard output
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    out_outliers: generic/file
+    # type=file: output image file name
     out_file: generic/file
     # type=file: capture standard output
     # type=file|default=<undefined>: capture standard output
-    out_outliers: generic/file
-    # type=file: output image file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -102,15 +99,15 @@
     # type=file: capture standard output
     # type=file|default=<undefined>: capture standard output
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -122,15 +119,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -146,11 +143,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/quality_index.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/quality_index.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -38,20 +38,17 @@
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset
     mask: generic/file
     # type=file|default=<undefined>: compute correlation only across masked voxels
-    out_file: Path
+    out_file: generic/file
     # type=file: file containing the captured standard output
     # type=file|default=<undefined>: capture standard output
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -95,15 +92,15 @@
     # type=file: file containing the captured standard output
     # type=file|default=<undefined>: capture standard output
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -115,15 +112,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -139,11 +136,11 @@
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/qwarp.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarp.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -105,54 +105,51 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    in_file: medimage/nifti1,medimage/nifti-gz
+    # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file: medimage/nifti1,medimage/nifti-gz
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
+    out_file: medimage/nifti-gz
+    # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
+    weight: generic/file
+    # type=file|default=<undefined>: Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.
+    out_weight_file: generic/file
+    # type=file|default=<undefined>: Write the weight volume to disk as a dataset
     emask: generic/file
     # type=file|default=<undefined>: Here, 'ee' is a dataset to specify a mask of voxelsto EXCLUDE from the analysis -- all voxels in 'ee'that are NONZERO will not be used in the alignment.The base image always automasked -- the emask isextra, to indicate voxels you definitely DON'T wantincluded in the matching process, even if they areinside the brain.
-    gridlist: generic/file
-    # type=file|default=<undefined>: This option provides an alternate way to specify the patch grid sizes used in the warp optimization process. 'gl' is a 1D file with a list of patches to use -- in most cases, you will want to use it in the following form: ``-gridlist '1D: 0 151 101 75 51'``  * Here, a 0 patch size means the global domain. Patch sizes   otherwise should be odd integers >= 5. * If you use the '0' patch size again after the first position,   you will actually get an iteration at the size of the   default patch level 1, where the patch sizes are 75% of   the volume dimension.  There is no way to force the program   to literally repeat the sui generis step of lev=0.  
-    in_file: medimage/nifti1,medimage/nifti-gz
-    # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     iniwarp: medimage-afni/head+list-of
     # type=list|default=[]: A dataset with an initial nonlinear warp to use.  * If this option is not used, the initial warp is the identity. * You can specify a catenation of warps (in quotes) here, as in   program 3dNwarpApply. * As a special case, if you just input an affine matrix in a .1D   file, that will work also -- it is treated as giving the initial   warp via the string "IDENT(base_dataset) matrix_file.aff12.1D". * You CANNOT use this option with -duplo !! * -iniwarp is usually used with -inilev to re-start 3dQwarp from   a previous stopping point.  
-    out_file: Path
-    # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
-    out_weight_file: Path
-    # type=file|default=<undefined>: Write the weight volume to disk as a dataset
-    weight: generic/file
-    # type=file|default=<undefined>: Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    gridlist: generic/file
+    # type=file|default=<undefined>: This option provides an alternate way to specify the patch grid sizes used in the warp optimization process. 'gl' is a 1D file with a list of patches to use -- in most cases, you will want to use it in the following form: ``-gridlist '1D: 0 151 101 75 51'``  * Here, a 0 patch size means the global domain. Patch sizes   otherwise should be odd integers >= 5. * If you use the '0' patch size again after the first position,   you will actually get an iteration at the size of the   default patch level 1, where the patch sizes are 75% of   the volume dimension.  There is no way to force the program   to literally repeat the sui generis step of lev=0.  
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    base_warp: generic/file
-    # type=file: Displacement in mm for the base image.If plus minus is used, this is the field suceptibility correctionwarp (in 'mm') for base image. This is only output if plusminusor iwarp options are passed
-    source_warp: generic/file
-    # type=file: Displacement in mm for the source image.If plusminus is used this is the field suceptibility correctionwarp (in 'mm') for source image.
-    warped_base: generic/file
-    # type=file: Undistorted base file.
     warped_source: generic/file
     # type=file: Warped source file. If plusminus is used, this is the undistortedsource file.
+    warped_base: generic/file
+    # type=file: Undistorted base file.
+    source_warp: generic/file
+    # type=file: Displacement in mm for the source image.If plusminus is used this is the field suceptibility correctionwarp (in 'mm') for source image.
+    base_warp: generic/file
+    # type=file: Displacement in mm for the base image.If plus minus is used, this is the field suceptibility correctionwarp (in 'mm') for base image. This is only output if plusminusor iwarp options are passed
     weights: generic/file
     # type=file: Auto-computed weight volume.
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
@@ -189,15 +186,15 @@
     noweight:
     # type=bool|default=False: If you want a binary weight (the old default), use this option.That is, each voxel in the base volume automask will beweighted the same in the computation of the cost functional.
     weight:
     # type=file|default=<undefined>: Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.
     wball:
     # type=list|default=[]: "``-wball x y z r f`` Enhance automatic weight from '-useweight' by a factor of 1+f\*Gaussian(FWHM=r) centered in the base image at DICOM coordinates (x,y,z) and with radius 'r'. The goal of this option is to try and make the alignment better in a specific part of the brain. Example:  -wball 0 14 6 30 40 to emphasize the thalamic area (in MNI/Talairach space).  * The 'r' parameter must be positive! * The 'f' parameter must be between 1 and 100 (inclusive). * '-wball' does nothing if you input your own weight   with the '-weight' option. * '-wball' does change the binary weight created by   the '-noweight' option. * You can only use '-wball' once in a run of 3dQwarp.  **The effect of '-wball' is not dramatic.** The example above makes the average brain image across a collection of subjects a little sharper in the thalamic area, which might have some small value.  If you care enough about alignment to use '-wball', then you should examine the results from 3dQwarp for each subject, to see if the alignments are good enough for your purposes.
     wmask:
-    # type=tuple|default=(<nipype.interfaces.base.traits_extension.File object at 0x1154d0790>, <traits.trait_types.Float object at 0x1154d0490>): Similar to '-wball', but here, you provide a dataset 'ws' that indicates where to increase the weight.  * The 'ws' dataset must be on the same 3D grid as the base dataset. * 'ws' is treated as a mask -- it only matters where it   is nonzero -- otherwise, the values inside are not used. * After 'ws' comes the factor 'f' by which to increase the   automatically computed weight.  Where 'ws' is nonzero,   the weighting will be multiplied by (1+f). * As with '-wball', the factor 'f' should be between 1 and 100.  
+    # type=tuple|default=(<nipype.interfaces.base.traits_extension.File object at 0x1122bbe50>, <traits.trait_types.Float object at 0x1122bbd90>): Similar to '-wball', but here, you provide a dataset 'ws' that indicates where to increase the weight.  * The 'ws' dataset must be on the same 3D grid as the base dataset. * 'ws' is treated as a mask -- it only matters where it   is nonzero -- otherwise, the values inside are not used. * After 'ws' comes the factor 'f' by which to increase the   automatically computed weight.  Where 'ws' is nonzero,   the weighting will be multiplied by (1+f). * As with '-wball', the factor 'f' should be between 1 and 100.  
     out_weight_file:
     # type=file|default=<undefined>: Write the weight volume to disk as a dataset
     blur:
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
     pblur:
     # type=list|default=[]: Use progressive blurring; that is, for larger patch sizes, the amount of blurring is larger.  The general idea is to avoid trying to match finer details when the patch size and incremental warps are coarse.  When '-blur' is used as well, it sets a minimum amount of blurring that will be used. [06 Aug 2014 -- '-pblur' may become the default someday].  * You can optionally give the fraction of the patch size that   is used for the progressive blur by providing a value between   0 and 0.25 after '-pblur'.  If you provide TWO values, the   the first fraction is used for progressively blurring the   base image and the second for the source image.  The default   parameters when just '-pblur' is given is the same as giving   the options as '-pblur 0.09 0.09'. * '-pblur' is useful when trying to match 2 volumes with high   amounts of detail; e.g, warping one subject's brain image to   match another's, or trying to warp to match a detailed template. * Note that using negative values with '-blur' means that the   progressive blurring will be done with median filters, rather   than Gaussian linear blurring.  Note: The combination of the -allineate and -pblur options will make the results of using 3dQwarp to align to a template somewhat less sensitive to initial head position and scaling.
     emask:
@@ -261,15 +258,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -287,15 +284,15 @@
     nopadWARP: 'True'
     # type=bool|default=False: If for some reason you require the warp volume tomatch the base volume, then use this option to have the outputWARP dataset(s) truncated.
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     plusminus: 'True'
     # type=bool|default=False: Normally, the warp displacements dis(x) are defined to match base(x) to source(x+dis(x)).  With this option, the match is between base(x-dis(x)) and source(x+dis(x)) -- the two images 'meet in the middle'.  * One goal is to mimic the warping done to MRI EPI data by   field inhomogeneities, when registering between a 'blip up'   and a 'blip down' down volume, which will have opposite   distortions. * Define Wp(x) = x+dis(x) and Wm(x) = x-dis(x).  Then since   base(Wm(x)) matches source(Wp(x)), by substituting INV(Wm(x))   wherever we see x, we have base(x) matches source(Wp(INV(Wm(x))));   that is, the warp V(x) that one would get from the 'usual' way   of running 3dQwarp is V(x) = Wp(INV(Wm(x))). * Conversely, we can calculate Wp(x) in terms of V(x) as follows:   If V(x) = x + dv(x), define Vh(x) = x + dv(x)/2;   then Wp(x) = V(INV(Vh(x))) * With the above formulas, it is possible to compute Wp(x) from   V(x) and vice-versa, using program 3dNwarpCalc.  The requisite   commands are left as an exercise for the aspiring AFNI Jedi Master. * You can use the semi-secret '-pmBASE' option to get the V(x)   warp and the source dataset warped to base space, in addition to   the Wp(x) '_PLUS' and Wm(x) '_MINUS' warps.    * Alas: -plusminus does not work with -duplo or -allineate :-(   * However, you can use -iniwarp with -plusminus :-)   * The outputs have _PLUS (from the source dataset) and _MINUS     (from the base dataset) in their filenames, in addition to     the prefix.  The -iwarp option, if present, will be ignored.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -311,15 +308,15 @@
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     resample: 'True'
     # type=bool|default=False: This option simply resamples the source dataset to match the base dataset grid.  You can use this if the two datasets overlap well (as seen in the AFNI GUI), but are not on the same 3D grid.  * If they don't overlap well, allineate them first * The reampling here is done with the   'wsinc5' method, which has very little blurring artifact. * If the base and source datasets ARE on the same 3D grid,   then the -resample option will be ignored. * You CAN use -resample with these 3dQwarp options:   -plusminus  -inilev  -iniwarp  -duplo  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -332,28 +329,28 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
-    out_file: '"anatSSQ.nii.gz"'
+    out_file:
     # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
     resample: 'True'
     # type=bool|default=False: This option simply resamples the source dataset to match the base dataset grid.  You can use this if the two datasets overlap well (as seen in the AFNI GUI), but are not on the same 3D grid.  * If they don't overlap well, allineate them first * The reampling here is done with the   'wsinc5' method, which has very little blurring artifact. * If the base and source datasets ARE on the same 3D grid,   then the -resample option will be ignored. * You CAN use -resample with these 3dQwarp options:   -plusminus  -inilev  -iniwarp  -duplo  
     lpc: 'True'
     # type=bool|default=False: Local Pearson minimization (i.e., EPI-T1 registration)This option has not be extensively testedIf you use '-lpc', then '-maxlev 0' is automatically set.If you want to go to more refined levels, you can set '-maxlev'This should be set up to have lpc as the second to last argumentand maxlev as the second to last argument, as needed by AFNIUsing maxlev > 1 is not recommended for EPI-T1 alignment.
     verb: 'True'
     # type=bool|default=False: more detailed description of the process
     iwarp: 'True'
     # type=bool|default=False: Do compute and save the _WARPINV file.
     blur: '[0,3]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -371,15 +368,15 @@
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     duplo: 'True'
     # type=bool|default=False: Start off with 1/2 scale versions of the volumes," for getting a speedy coarse first alignment."  * Then scales back up to register the full volumes."   The goal is greater speed, and it seems to help this"   positively piggish program to be more expeditious." * However, accuracy is somewhat lower with '-duplo',"   for reasons that currently elude Zhark; for this reason,"   the Emperor does not usually use '-duplo'.  
     blur: '[0,3]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -398,18 +395,18 @@
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     duplo: 'True'
     # type=bool|default=False: Start off with 1/2 scale versions of the volumes," for getting a speedy coarse first alignment."  * Then scales back up to register the full volumes."   The goal is greater speed, and it seems to help this"   positively piggish program to be more expeditious." * However, accuracy is somewhat lower with '-duplo',"   for reasons that currently elude Zhark; for this reason,"   the Emperor does not usually use '-duplo'.  
     minpatch: '25'
     # type=int|default=0: The value of mm should be an odd integer.  * The default value of mm is 25. * For more accurate results than mm=25, try 19 or 13. * The smallest allowed patch size is 5. * You may want stop at a larger patch size (say 7 or 9) and use   the -Qfinal option to run that final level with quintic warps,   which might run faster and provide the same degree of warp detail. * Trying to make two different brain volumes match in fine detail   is usually a waste of time, especially in humans.  There is too   much variability in anatomy to match gyrus to gyrus accurately.   For this reason, the default minimum patch size is 25 voxels.   Using a smaller '-minpatch' might try to force the warp to   match features that do not match, and the result can be useless   image distortions -- another reason to LOOK AT THE RESULTS.  
     blur: '[0,3]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
-    out_file: '"Q25"'
+    out_file:
     # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -424,22 +421,22 @@
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     blur: '[0,2]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
-    out_file: '"Q11"'
+    out_file:
     # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
     inilev: '7'
     # type=int|default=0: The initial refinement 'level' at which to start.  * Usually used with -iniwarp; CANNOT be used with -duplo. * The combination of -inilev and -iniwarp lets you take the   results of a previous 3dQwarp run and refine them further:   Note that the source dataset in the second run is the SAME as   in the first run.  If you don't see why this is necessary,   then you probably need to seek help from an AFNI guru.  
     iniwarp:
     # type=list|default=[]: A dataset with an initial nonlinear warp to use.  * If this option is not used, the initial warp is the identity. * You can specify a catenation of warps (in quotes) here, as in   program 3dNwarpApply. * As a special case, if you just input an affine matrix in a .1D   file, that will work also -- it is treated as giving the initial   warp via the string "IDENT(base_dataset) matrix_file.aff12.1D". * You CANNOT use this option with -duplo !! * -iniwarp is usually used with -inilev to re-start 3dQwarp from   a previous stopping point.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -457,15 +454,15 @@
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     allineate: 'True'
     # type=bool|default=False: This option will make 3dQwarp run 3dAllineate first, to align the source dataset to the base with an affine transformation. It will then use that alignment as a starting point for the nonlinear warping.
     allineate_opts: '"-cose lpa -verb"'
     # type=str|default='': add extra options to the 3dAllineate command to be run by 3dQwarp.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -487,15 +484,15 @@
     nopadWARP: 'True'
     # type=bool|default=False: If for some reason you require the warp volume tomatch the base volume, then use this option to have the outputWARP dataset(s) truncated.
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     plusminus: 'True'
     # type=bool|default=False: Normally, the warp displacements dis(x) are defined to match base(x) to source(x+dis(x)).  With this option, the match is between base(x-dis(x)) and source(x+dis(x)) -- the two images 'meet in the middle'.  * One goal is to mimic the warping done to MRI EPI data by   field inhomogeneities, when registering between a 'blip up'   and a 'blip down' down volume, which will have opposite   distortions. * Define Wp(x) = x+dis(x) and Wm(x) = x-dis(x).  Then since   base(Wm(x)) matches source(Wp(x)), by substituting INV(Wm(x))   wherever we see x, we have base(x) matches source(Wp(INV(Wm(x))));   that is, the warp V(x) that one would get from the 'usual' way   of running 3dQwarp is V(x) = Wp(INV(Wm(x))). * Conversely, we can calculate Wp(x) in terms of V(x) as follows:   If V(x) = x + dv(x), define Vh(x) = x + dv(x)/2;   then Wp(x) = V(INV(Vh(x))) * With the above formulas, it is possible to compute Wp(x) from   V(x) and vice-versa, using program 3dNwarpCalc.  The requisite   commands are left as an exercise for the aspiring AFNI Jedi Master. * You can use the semi-secret '-pmBASE' option to get the V(x)   warp and the source dataset warped to base space, in addition to   the Wp(x) '_PLUS' and Wm(x) '_MINUS' warps.    * Alas: -plusminus does not work with -duplo or -allineate :-(   * However, you can use -iniwarp with -plusminus :-)   * The outputs have _PLUS (from the source dataset) and _MINUS     (from the base dataset) in their filenames, in addition to     the prefix.  The -iwarp option, if present, will be ignored.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dQwarp -base mni.nii -source structural.nii -prefix ppp_structural -resample
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -504,42 +501,42 @@
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     resample: 'True'
     # type=bool|default=False: This option simply resamples the source dataset to match the base dataset grid.  You can use this if the two datasets overlap well (as seen in the AFNI GUI), but are not on the same 3D grid.  * If they don't overlap well, allineate them first * The reampling here is done with the   'wsinc5' method, which has very little blurring artifact. * If the base and source datasets ARE on the same 3D grid,   then the -resample option will be ignored. * You CAN use -resample with these 3dQwarp options:   -plusminus  -inilev  -iniwarp  -duplo  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dQwarp -base epi.nii -blur 0.0 3.0 -source structural.nii -iwarp -prefix anatSSQ.nii.gz -resample -verb -lpc
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
-    out_file: '"anatSSQ.nii.gz"'
+    out_file:
     # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
     resample: 'True'
     # type=bool|default=False: This option simply resamples the source dataset to match the base dataset grid.  You can use this if the two datasets overlap well (as seen in the AFNI GUI), but are not on the same 3D grid.  * If they don't overlap well, allineate them first * The reampling here is done with the   'wsinc5' method, which has very little blurring artifact. * If the base and source datasets ARE on the same 3D grid,   then the -resample option will be ignored. * You CAN use -resample with these 3dQwarp options:   -plusminus  -inilev  -iniwarp  -duplo  
     lpc: 'True'
     # type=bool|default=False: Local Pearson minimization (i.e., EPI-T1 registration)This option has not be extensively testedIf you use '-lpc', then '-maxlev 0' is automatically set.If you want to go to more refined levels, you can set '-maxlev'This should be set up to have lpc as the second to last argumentand maxlev as the second to last argument, as needed by AFNIUsing maxlev > 1 is not recommended for EPI-T1 alignment.
     verb: 'True'
     # type=bool|default=False: more detailed description of the process
     iwarp: 'True'
     # type=bool|default=False: Do compute and save the _WARPINV file.
     blur: '[0,3]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dQwarp -base mni.nii -blur 0.0 3.0 -duplo -source structural.nii -prefix ppp_structural
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -550,15 +547,15 @@
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     duplo: 'True'
     # type=bool|default=False: Start off with 1/2 scale versions of the volumes," for getting a speedy coarse first alignment."  * Then scales back up to register the full volumes."   The goal is greater speed, and it seems to help this"   positively piggish program to be more expeditious." * However, accuracy is somewhat lower with '-duplo',"   for reasons that currently elude Zhark; for this reason,"   the Emperor does not usually use '-duplo'.  
     blur: '[0,3]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dQwarp -base mni.nii -blur 0.0 3.0 -duplo -source structural.nii -minpatch 25 -prefix Q25
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -570,18 +567,18 @@
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     duplo: 'True'
     # type=bool|default=False: Start off with 1/2 scale versions of the volumes," for getting a speedy coarse first alignment."  * Then scales back up to register the full volumes."   The goal is greater speed, and it seems to help this"   positively piggish program to be more expeditious." * However, accuracy is somewhat lower with '-duplo',"   for reasons that currently elude Zhark; for this reason,"   the Emperor does not usually use '-duplo'.  
     minpatch: '25'
     # type=int|default=0: The value of mm should be an odd integer.  * The default value of mm is 25. * For more accurate results than mm=25, try 19 or 13. * The smallest allowed patch size is 5. * You may want stop at a larger patch size (say 7 or 9) and use   the -Qfinal option to run that final level with quintic warps,   which might run faster and provide the same degree of warp detail. * Trying to make two different brain volumes match in fine detail   is usually a waste of time, especially in humans.  There is too   much variability in anatomy to match gyrus to gyrus accurately.   For this reason, the default minimum patch size is 25 voxels.   Using a smaller '-minpatch' might try to force the warp to   match features that do not match, and the result can be useless   image distortions -- another reason to LOOK AT THE RESULTS.  
     blur: '[0,3]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
-    out_file: '"Q25"'
+    out_file:
     # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dQwarp -base mni.nii -blur 0.0 2.0 -source structural.nii -inilev 7 -iniwarp Q25_warp+tlrc.HEAD -prefix Q11
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -589,22 +586,22 @@
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     blur: '[0,2]'
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
-    out_file: '"Q11"'
+    out_file:
     # type=file|default=<undefined>: Sets the prefix/suffix for the output datasets.  * The source dataset is warped to match the base   and gets prefix 'ppp'. (Except if '-plusminus' is used * The final interpolation to this output dataset is   done using the 'wsinc5' method.  See the output of   3dAllineate -HELP   (in the "Modifying '-final wsinc5'" section) for   the lengthy technical details. * The 3D warp used is saved in a dataset with   prefix 'ppp_WARP' -- this dataset can be used   with 3dNwarpApply and 3dNwarpCat, for example. * To be clear, this is the warp from source dataset   coordinates to base dataset coordinates, where the   values at each base grid point are the xyz displacements   needed to move that grid point's xyz values to the   corresponding xyz values in the source dataset:   base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)   Another way to think of this warp is that it 'pulls'   values back from source space to base space. * 3dNwarpApply would use 'ppp_WARP' to transform datasets   aligned with the source dataset to be aligned with the   base dataset.  **If you do NOT want this warp saved, use the option '-nowarp'**. (However, this warp is usually the most valuable possible output!)  * If you want to calculate and save the inverse 3D warp,   use the option '-iwarp'.  This inverse warp will then be   saved in a dataset with prefix 'ppp_WARPINV'. * This inverse warp could be used to transform data from base   space to source space, if you need to do such an operation. * You can easily compute the inverse later, say by a command like   3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'   or the inverse can be computed as needed in 3dNwarpApply, like   3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...  
     inilev: '7'
     # type=int|default=0: The initial refinement 'level' at which to start.  * Usually used with -iniwarp; CANNOT be used with -duplo. * The combination of -inilev and -iniwarp lets you take the   results of a previous 3dQwarp run and refine them further:   Note that the source dataset in the second run is the SAME as   in the first run.  If you don't see why this is necessary,   then you probably need to seek help from an AFNI guru.  
     iniwarp:
     # type=list|default=[]: A dataset with an initial nonlinear warp to use.  * If this option is not used, the initial warp is the identity. * You can specify a catenation of warps (in quotes) here, as in   program 3dNwarpApply. * As a special case, if you just input an affine matrix in a .1D   file, that will work also -- it is treated as giving the initial   warp via the string "IDENT(base_dataset) matrix_file.aff12.1D". * You CANNOT use this option with -duplo !! * -iniwarp is usually used with -inilev to re-start 3dQwarp from   a previous stopping point.  
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dQwarp -allineate -allineate_opts "-cose lpa -verb" -base mni.nii -source structural.nii -prefix ppp_structural
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -615,11 +612,11 @@
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
     allineate: 'True'
     # type=bool|default=False: This option will make 3dQwarp run 3dAllineate first, to align the source dataset to the base with an affine transformation. It will then use that alignment as a starting point for the nonlinear warping.
     allineate_opts: '"-cose lpa -verb"'
     # type=str|default='': add extra options to the 3dAllineate command to be run by 3dQwarp.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/qwarp_plus_minus.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/qwarp_plus_minus.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -35,56 +35,53 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    source_file: generic/file
+    # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image)
+    out_file: generic/file
+    # type=file|default='Qwarp.nii.gz': Output file
+    in_file: medimage/nifti-gz
+    # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     base_file: medimage/nifti-gz
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
+    weight: generic/file
+    # type=file|default=<undefined>: Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.
+    out_weight_file: generic/file
+    # type=file|default=<undefined>: Write the weight volume to disk as a dataset
     emask: generic/file
     # type=file|default=<undefined>: Here, 'ee' is a dataset to specify a mask of voxelsto EXCLUDE from the analysis -- all voxels in 'ee'that are NONZERO will not be used in the alignment.The base image always automasked -- the emask isextra, to indicate voxels you definitely DON'T wantincluded in the matching process, even if they areinside the brain.
-    gridlist: generic/file
-    # type=file|default=<undefined>: This option provides an alternate way to specify the patch grid sizes used in the warp optimization process. 'gl' is a 1D file with a list of patches to use -- in most cases, you will want to use it in the following form: ``-gridlist '1D: 0 151 101 75 51'``  * Here, a 0 patch size means the global domain. Patch sizes   otherwise should be odd integers >= 5. * If you use the '0' patch size again after the first position,   you will actually get an iteration at the size of the   default patch level 1, where the patch sizes are 75% of   the volume dimension.  There is no way to force the program   to literally repeat the sui generis step of lev=0.  
-    in_file: medimage/nifti-gz
-    # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     iniwarp: generic/file+list-of
     # type=list|default=[]: A dataset with an initial nonlinear warp to use.  * If this option is not used, the initial warp is the identity. * You can specify a catenation of warps (in quotes) here, as in   program 3dNwarpApply. * As a special case, if you just input an affine matrix in a .1D   file, that will work also -- it is treated as giving the initial   warp via the string "IDENT(base_dataset) matrix_file.aff12.1D". * You CANNOT use this option with -duplo !! * -iniwarp is usually used with -inilev to re-start 3dQwarp from   a previous stopping point.  
-    out_file: Path
-    # type=file|default='Qwarp.nii.gz': Output file
-    out_weight_file: Path
-    # type=file|default=<undefined>: Write the weight volume to disk as a dataset
-    source_file: generic/file
-    # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image)
-    weight: generic/file
-    # type=file|default=<undefined>: Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    gridlist: generic/file
+    # type=file|default=<undefined>: This option provides an alternate way to specify the patch grid sizes used in the warp optimization process. 'gl' is a 1D file with a list of patches to use -- in most cases, you will want to use it in the following form: ``-gridlist '1D: 0 151 101 75 51'``  * Here, a 0 patch size means the global domain. Patch sizes   otherwise should be odd integers >= 5. * If you use the '0' patch size again after the first position,   you will actually get an iteration at the size of the   default patch level 1, where the patch sizes are 75% of   the volume dimension.  There is no way to force the program   to literally repeat the sui generis step of lev=0.  
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    base_warp: generic/file
-    # type=file: Displacement in mm for the base image.If plus minus is used, this is the field suceptibility correctionwarp (in 'mm') for base image. This is only output if plusminusor iwarp options are passed
-    source_warp: generic/file
-    # type=file: Displacement in mm for the source image.If plusminus is used this is the field suceptibility correctionwarp (in 'mm') for source image.
-    warped_base: generic/file
-    # type=file: Undistorted base file.
     warped_source: generic/file
     # type=file: Warped source file. If plusminus is used, this is the undistortedsource file.
+    warped_base: generic/file
+    # type=file: Undistorted base file.
+    source_warp: generic/file
+    # type=file: Displacement in mm for the source image.If plusminus is used this is the field suceptibility correctionwarp (in 'mm') for source image.
+    base_warp: generic/file
+    # type=file: Displacement in mm for the base image.If plus minus is used, this is the field suceptibility correctionwarp (in 'mm') for base image. This is only output if plusminusor iwarp options are passed
     weights: generic/file
     # type=file: Auto-computed weight volume.
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
@@ -125,15 +122,15 @@
     noweight:
     # type=bool|default=False: If you want a binary weight (the old default), use this option.That is, each voxel in the base volume automask will beweighted the same in the computation of the cost functional.
     weight:
     # type=file|default=<undefined>: Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.
     wball:
     # type=list|default=[]: "``-wball x y z r f`` Enhance automatic weight from '-useweight' by a factor of 1+f\*Gaussian(FWHM=r) centered in the base image at DICOM coordinates (x,y,z) and with radius 'r'. The goal of this option is to try and make the alignment better in a specific part of the brain. Example:  -wball 0 14 6 30 40 to emphasize the thalamic area (in MNI/Talairach space).  * The 'r' parameter must be positive! * The 'f' parameter must be between 1 and 100 (inclusive). * '-wball' does nothing if you input your own weight   with the '-weight' option. * '-wball' does change the binary weight created by   the '-noweight' option. * You can only use '-wball' once in a run of 3dQwarp.  **The effect of '-wball' is not dramatic.** The example above makes the average brain image across a collection of subjects a little sharper in the thalamic area, which might have some small value.  If you care enough about alignment to use '-wball', then you should examine the results from 3dQwarp for each subject, to see if the alignments are good enough for your purposes.
     wmask:
-    # type=tuple|default=(<nipype.interfaces.base.traits_extension.File object at 0x1154d0790>, <traits.trait_types.Float object at 0x1154d0490>): Similar to '-wball', but here, you provide a dataset 'ws' that indicates where to increase the weight.  * The 'ws' dataset must be on the same 3D grid as the base dataset. * 'ws' is treated as a mask -- it only matters where it   is nonzero -- otherwise, the values inside are not used. * After 'ws' comes the factor 'f' by which to increase the   automatically computed weight.  Where 'ws' is nonzero,   the weighting will be multiplied by (1+f). * As with '-wball', the factor 'f' should be between 1 and 100.  
+    # type=tuple|default=(<nipype.interfaces.base.traits_extension.File object at 0x1122bbe50>, <traits.trait_types.Float object at 0x1122bbd90>): Similar to '-wball', but here, you provide a dataset 'ws' that indicates where to increase the weight.  * The 'ws' dataset must be on the same 3D grid as the base dataset. * 'ws' is treated as a mask -- it only matters where it   is nonzero -- otherwise, the values inside are not used. * After 'ws' comes the factor 'f' by which to increase the   automatically computed weight.  Where 'ws' is nonzero,   the weighting will be multiplied by (1+f). * As with '-wball', the factor 'f' should be between 1 and 100.  
     out_weight_file:
     # type=file|default=<undefined>: Write the weight volume to disk as a dataset
     blur:
     # type=list|default=[]: Gaussian blur the input images by 'bb' (FWHM) voxels before doing the alignment (the output dataset will not be blurred). The default is 2.345 (for no good reason).  * Optionally, you can provide 2 values for 'bb', and then   the first one is applied to the base volume, the second   to the source volume.   e.g., '-blur 0 3' to skip blurring the base image   (if the base is a blurry template, for example). * A negative blur radius means to use 3D median filtering,   rather than Gaussian blurring.  This type of filtering will   better preserve edges, which can be important in alignment. * If the base is a template volume that is already blurry,   you probably don't want to blur it again, but blurring   the source volume a little is probably a good idea, to   help the program avoid trying to match tiny features. * Note that -duplo will blur the volumes some extra   amount for the initial small-scale warping, to make   that phase of the program converge more rapidly.  
     pblur:
     # type=list|default=[]: Use progressive blurring; that is, for larger patch sizes, the amount of blurring is larger.  The general idea is to avoid trying to match finer details when the patch size and incremental warps are coarse.  When '-blur' is used as well, it sets a minimum amount of blurring that will be used. [06 Aug 2014 -- '-pblur' may become the default someday].  * You can optionally give the fraction of the patch size that   is used for the progressive blur by providing a value between   0 and 0.25 after '-pblur'.  If you provide TWO values, the   the first fraction is used for progressively blurring the   base image and the second for the source image.  The default   parameters when just '-pblur' is given is the same as giving   the options as '-pblur 0.09 0.09'. * '-pblur' is useful when trying to match 2 volumes with high   amounts of detail; e.g, warping one subject's brain image to   match another's, or trying to warp to match a detailed template. * Note that using negative values with '-blur' means that the   progressive blurring will be done with median filters, rather   than Gaussian linear blurring.  Note: The combination of the -allineate and -pblur options will make the results of using 3dQwarp to align to a template somewhat less sensitive to initial head position and scaling.
     emask:
@@ -195,15 +192,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -219,15 +216,15 @@
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     nopadWARP: 'True'
     # type=bool|default=False: If for some reason you require the warp volume tomatch the base volume, then use this option to have the outputWARP dataset(s) truncated.
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -247,11 +244,11 @@
     in_file:
     # type=file|default=<undefined>: Source image (opposite phase encoding direction than base image).
     nopadWARP: 'True'
     # type=bool|default=False: If for some reason you require the warp volume tomatch the base volume, then use this option to have the outputWARP dataset(s) truncated.
     base_file:
     # type=file|default=<undefined>: Base image (opposite phase encoding direction than source image).
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/re_ho.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/re_ho.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -35,24 +35,21 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset
-    label_set: generic/file
-    # type=file|default=<undefined>: a set of ROIs, each labelled with distinct integers. ReHo will then be calculated per ROI.
-    mask_file: generic/file
-    # type=file|default=<undefined>: Mask within which ReHo should be calculated voxelwise
-    out_file: Path
+    out_file: medimage/nifti-gz
     # type=file: Voxelwise regional homogeneity map
     # type=file|default=<undefined>: Output dataset.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    mask_file: generic/file
+    # type=file|default=<undefined>: Mask within which ReHo should be calculated voxelwise
+    label_set: generic/file
+    # type=file|default=<undefined>: a set of ROIs, each labelled with distinct integers. ReHo will then be calculated per ROI.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -98,15 +95,15 @@
     overwrite:
     # type=bool|default=False: overwrite output file if it already exists
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -117,21 +114,21 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset
-    out_file: '"reho.nii.gz"'
+    out_file:
     # type=file: Voxelwise regional homogeneity map
     # type=file|default=<undefined>: Output dataset.
     neighborhood: '"vertices"'
     # type=enum|default='faces'|allowed['edges','faces','vertices']:  voxels in neighborhood. can be: ``faces`` (for voxel and 6 facewise neighbors, only), ``edges`` (for voxel and 18 face- and edge-wise neighbors), ``vertices`` (for voxel and 26 face-, edge-, and node-wise neighbors).
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -146,17 +143,17 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset
-    out_file: '"reho.nii.gz"'
+    out_file:
     # type=file: Voxelwise regional homogeneity map
     # type=file|default=<undefined>: Output dataset.
     neighborhood: '"vertices"'
     # type=enum|default='faces'|allowed['edges','faces','vertices']:  voxels in neighborhood. can be: ``faces`` (for voxel and 6 facewise neighbors, only), ``edges`` (for voxel and 18 face- and edge-wise neighbors), ``vertices`` (for voxel and 26 face-, edge-, and node-wise neighbors).
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/refit.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/refit.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -38,21 +38,18 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    duporigin_file: generic/file
-    # type=file|default=<undefined>: Copies the xorigin, yorigin, and zorigin values from the header of the given dataset
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3drefit
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    duporigin_file: generic/file
+    # type=file|default=<undefined>: Copies the xorigin, yorigin, and zorigin values from the header of the given dataset
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -110,15 +107,15 @@
     nosaveatr:
     # type=bool|default=False: Opposite of -saveatr
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -132,15 +129,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3drefit
     deoblique: 'True'
     # type=bool|default=False: replace current transformation matrix with cardinal matrix
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -154,15 +151,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3drefit
     atrfloat: ("IJK_TO_DICOM_REAL", "'1 0.2 0 0 -0.2 1 0 0 0 0 1 0'")
     # type=tuple|default=('', ''): Create or modify floating point attributes. The input values may be specified as a single string in quotes or as a 1D filename or string, example '1 0.2 0 0 -0.2 1 0 0 0 0 1 0' or flipZ.1D or '1D:1,0.2,2@0,-0.2,1,2@0,2@0,1,0'
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -180,26 +177,26 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3drefit
     deoblique: 'True'
     # type=bool|default=False: replace current transformation matrix with cardinal matrix
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3drefit -atrfloat IJK_TO_DICOM_REAL "1 0.2 0 0 -0.2 1 0 0 0 0 1 0" structural.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3drefit
     atrfloat: ("IJK_TO_DICOM_REAL", "'1 0.2 0 0 -0.2 1 0 0 0 0 1 0'")
     # type=tuple|default=('', ''): Create or modify floating point attributes. The input values may be specified as a single string in quotes or as a 1D filename or string, example '1 0.2 0 0 -0.2 1 0 0 0 0 1 0' or flipZ.1D or '1D:1,0.2,2@0,-0.2,1,2@0,2@0,1,0'
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/remlfit.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/remlfit.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -35,126 +35,123 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
+    in_files: medimage/nifti1+list-of
+    # type=inputmultiobject|default=[]: Read time series dataset
+    matrix: medimage-afni/one-d
+    # type=file|default=<undefined>: the design matrix file, which should have been output from Deconvolve via the 'x1D' option
+    matim: generic/file
+    # type=file|default=<undefined>: read a standard file as the matrix. You can use only Col as a name in GLTs with these nonstandard matrix input methods, since the other names come from the 'matrix' file. These mutually exclusive options are ignored if 'matrix' is used.
+    mask: generic/file
+    # type=file|default=<undefined>: filename of 3D mask dataset; only data time series from within the mask will be analyzed; results for voxels outside the mask will be set to zero.
     STATmask: generic/file
     # type=file|default=<undefined>: filename of 3D mask dataset to be used for the purpose of reporting truncation-to float issues AND for computing the FDR curves. The actual results ARE not masked with this option (only with 'mask' or 'automask' options).
     addbase: generic/file+list-of
     # type=inputmultiobject|default=[]: file(s) to add baseline model columns to the matrix with this option. Each column in the specified file(s) will be appended to the matrix. File(s) must have at least as many rows as the matrix does.
+    slibase: generic/file+list-of
+    # type=inputmultiobject|default=[]: similar to 'addbase' in concept, BUT each specified file must have an integer multiple of the number of slices in the input dataset(s); then, separate regression matrices are generated for each slice, with the first column of the file appended to the matrix for the first slice of the dataset, the second column of the file appended to the matrix for the first slice of the dataset, and so on. Intended to help model physiological noise in FMRI, or other effects you want to regress out that might change significantly in the inter-slice time intervals. This will slow the program down, and make it use a lot more memory (to hold all the matrix stuff).
+    slibase_sm: generic/file+list-of
+    # type=inputmultiobject|default=[]: similar to 'slibase', BUT each file much be in slice major order (i.e. all slice0 columns come first, then all slice1 columns, etc).
     dsort: generic/file
     # type=file|default=<undefined>: 4D dataset to be used as voxelwise baseline regressor
-    errts_file: Path
-    # type=file: output dataset for REML residuals = data - fitted model (if generated
-    # type=file|default=<undefined>: output dataset for REML residuals = data - fitted model
-    fitts_file: Path
-    # type=file: output dataset for REML fitted model (if generated)
-    # type=file|default=<undefined>: output dataset for REML fitted model
-    glt_file: Path
+    out_file: medimage/nifti1
+    # type=file: dataset for beta + statistics from the REML estimation (if generated
+    # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
+    var_file: generic/file
+    # type=file: dataset for REML variance parameters (if generated)
+    # type=file|default=<undefined>: output dataset for REML variance parameters
+    rbeta_file: generic/file
+    # type=file: output dataset for beta weights from the REML estimation (if generated
+    # type=file|default=<undefined>: output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.
+    glt_file: generic/file
     # type=file: output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym' (if generated)
     # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym'; GLTs from Deconvolve's command line will NOT be included.
-    in_files: medimage/nifti1+list-of
-    # type=inputmultiobject|default=[]: Read time series dataset
-    mask: generic/file
-    # type=file|default=<undefined>: filename of 3D mask dataset; only data time series from within the mask will be analyzed; results for voxels outside the mask will be set to zero.
-    matim: generic/file
-    # type=file|default=<undefined>: read a standard file as the matrix. You can use only Col as a name in GLTs with these nonstandard matrix input methods, since the other names come from the 'matrix' file. These mutually exclusive options are ignored if 'matrix' is used.
-    matrix: medimage-afni/one-d
-    # type=file|default=<undefined>: the design matrix file, which should have been output from Deconvolve via the 'x1D' option
-    obeta: Path
+    fitts_file: generic/file
+    # type=file: output dataset for REML fitted model (if generated)
+    # type=file|default=<undefined>: output dataset for REML fitted model
+    errts_file: generic/file
+    # type=file: output dataset for REML residuals = data - fitted model (if generated
+    # type=file|default=<undefined>: output dataset for REML residuals = data - fitted model
+    wherr_file: generic/file
+    # type=file: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise (if generated)
+    # type=file|default=<undefined>: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise
+    ovar: generic/file
+    # type=file: dataset for OLSQ st.dev. parameter (if generated)
+    # type=file|default=<undefined>: dataset for OLSQ st.dev. parameter (kind of boring)
+    obeta: generic/file
     # type=file: dataset for beta weights from the OLSQ estimation (if generated)
     # type=file|default=<undefined>: dataset for beta weights from the OLSQ estimation
-    obuck: Path
+    obuck: generic/file
     # type=file: dataset for beta + statistics from the OLSQ estimation (if generated)
     # type=file|default=<undefined>: dataset for beta + statistics from the OLSQ estimation
-    oerrts: Path
-    # type=file: dataset for OLSQ residuals = data - fitted model (if generated
-    # type=file|default=<undefined>: dataset for OLSQ residuals (data - fitted model)
-    ofitts: Path
-    # type=file: dataset for OLSQ fitted model (if generated)
-    # type=file|default=<undefined>: dataset for OLSQ fitted model
-    oglt: Path
+    oglt: generic/file
     # type=file: dataset for beta + statistics from 'gltsym' options (if generated
     # type=file|default=<undefined>: dataset for beta + statistics from 'gltsym' options
-    out_file: Path
-    # type=file: dataset for beta + statistics from the REML estimation (if generated
-    # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
-    ovar: Path
-    # type=file: dataset for OLSQ st.dev. parameter (if generated)
-    # type=file|default=<undefined>: dataset for OLSQ st.dev. parameter (kind of boring)
-    rbeta_file: Path
-    # type=file: output dataset for beta weights from the REML estimation (if generated
-    # type=file|default=<undefined>: output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.
-    slibase: generic/file+list-of
-    # type=inputmultiobject|default=[]: similar to 'addbase' in concept, BUT each specified file must have an integer multiple of the number of slices in the input dataset(s); then, separate regression matrices are generated for each slice, with the first column of the file appended to the matrix for the first slice of the dataset, the second column of the file appended to the matrix for the first slice of the dataset, and so on. Intended to help model physiological noise in FMRI, or other effects you want to regress out that might change significantly in the inter-slice time intervals. This will slow the program down, and make it use a lot more memory (to hold all the matrix stuff).
-    slibase_sm: generic/file+list-of
-    # type=inputmultiobject|default=[]: similar to 'slibase', BUT each file much be in slice major order (i.e. all slice0 columns come first, then all slice1 columns, etc).
-    var_file: Path
-    # type=file: dataset for REML variance parameters (if generated)
-    # type=file|default=<undefined>: output dataset for REML variance parameters
-    wherr_file: Path
-    # type=file: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise (if generated)
-    # type=file|default=<undefined>: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    ofitts: generic/file
+    # type=file: dataset for OLSQ fitted model (if generated)
+    # type=file|default=<undefined>: dataset for OLSQ fitted model
+    oerrts: generic/file
+    # type=file: dataset for OLSQ residuals = data - fitted model (if generated
+    # type=file|default=<undefined>: dataset for OLSQ residuals (data - fitted model)
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    errts_file: generic/file
-    # type=file: output dataset for REML residuals = data - fitted model (if generated
-    # type=file|default=<undefined>: output dataset for REML residuals = data - fitted model
-    fitts_file: generic/file
-    # type=file: output dataset for REML fitted model (if generated)
-    # type=file|default=<undefined>: output dataset for REML fitted model
+    out_file: medimage/nifti1
+    # type=file: dataset for beta + statistics from the REML estimation (if generated
+    # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
+    var_file: generic/file
+    # type=file: dataset for REML variance parameters (if generated)
+    # type=file|default=<undefined>: output dataset for REML variance parameters
+    rbeta_file: generic/file
+    # type=file: output dataset for beta weights from the REML estimation (if generated
+    # type=file|default=<undefined>: output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.
     glt_file: generic/file
     # type=file: output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym' (if generated)
     # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym'; GLTs from Deconvolve's command line will NOT be included.
+    fitts_file: generic/file
+    # type=file: output dataset for REML fitted model (if generated)
+    # type=file|default=<undefined>: output dataset for REML fitted model
+    errts_file: generic/file
+    # type=file: output dataset for REML residuals = data - fitted model (if generated
+    # type=file|default=<undefined>: output dataset for REML residuals = data - fitted model
+    wherr_file: generic/file
+    # type=file: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise (if generated)
+    # type=file|default=<undefined>: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise
+    ovar: generic/file
+    # type=file: dataset for OLSQ st.dev. parameter (if generated)
+    # type=file|default=<undefined>: dataset for OLSQ st.dev. parameter (kind of boring)
     obeta: generic/file
     # type=file: dataset for beta weights from the OLSQ estimation (if generated)
     # type=file|default=<undefined>: dataset for beta weights from the OLSQ estimation
     obuck: generic/file
     # type=file: dataset for beta + statistics from the OLSQ estimation (if generated)
     # type=file|default=<undefined>: dataset for beta + statistics from the OLSQ estimation
-    oerrts: generic/file
-    # type=file: dataset for OLSQ residuals = data - fitted model (if generated
-    # type=file|default=<undefined>: dataset for OLSQ residuals (data - fitted model)
-    ofitts: generic/file
-    # type=file: dataset for OLSQ fitted model (if generated)
-    # type=file|default=<undefined>: dataset for OLSQ fitted model
     oglt: generic/file
     # type=file: dataset for beta + statistics from 'gltsym' options (if generated
     # type=file|default=<undefined>: dataset for beta + statistics from 'gltsym' options
-    out_file: medimage/nifti1
-    # type=file: dataset for beta + statistics from the REML estimation (if generated
-    # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
-    ovar: generic/file
-    # type=file: dataset for OLSQ st.dev. parameter (if generated)
-    # type=file|default=<undefined>: dataset for OLSQ st.dev. parameter (kind of boring)
-    rbeta_file: generic/file
-    # type=file: output dataset for beta weights from the REML estimation (if generated
-    # type=file|default=<undefined>: output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.
-    var_file: generic/file
-    # type=file: dataset for REML variance parameters (if generated)
-    # type=file|default=<undefined>: output dataset for REML variance parameters
-    wherr_file: generic/file
-    # type=file: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise (if generated)
-    # type=file|default=<undefined>: dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise
+    ofitts: generic/file
+    # type=file: dataset for OLSQ fitted model (if generated)
+    # type=file|default=<undefined>: dataset for OLSQ fitted model
+    oerrts: generic/file
+    # type=file: dataset for OLSQ residuals = data - fitted model (if generated
+    # type=file|default=<undefined>: dataset for OLSQ residuals (data - fitted model)
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -252,15 +249,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -271,23 +268,23 @@
     # bool - whether the unittest is expected to fail or not. Set to false
     # when you are satisfied with the edits you have made to this file
   - inputs:
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       in_files:
       # type=inputmultiobject|default=[]: Read time series dataset
-      out_file: '"output.nii"'
+      out_file:
       # type=file: dataset for beta + statistics from the REML estimation (if generated
       # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
       matrix:
       # type=file|default=<undefined>: the design matrix file, which should have been output from Deconvolve via the 'x1D' option
       gltsym: '[("SYM: +Lab1 -Lab2", "TestSYM"), ("timeseries.txt", "TestFile")]'
       # type=list|default=[]: read a symbolic GLT from input file and associate it with a label. As in Deconvolve, you can also use the 'SYM:' method to provide the definition of the GLT directly as a string (e.g., with 'SYM: +Label1 -Label2'). Unlike Deconvolve, you MUST specify 'SYM: ' if providing the GLT directly as a string instead of from a file
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -302,19 +299,19 @@
     # str - the expected cmdline output
     inputs:
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       in_files:
       # type=inputmultiobject|default=[]: Read time series dataset
-      out_file: '"output.nii"'
+      out_file:
       # type=file: dataset for beta + statistics from the REML estimation (if generated
       # type=file|default=<undefined>: output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
       matrix:
       # type=file|default=<undefined>: the design matrix file, which should have been output from Deconvolve via the 'x1D' option
       gltsym: '[("SYM: +Lab1 -Lab2", "TestSYM"), ("timeseries.txt", "TestFile")]'
       # type=list|default=[]: read a symbolic GLT from input file and associate it with a label. As in Deconvolve, you can also use the 'SYM:' method to provide the definition of the GLT directly as a string (e.g., with 'SYM: +Label1 -Label2'). Unlike Deconvolve, you MUST specify 'SYM: ' if providing the GLT directly as a string instead of from a file
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/resample.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/resample.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -34,22 +34,19 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dresample
-    master: generic/file
-    # type=file|default=<undefined>: align dataset grid to a reference file
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    master: generic/file
+    # type=file|default=<undefined>: align dataset grid to a reference file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -91,15 +88,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -115,15 +112,15 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dresample
     orientation: '"RPI"'
     # type=str|default='': new orientation code
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -143,11 +140,11 @@
     in_file:
     # type=file|default=<undefined>: input file to 3dresample
     orientation: '"RPI"'
     # type=str|default='': new orientation code
     outputtype: '"NIFTI"'
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/retroicor.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/retroicor.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -48,30 +48,27 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    card: medimage-afni/one-d
-    # type=file|default=<undefined>: 1D cardiac data file for cardiac correction
-    cardphase: generic/file
-    # type=file|default=<undefined>: Filename for 1D cardiac phase output
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dretroicor
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
+    card: medimage-afni/one-d
+    # type=file|default=<undefined>: 1D cardiac data file for cardiac correction
     resp: medimage-afni/one-d
     # type=file|default=<undefined>: 1D respiratory waveform data for correction
+    cardphase: generic/file
+    # type=file|default=<undefined>: Filename for 1D cardiac phase output
     respphase: generic/file
     # type=file|default=<undefined>: Filename for 1D resp phase output
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -117,15 +114,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -143,15 +140,15 @@
       card:
       # type=file|default=<undefined>: 1D cardiac data file for cardiac correction
       resp:
       # type=file|default=<undefined>: 1D respiratory waveform data for correction
       outputtype: '"NIFTI"'
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -173,11 +170,11 @@
       card:
       # type=file|default=<undefined>: 1D cardiac data file for cardiac correction
       resp:
       # type=file|default=<undefined>: 1D respiratory waveform data for correction
       outputtype: '"NIFTI"'
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/roi_stats.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/roi_stats.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -39,22 +39,21 @@
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input dataset
     mask: generic/file
     # type=file|default=<undefined>: input mask
     mask_file: medimage/nifti-gz
     # type=file|default=<undefined>: input mask
-    out_file: Path
-    # type=file: output tab-separated values file
-    # type=file|default=<undefined>: output file
     roisel: generic/file
     # type=file|default=<undefined>: Only considers ROIs denoted by values found in the specified file. Note that the order of the ROIs as specified in the file is not preserved. So an SEL.1D of '2 8 20' produces the same output as '8 20 2'
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    stat: generic/file+list-of
+    # type=inputmultiobject|default=[]: Statistics to compute. Options include:   * mean       =   Compute the mean using only non_zero voxels.                   Implies the opposite for the mean computed                   by default.  * median     =   Compute the median of nonzero voxels  * mode       =   Compute the mode of nonzero voxels.                   (integral valued sets only)  * minmax     =   Compute the min/max of nonzero voxels  * sum        =   Compute the sum using only nonzero voxels.  * voxels     =   Compute the number of nonzero voxels  * sigma      =   Compute the standard deviation of nonzero                   voxels  Statistics that include zero-valued voxels:   * zerominmax =   Compute the min/max of all voxels.  * zerosigma  =   Compute the standard deviation of all                   voxels.  * zeromedian =   Compute the median of all voxels.  * zeromode   =   Compute the mode of all voxels.  * summary    =   Only output a summary line with the grand                   mean across all briks in the input dataset.                   This option cannot be used with nomeanout.  More that one option can be specified.
+    out_file: generic/file
+    # type=file: output tab-separated values file
+    # type=file|default=<undefined>: output file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -110,15 +109,15 @@
     # type=file: output tab-separated values file
     # type=file|default=<undefined>: output file
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -131,20 +130,20 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input dataset
     mask_file:
     # type=file|default=<undefined>: input mask
-    stat: '["mean", "median", "voxels"]'
+    stat:
     # type=inputmultiobject|default=[]: Statistics to compute. Options include:   * mean       =   Compute the mean using only non_zero voxels.                   Implies the opposite for the mean computed                   by default.  * median     =   Compute the median of nonzero voxels  * mode       =   Compute the mode of nonzero voxels.                   (integral valued sets only)  * minmax     =   Compute the min/max of nonzero voxels  * sum        =   Compute the sum using only nonzero voxels.  * voxels     =   Compute the number of nonzero voxels  * sigma      =   Compute the standard deviation of nonzero                   voxels  Statistics that include zero-valued voxels:   * zerominmax =   Compute the min/max of all voxels.  * zerosigma  =   Compute the standard deviation of all                   voxels.  * zeromedian =   Compute the median of all voxels.  * zeromode   =   Compute the mode of all voxels.  * summary    =   Only output a summary line with the grand                   mean across all briks in the input dataset.                   This option cannot be used with nomeanout.  More that one option can be specified.
     nomeanout: 'True'
     # type=bool|default=False: Do not include the (zero-inclusive) mean among computed stats
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -161,16 +160,16 @@
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input dataset
     mask_file:
     # type=file|default=<undefined>: input mask
-    stat: '["mean", "median", "voxels"]'
+    stat:
     # type=inputmultiobject|default=[]: Statistics to compute. Options include:   * mean       =   Compute the mean using only non_zero voxels.                   Implies the opposite for the mean computed                   by default.  * median     =   Compute the median of nonzero voxels  * mode       =   Compute the mode of nonzero voxels.                   (integral valued sets only)  * minmax     =   Compute the min/max of nonzero voxels  * sum        =   Compute the sum using only nonzero voxels.  * voxels     =   Compute the number of nonzero voxels  * sigma      =   Compute the standard deviation of nonzero                   voxels  Statistics that include zero-valued voxels:   * zerominmax =   Compute the min/max of all voxels.  * zerosigma  =   Compute the standard deviation of all                   voxels.  * zeromedian =   Compute the median of all voxels.  * zeromode   =   Compute the mode of all voxels.  * summary    =   Only output a summary line with the grand                   mean across all briks in the input dataset.                   This option cannot be used with nomeanout.  More that one option can be specified.
     nomeanout: 'True'
     # type=bool|default=False: Do not include the (zero-inclusive) mean among computed stats
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/seg.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/seg.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -35,17 +35,14 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: ANAT is the volume to segment
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -91,15 +88,15 @@
     main_N:
     # type=int|default=0: Number of iterations to perform.
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -113,15 +110,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: ANAT is the volume to segment
     mask: '"AUTO"'
     # type=traitcompound|default=None: only non-zero voxels in mask are analyzed. mask can either be a dataset or the string "AUTO" which would use AFNI's automask function to create the mask.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -139,11 +136,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: ANAT is the volume to segment
     mask: '"AUTO"'
     # type=traitcompound|default=None: only non-zero voxels in mask are analyzed. mask can either be a dataset or the string "AUTO" which would use AFNI's automask function to create the mask.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/skull_strip.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/skull_strip.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -35,20 +35,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dSkullStrip
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -82,15 +79,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -104,15 +101,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dSkullStrip
     args: '"-o_ply"'
     # type=str|default='': Additional parameters to the command
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -130,11 +127,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dSkullStrip
     args: '"-o_ply"'
     # type=str|default='': Additional parameters to the command
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/svm_test.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svm_test.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -34,22 +34,19 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: generic/file
     # type=file|default=<undefined>: A 3D or 3D+t AFNI brik dataset to be used for testing.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: filename for .1D prediction file(s).
     testlabels: generic/file
     # type=file|default=<undefined>: *true* class category .1D labels for the test dataset. It is used to calculate the prediction accuracy performance
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -97,15 +94,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test,
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/svm_train.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/svm_train.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -34,56 +34,53 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    alphas: Path
-    # type=file: output alphas file name
-    # type=file|default=<undefined>: output alphas file name
-    censor: generic/file
-    # type=file|default=<undefined>: .1D censor file that allows the user to ignore certain samples in the training data.
     in_file: generic/file
     # type=file|default=<undefined>: A 3D+t AFNI brik dataset to be used for training.
-    mask: generic/file
-    # type=file|default=<undefined>: byte-format brik file used to mask voxels in the analysis
-    model: Path
-    # type=file: brik containing the SVM model file name
-    # type=file|default=<undefined>: basename for the brik containing the SVM model
-    out_file: Path
+    out_file: generic/file
     # type=file: sum of weighted linear support vectors file name
     # type=file|default=<undefined>: output sum of weighted linear support vectors file name
+    model: generic/file
+    # type=file: brik containing the SVM model file name
+    # type=file|default=<undefined>: basename for the brik containing the SVM model
+    alphas: generic/file
+    # type=file: output alphas file name
+    # type=file|default=<undefined>: output alphas file name
+    mask: generic/file
+    # type=file|default=<undefined>: byte-format brik file used to mask voxels in the analysis
     trainlabels: generic/file
     # type=file|default=<undefined>: .1D labels corresponding to the stimulus paradigm for the training data.
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    censor: generic/file
+    # type=file|default=<undefined>: .1D censor file that allows the user to ignore certain samples in the training data.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    alphas: generic/file
-    # type=file: output alphas file name
-    # type=file|default=<undefined>: output alphas file name
-    model: generic/file
-    # type=file: brik containing the SVM model file name
-    # type=file|default=<undefined>: basename for the brik containing the SVM model
     out_file: generic/file
     # type=file: sum of weighted linear support vectors file name
     # type=file|default=<undefined>: output sum of weighted linear support vectors file name
+    model: generic/file
+    # type=file: brik containing the SVM model file name
+    # type=file|default=<undefined>: basename for the brik containing the SVM model
+    alphas: generic/file
+    # type=file: output alphas file name
+    # type=file|default=<undefined>: output alphas file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -125,15 +122,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test,
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/synthesize.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/synthesize.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -38,20 +38,17 @@
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
     cbucket: medimage/nifti1
     # type=file|default=<undefined>: Read the dataset output from 3dDeconvolve via the '-cbucket' option.
     matrix: medimage-afni/one-d
     # type=file|default=<undefined>: Read the matrix output from 3dDeconvolve via the '-x1D' option.
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'syn')
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -95,15 +92,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -119,15 +116,15 @@
       cbucket:
       # type=file|default=<undefined>: Read the dataset output from 3dDeconvolve via the '-cbucket' option.
       matrix:
       # type=file|default=<undefined>: Read the matrix output from 3dDeconvolve via the '-x1D' option.
       select: '["baseline"]'
       # type=list|default=[]: A list of selected columns from the matrix (and the corresponding coefficient sub-bricks from the cbucket). Valid types include 'baseline',  'polort', 'allfunc', 'allstim', 'all', Can also provide 'something' where something matches a stim_label from 3dDeconvolve, and 'digits' where digits are the numbers of the select matrix columns by numbers (starting at 0), or number ranges of the form '3..7' and '3-7'.
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -147,11 +144,11 @@
       cbucket:
       # type=file|default=<undefined>: Read the dataset output from 3dDeconvolve via the '-cbucket' option.
       matrix:
       # type=file|default=<undefined>: Read the matrix output from 3dDeconvolve via the '-x1D' option.
       select: '["baseline"]'
       # type=list|default=[]: A list of selected columns from the matrix (and the corresponding coefficient sub-bricks from the cbucket). Valid types include 'baseline',  'polort', 'allfunc', 'allstim', 'all', Can also provide 'something' where something matches a stim_label from 3dDeconvolve, and 'digits' where digits are the numbers of the select matrix columns by numbers (starting at 0), or number ranges of the form '3..7' and '3-7'.
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_cat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_cat.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -37,20 +37,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_files: medimage/nifti1+list-of
     # type=inputmultiobject|default=[]: input file to 3dTcat
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -88,15 +85,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -107,21 +104,21 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_files:
     # type=inputmultiobject|default=[]: input file to 3dTcat
-    out_file: '"functional_tcat.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     rlt: '"+"'
     # type=enum|default=''|allowed['','+','++']: Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -136,17 +133,17 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_files:
     # type=inputmultiobject|default=[]: input file to 3dTcat
-    out_file: '"functional_tcat.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     rlt: '"+"'
     # type=enum|default=''|allowed['','+','++']: Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_cat_sub_brick.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_cat_sub_brick.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -33,20 +33,14 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -85,15 +79,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -110,15 +104,15 @@
     # type=list|default=[]: List of tuples of file names and subbrick selectors as strings.Don't forget to protect the single quotes in the subbrick selectorso the contents are protected from the command line interpreter.
     out_file: '"functional_tcat.nii"'
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     rlt: '"+"'
     # type=enum|default=''|allowed['','+','++']: Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -139,11 +133,11 @@
     # type=list|default=[]: List of tuples of file names and subbrick selectors as strings.Don't forget to protect the single quotes in the subbrick selectorso the contents are protected from the command line interpreter.
     out_file: '"functional_tcat.nii"'
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     rlt: '"+"'
     # type=enum|default=''|allowed['','+','++']: Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_corr_1d.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_corr_1d.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -30,24 +30,21 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    out_file: Path
-    # type=file: output file containing correlations
-    # type=file|default=<undefined>: output filename prefix
     xset: medimage/nifti1
     # type=file|default=<undefined>: 3d+time dataset input
     y_1d: medimage-afni/one-d
     # type=file|default=<undefined>: 1D time series file input
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: generic/file
+    # type=file: output file containing correlations
+    # type=file|default=<undefined>: output filename prefix
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -91,15 +88,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -113,15 +110,15 @@
       # dict[str, str] - values to provide to inputs fields in the task initialisation
       # (if not specified, will try to choose a sensible value)
       xset:
       # type=file|default=<undefined>: 3d+time dataset input
       y_1d:
       # type=file|default=<undefined>: 1D time series file input
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -139,11 +136,11 @@
       # If the field is of file-format type and the value is None, then the
       # '.mock()' method of the corresponding class is used instead.
       xset:
       # type=file|default=<undefined>: 3d+time dataset input
       y_1d:
       # type=file|default=<undefined>: 1D time series file input
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_corr_map.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_corr_map.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -34,116 +34,113 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    absolute_threshold: Path
-    # type=file: 
+    in_file: medimage/nifti1
     # type=file|default=<undefined>: 
-    average_expr: Path
-    # type=file: 
+    seeds: generic/file
     # type=file|default=<undefined>: 
-    average_expr_nonzero: Path
-    # type=file: 
+    mask: medimage/nifti1
     # type=file|default=<undefined>: 
-    correlation_maps: Path
-    # type=file: 
+    regress_out_timeseries: generic/file
     # type=file|default=<undefined>: 
-    correlation_maps_masked: Path
+    mean_file: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    histogram: Path
+    zmean: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    in_file: medimage/nifti1
+    qmean: generic/file
+    # type=file: 
     # type=file|default=<undefined>: 
-    mask: medimage/nifti1
+    pmean: generic/file
+    # type=file: 
     # type=file|default=<undefined>: 
-    mean_file: Path
+    absolute_threshold: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    out_file: Path
-    # type=file|default=<undefined>: output image file name
-    pmean: Path
+    var_absolute_threshold: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    qmean: Path
+    var_absolute_threshold_normalize: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    regress_out_timeseries: generic/file
+    correlation_maps: generic/file
+    # type=file: 
     # type=file|default=<undefined>: 
-    seeds: generic/file
+    correlation_maps_masked: generic/file
+    # type=file: 
     # type=file|default=<undefined>: 
-    sum_expr: Path
+    average_expr: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    var_absolute_threshold: Path
+    average_expr_nonzero: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    var_absolute_threshold_normalize: Path
+    sum_expr: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    zmean: Path
+    histogram: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: generic/file
+    # type=file|default=<undefined>: output image file name
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    absolute_threshold: generic/file
+    mean_file: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    average_expr: generic/file
+    zmean: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    average_expr_nonzero: generic/file
+    qmean: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    correlation_maps: generic/file
+    pmean: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    correlation_maps_masked: generic/file
+    absolute_threshold: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    histogram: generic/file
+    var_absolute_threshold: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    mean_file: generic/file
+    var_absolute_threshold_normalize: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    pmean: generic/file
+    correlation_maps: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    qmean: generic/file
+    correlation_maps_masked: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    sum_expr: generic/file
+    average_expr: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    var_absolute_threshold: generic/file
+    average_expr_nonzero: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    var_absolute_threshold_normalize: generic/file
+    sum_expr: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
-    zmean: generic/file
+    histogram: generic/file
     # type=file: 
     # type=file|default=<undefined>: 
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
@@ -160,15 +157,15 @@
     mask:
     # type=file|default=<undefined>: 
     automask:
     # type=bool|default=False: 
     polort:
     # type=int|default=0: 
     bandpass:
-    # type=tuple|default=(<traits.trait_types.Float object at 0x1154b5c50>, <traits.trait_types.Float object at 0x1154b57d0>): 
+    # type=tuple|default=(<traits.trait_types.Float object at 0x11228fdf0>, <traits.trait_types.Float object at 0x11228fe50>): 
     regress_out_timeseries:
     # type=file|default=<undefined>: 
     blur_fwhm:
     # type=float|default=0.0: 
     seeds_width:
     # type=float|default=0.0: 
     mean_file:
@@ -223,15 +220,15 @@
     out_file:
     # type=file|default=<undefined>: output image file name
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -245,15 +242,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: 
     mask:
     # type=file|default=<undefined>: 
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -271,11 +268,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: 
     mask:
     # type=file|default=<undefined>: 
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_correlate.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_correlate.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -35,24 +35,21 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
     xset: medimage/nifti1
     # type=file|default=<undefined>: input xset
     yset: medimage/nifti1
     # type=file|default=<undefined>: input yset
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    out_file: medimage/nifti-gz
+    # type=file: output file
+    # type=file|default=<undefined>: output image file name
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -92,15 +89,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -113,23 +110,23 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     xset:
     # type=file|default=<undefined>: input xset
     yset:
     # type=file|default=<undefined>: input yset
-    out_file: '"functional_tcorrelate.nii.gz"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     polort: '-1'
     # type=int|default=0: Remove polynomical trend of order m
     pearson: 'True'
     # type=bool|default=False: Correlation is the normal Pearson correlation coefficient
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -146,19 +143,19 @@
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     xset:
     # type=file|default=<undefined>: input xset
     yset:
     # type=file|default=<undefined>: input yset
-    out_file: '"functional_tcorrelate.nii.gz"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     polort: '-1'
     # type=int|default=0: Remove polynomical trend of order m
     pearson: 'True'
     # type=bool|default=False: Correlation is the normal Pearson correlation coefficient
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_norm.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_norm.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -3,156 +3,153 @@
 #
 # Please fill-in/edit the fields below where appropriate
 #
 # Docs
 # ----
 # Shifts voxel time series from input so that separate slices are aligned
 #     to the same temporal origin.
-# 
+#
 #     For complete details, see the `3dTnorm Documentation.
 #     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dTnorm.html>`_
-# 
+#
 #     Examples
 #     --------
 #     >>> from nipype.interfaces import afni
 #     >>> tnorm = afni.TNorm()
 #     >>> tnorm.inputs.in_file = 'functional.nii'
 #     >>> tnorm.inputs.norm2 = True
 #     >>> tnorm.inputs.out_file = 'rm.errts.unit errts+tlrc'
 #     >>> tnorm.cmdline
 #     '3dTnorm -norm2 -prefix rm.errts.unit errts+tlrc functional.nii'
 #     >>> res = tshift.run()  # doctest: +SKIP
-# 
-#     
+#
+#
 task_name: TNorm
 nipype_name: TNorm
 nipype_module: nipype.interfaces.afni.preprocess
 inputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
-  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
-  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
-  # from the nipype interface, but you may want to be more specific, particularly
-  # for file types, where specifying the format also specifies the file that will be
-  # passed to the field in the automatically generated unittests.
+    # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
+    # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
+    # from the nipype interface, but you may want to be more specific, particularly
+    # for file types, where specifying the format also specifies the file that will be
+    # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dTNorm
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
-  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
-  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
-  # from the nipype interface, but you may want to be more specific, particularly
-  # for file types, where specifying the format also specifies the file that will be
-  # passed to the field in the automatically generated unittests.
+    # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
+    # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
+    # from the nipype interface, but you may want to be more specific, particularly
+    # for file types, where specifying the format also specifies the file that will be
+    # passed to the field in the automatically generated unittests.
     out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
-- inputs:
-  # dict[str, str] - values to provide to inputs fields in the task initialisation
-  # (if not specified, will try to choose a sensible value)
-    in_file:
-    # type=file|default=<undefined>: input file to 3dTNorm
-    out_file:
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-    norm2:
-    # type=bool|default=False: L2 normalize (sum of squares = 1) [DEFAULT]
-    normR:
-    # type=bool|default=False: normalize so sum of squares = number of time points \* e.g., so RMS = 1.
-    norm1:
-    # type=bool|default=False: L1 normalize (sum of absolute values = 1)
-    normx:
-    # type=bool|default=False: Scale so max absolute value = 1 (L_infinity norm)
-    polort:
-    # type=int|default=0: Detrend with polynomials of order p before normalizing [DEFAULT = don't do this]. Use '-polort 0' to remove the mean, for example
-    L1fit:
-    # type=bool|default=False: Detrend with L1 regression (L2 is the default) This option is here just for the hell of it
-    num_threads:
-    # type=int|default=1: set number of threads
-    outputtype:
-    # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
-    args:
-    # type=str|default='': Additional parameters to the command
-    environ:
-    # type=dict|default={}: Environment variables
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  expected_outputs:
-  # dict[str, str] - expected values for selected outputs, noting that tests will typically
-  # be terminated before they complete for time-saving reasons, and therefore
-  # these values will be ignored, when running in CI
-  timeout: 10
-  # int - the value to set for the timeout in the generated test, 
-  # after which the test will be considered to have been initialised 
-  # successfully. Set to 0 to disable the timeout (warning, this could
-  # lead to the unittests taking a very long time to complete)
-  xfail: true
-  # bool - whether the unittest is expected to fail or not. Set to false
-  # when you are satisfied with the edits you have made to this file
-- inputs:
-  # dict[str, str] - values to provide to inputs fields in the task initialisation
-  # (if not specified, will try to choose a sensible value)
-    in_file:
-    # type=file|default=<undefined>: input file to 3dTNorm
-    norm2: 'True'
-    # type=bool|default=False: L2 normalize (sum of squares = 1) [DEFAULT]
-    out_file: '"rm.errts.unit errts+tlrc"'
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  expected_outputs:
-  # dict[str, str] - expected values for selected outputs, noting that tests will typically
-  # be terminated before they complete for time-saving reasons, and therefore
-  # these values will be ignored, when running in CI
-  timeout: 10
-  # int - the value to set for the timeout in the generated test, 
-  # after which the test will be considered to have been initialised 
-  # successfully. Set to 0 to disable the timeout (warning, this could
-  # lead to the unittests taking a very long time to complete)
-  xfail: true
-  # bool - whether the unittest is expected to fail or not. Set to false
-  # when you are satisfied with the edits you have made to this file
+  - inputs:
+      # dict[str, str] - values to provide to inputs fields in the task initialisation
+      # (if not specified, will try to choose a sensible value)
+      in_file:
+      # type=file|default=<undefined>: input file to 3dTNorm
+      out_file:
+      # type=file: output file
+      # type=file|default=<undefined>: output image file name
+      norm2:
+      # type=bool|default=False: L2 normalize (sum of squares = 1) [DEFAULT]
+      normR:
+      # type=bool|default=False: normalize so sum of squares = number of time points \* e.g., so RMS = 1.
+      norm1:
+      # type=bool|default=False: L1 normalize (sum of absolute values = 1)
+      normx:
+      # type=bool|default=False: Scale so max absolute value = 1 (L_infinity norm)
+      polort:
+      # type=int|default=0: Detrend with polynomials of order p before normalizing [DEFAULT = don't do this]. Use '-polort 0' to remove the mean, for example
+      L1fit:
+      # type=bool|default=False: Detrend with L1 regression (L2 is the default) This option is here just for the hell of it
+      num_threads:
+      # type=int|default=1: set number of threads
+      outputtype:
+      # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
+      args:
+      # type=str|default='': Additional parameters to the command
+      environ:
+      # type=dict|default={}: Environment variables
+    imports:
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+    # consisting of 'module', 'name', and optionally 'alias' keys
+    expected_outputs:
+    # dict[str, str] - expected values for selected outputs, noting that tests will typically
+    # be terminated before they complete for time-saving reasons, and therefore
+    # these values will be ignored, when running in CI
+    timeout: 10
+    # int - the value to set for the timeout in the generated test,
+    # after which the test will be considered to have been initialised
+    # successfully. Set to 0 to disable the timeout (warning, this could
+    # lead to the unittests taking a very long time to complete)
+    xfail: true
+    # bool - whether the unittest is expected to fail or not. Set to false
+    # when you are satisfied with the edits you have made to this file
+  - inputs:
+      # dict[str, str] - values to provide to inputs fields in the task initialisation
+      # (if not specified, will try to choose a sensible value)
+      in_file:
+      # type=file|default=<undefined>: input file to 3dTNorm
+      norm2: "True"
+      # type=bool|default=False: L2 normalize (sum of squares = 1) [DEFAULT]
+      out_file:
+      # type=file: output file
+      # type=file|default=<undefined>: output image file name
+    imports:
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+    # consisting of 'module', 'name', and optionally 'alias' keys
+    expected_outputs:
+    # dict[str, str] - expected values for selected outputs, noting that tests will typically
+    # be terminated before they complete for time-saving reasons, and therefore
+    # these values will be ignored, when running in CI
+    timeout: 10
+    # int - the value to set for the timeout in the generated test,
+    # after which the test will be considered to have been initialised
+    # successfully. Set to 0 to disable the timeout (warning, this could
+    # lead to the unittests taking a very long time to complete)
+    xfail: true
+    # bool - whether the unittest is expected to fail or not. Set to false
+    # when you are satisfied with the edits you have made to this file
 doctests:
-- cmdline: 3dTnorm -norm2 -prefix rm.errts.unit errts+tlrc functional.nii
-  # str - the expected cmdline output
-  inputs:
-  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
-  # If the field is of file-format type and the value is None, then the
-  # '.mock()' method of the corresponding class is used instead.
-    in_file:
-    # type=file|default=<undefined>: input file to 3dTNorm
-    norm2: 'True'
-    # type=bool|default=False: L2 normalize (sum of squares = 1) [DEFAULT]
-    out_file: '"rm.errts.unit errts+tlrc"'
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  directive:
-  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
+  - cmdline: 3dTnorm -norm2 -prefix rm.errts.unit errts+tlrc functional.nii
+    # str - the expected cmdline output
+    inputs:
+      # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
+      # If the field is of file-format type and the value is None, then the
+      # '.mock()' method of the corresponding class is used instead.
+      in_file:
+      # type=file|default=<undefined>: input file to 3dTNorm
+      norm2: "True"
+      # type=bool|default=False: L2 normalize (sum of squares = 1) [DEFAULT]
+      out_file:
+      # type=file: output file
+      # type=file|default=<undefined>: output image file name
+    imports:
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
+    # consisting of 'module', 'name', and optionally 'alias' keys
+    directive:
+    # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_project.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_project.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -44,32 +44,29 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    in_file: medimage/nifti1
+    # type=file|default=<undefined>: input file to 3dTproject
+    out_file: medimage/nifti-gz
+    # type=file: output file
+    # type=file|default=<undefined>: output image file name
     censor: generic/file
     # type=file|default=<undefined>: Filename of censor .1D time series. This is a file of 1s and 0s, indicating which time points are to be included (1) and which are to be excluded (0).
     concat: generic/file
     # type=file|default=<undefined>: The catenation file, as in 3dDeconvolve, containing the TR indexes of the start points for each contiguous run within the input dataset (the first entry should be 0).  * Also as in 3dDeconvolve, if the input dataset is   automatically catenated from a collection of datasets,   then the run start indexes are determined directly,   and '-concat' is not needed (and will be ignored). * Each run must have at least 9 time points AFTER   censoring, or the program will not work! * The only use made of this input is in setting up   the bandpass/stopband regressors. * '-ort' and '-dsort' regressors run through all time   points, as read in.  If you want separate projections   in each run, then you must either break these ort files   into appropriate components, OR you must run 3dTproject   for each run separately, using the appropriate pieces   from the ort files via the ``{...}`` selector for the   1D files and the ``[...]`` selector for the datasets.  
+    ort: generic/file
+    # type=file|default=<undefined>: Remove each column in file. Each column will have its mean removed.
     dsort: generic/file+list-of
     # type=inputmultiobject|default=[]: Remove the 3D+time time series in dataset fset.  * That is, 'fset' contains a different nuisance time   series for each voxel (e.g., from AnatICOR). * Multiple -dsort options are allowed.  
-    in_file: medimage/nifti1
-    # type=file|default=<undefined>: input file to 3dTproject
     mask: generic/file
     # type=file|default=<undefined>: Only operate on voxels nonzero in the mset dataset.  * Voxels outside the mask will be filled with zeros. * If no masking option is given, then all voxels   will be processed.  
-    ort: generic/file
-    # type=file|default=<undefined>: Remove each column in file. Each column will have its mean removed.
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -133,15 +130,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -158,19 +155,19 @@
     # type=file|default=<undefined>: input file to 3dTproject
     bandpass: (0.00667, 99999)
     # type=tuple|default=(0.0, 0.0): Remove all frequencies EXCEPT those in the range
     polort: '3'
     # type=int|default=0: Remove polynomials up to and including degree pp.  * Default value is 2. * It makes no sense to use a value of pp greater than   2, if you are bandpassing out the lower frequencies! * For catenated datasets, each run gets a separate set   set of pp+1 Legendre polynomial regressors. * Use of -polort -1 is not advised (if data mean != 0),   even if -ort contains constant terms, as all means are   removed.  
     automask: 'True'
     # type=bool|default=False: Generate a mask automatically
-    out_file: '"projected.nii.gz"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -191,15 +188,15 @@
     # type=file|default=<undefined>: input file to 3dTproject
     bandpass: (0.00667, 99999)
     # type=tuple|default=(0.0, 0.0): Remove all frequencies EXCEPT those in the range
     polort: '3'
     # type=int|default=0: Remove polynomials up to and including degree pp.  * Default value is 2. * It makes no sense to use a value of pp greater than   2, if you are bandpassing out the lower frequencies! * For catenated datasets, each run gets a separate set   set of pp+1 Legendre polynomial regressors. * Use of -polort -1 is not advised (if data mean != 0),   even if -ort contains constant terms, as all means are   removed.  
     automask: 'True'
     # type=bool|default=False: Generate a mask automatically
-    out_file: '"projected.nii.gz"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_shift.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_shift.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -105,38 +105,35 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dTshift
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
+    timing_file: generic/file
+    # type=file: AFNI formatted timing file, if ``slice_timing`` is a list
     out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-    timing_file: generic/file
-    # type=file: AFNI formatted timing file, if ``slice_timing`` is a list
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -174,15 +171,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -200,15 +197,15 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     slice_timing: list(np.arange(40) / TR)
     # type=traitcompound|default=None: time offsets from the volume acquisition onset for each slice
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -220,15 +217,15 @@
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     slice_encoding_direction: '"k-"'
     # type=enum|default='k'|allowed['k','k-']: Direction in which slice_timing is specified (default: k). If negative,slice_timing is defined in reverse order, that is, the first entry corresponds to the slice with the largest index, and the final entry corresponds to slice index zero. Only in effect when slice_timing is passed as list, not when it is passed as file.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -246,15 +243,15 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     slice_timing: '"slice_timing.1D"'
     # type=traitcompound|default=None: time offsets from the volume acquisition onset for each slice
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -272,15 +269,15 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     tpattern: '"alt+z"'
     # type=traitcompound|default=None: use specified slice time pattern rather than one in header
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -298,15 +295,15 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     tpattern: '"@slice_timing.1D"'
     # type=traitcompound|default=None: use specified slice time pattern rather than one in header
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -328,28 +325,28 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     slice_timing: list(np.arange(40) / TR)
     # type=traitcompound|default=None: time offsets from the volume acquisition onset for each slice
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii" >>> np.loadtxt(tshift._list_outputs()["timing_file
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     slice_encoding_direction: '"k-"'
     # type=enum|default='k'|allowed['k','k-']: Direction in which slice_timing is specified (default: k). If negative,slice_timing is defined in reverse order, that is, the first entry corresponds to the slice with the largest index, and the final entry corresponds to slice index zero. Only in effect when slice_timing is passed as list, not when it is passed as file.
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -360,15 +357,15 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     slice_timing: '"slice_timing.1D"'
     # type=traitcompound|default=None: time offsets from the volume acquisition onset for each slice
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dTshift -prefix functional_tshift -tpattern alt+z -TR 2.5s -tzero 0.0 functional.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -379,15 +376,15 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     tpattern: '"alt+z"'
     # type=traitcompound|default=None: use specified slice time pattern rather than one in header
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -398,11 +395,11 @@
     tzero: '0.0'
     # type=float|default=0.0: align each slice to given time offset
     tr: '"%.1fs" % TR'
     # type=str|default='': manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.
     tpattern: '"@slice_timing.1D"'
     # type=traitcompound|default=None: use specified slice time pattern rather than one in header
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_smooth.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/t_smooth.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -33,24 +33,21 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    custom: generic/file
-    # type=file|default=<undefined>: odd # of coefficients must be in a single column in ASCII file
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dTSmooth
-    out_file: Path
+    out_file: generic/file
     # type=file: output file
     # type=file|default=<undefined>: output file from 3dTSmooth
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    custom: generic/file
+    # type=file|default=<undefined>: odd # of coefficients must be in a single column in ASCII file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -102,15 +99,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -124,15 +121,15 @@
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dTSmooth
     adaptive: '5'
     # type=int|default=0: use adaptive mean filtering of width N (where N must be odd and bigger than 3).
   imports: &id001
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   - module: nipype.testing
     name: ' example_data'
     alias:
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
@@ -153,11 +150,11 @@
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dTSmooth
     adaptive: '5'
     # type=int|default=0: use adaptive mean filtering of width N (where N must be odd and bigger than 3).
   imports: *id001
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/t_stat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/z_cut_up.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -1,101 +1,94 @@
 # This file is used to manually specify the semi-automatic conversion of
-# 'nipype.interfaces.afni.utils.TStat' from Nipype to Pydra.
+# 'nipype.interfaces.afni.utils.ZCutUp' from Nipype to Pydra.
 #
 # Please fill-in/edit the fields below where appropriate
 #
 # Docs
 # ----
-# Compute voxel-wise statistics using AFNI 3dTstat command
+# Cut z-slices from a volume using AFNI 3dZcutup command
 # 
-#     For complete details, see the `3dTstat Documentation.
-#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dTstat.html>`_
+#     For complete details, see the `3dZcutup Documentation.
+#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dZcutup.html>`_
 # 
 #     Examples
 #     --------
 #     >>> from nipype.interfaces import afni
-#     >>> tstat = afni.TStat()
-#     >>> tstat.inputs.in_file = 'functional.nii'
-#     >>> tstat.inputs.args = '-mean'
-#     >>> tstat.inputs.out_file = 'stats'
-#     >>> tstat.cmdline
-#     '3dTstat -mean -prefix stats functional.nii'
-#     >>> res = tstat.run()  # doctest: +SKIP
+#     >>> zcutup = afni.ZCutUp()
+#     >>> zcutup.inputs.in_file = 'functional.nii'
+#     >>> zcutup.inputs.out_file = 'functional_zcutup.nii'
+#     >>> zcutup.inputs.keep= '0 10'
+#     >>> zcutup.cmdline
+#     '3dZcutup -keep 0 10 -prefix functional_zcutup.nii functional.nii'
+#     >>> res = zcutup.run()  # doctest: +SKIP
 # 
 #     
-task_name: TStat
-nipype_name: TStat
+task_name: ZCutUp
+nipype_name: ZCutUp
 nipype_module: nipype.interfaces.afni.utils
 inputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
-    # type=file|default=<undefined>: input file to 3dTstat
-    mask: generic/file
-    # type=file|default=<undefined>: mask file
-    out_file: Path
+    # type=file|default=<undefined>: input file to 3dZcutup
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: generic/file
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
-    # type=file|default=<undefined>: input file to 3dTstat
+    # type=file|default=<undefined>: input file to 3dZcutup
     out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-    mask:
-    # type=file|default=<undefined>: mask file
-    options:
-    # type=str|default='': selected statistical output
+    keep:
+    # type=str|default='': slice range to keep in output
     num_threads:
     # type=int|default=1: set number of threads
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -105,47 +98,47 @@
   xfail: true
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
-    # type=file|default=<undefined>: input file to 3dTstat
-    args: '"-mean"'
-    # type=str|default='': Additional parameters to the command
-    out_file: '"stats"'
+    # type=file|default=<undefined>: input file to 3dZcutup
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
+    keep: '"0 10"'
+    # type=str|default='': slice range to keep in output
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
   # after which the test will be considered to have been initialised 
   # successfully. Set to 0 to disable the timeout (warning, this could
   # lead to the unittests taking a very long time to complete)
   xfail: true
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 doctests:
-- cmdline: 3dTstat -mean -prefix stats functional.nii
+- cmdline: 3dZcutup -keep 0 10 -prefix functional_zcutup.nii functional.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
-    # type=file|default=<undefined>: input file to 3dTstat
-    args: '"-mean"'
-    # type=str|default='': Additional parameters to the command
-    out_file: '"stats"'
+    # type=file|default=<undefined>: input file to 3dZcutup
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
+    keep: '"0 10"'
+    # type=str|default='': slice range to keep in output
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/to_3d.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/to_3d.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -33,22 +33,17 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    in_folder: generic/directory
-    # type=directory|default=<undefined>: folder with DICOM images to convert
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -92,15 +87,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -113,21 +108,21 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     datatype: '"float"'
     # type=enum|default='short'|allowed['byte','complex','float','short']: set output file datatype
     in_folder: '"."'
     # type=directory|default=<undefined>: folder with DICOM images to convert
-    out_file: '"dicomdir.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     filetype: '"anat"'
     # type=enum|default='spgr'|allowed['abuc','anat','bmap','ct','diff','epan','fbuc','fibn','fibt','fico','fict','fift','figt','fim','fipt','fith','fitt','fizt','fse','mra','omri','pet','spct','spgr']: type of datafile being converted
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -144,17 +139,17 @@
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     datatype: '"float"'
     # type=enum|default='short'|allowed['byte','complex','float','short']: set output file datatype
     in_folder: '"."'
     # type=directory|default=<undefined>: folder with DICOM images to convert
-    out_file: '"dicomdir.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output image file name
     filetype: '"anat"'
     # type=enum|default='spgr'|allowed['abuc','anat','bmap','ct','diff','epan','fbuc','fibn','fibt','fico','fict','fift','figt','fim','fipt','fith','fitt','fizt','fse','mra','omri','pet','spct','spgr']: type of datafile being converted
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/undump.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/undump.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -51,22 +51,19 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dUndump, whose geometry will determinethe geometry of the output
-    mask_file: generic/file
-    # type=file|default=<undefined>: mask image file name. Only voxels that are nonzero in the mask can be set.
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: assembled file
     # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    mask_file: generic/file
+    # type=file|default=<undefined>: mask image file name. Only voxels that are nonzero in the mask can be set.
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -116,15 +113,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -135,19 +132,19 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dUndump, whose geometry will determinethe geometry of the output
-    out_file: '"structural_undumped.nii"'
+    out_file:
     # type=file: assembled file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -162,15 +159,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dUndump, whose geometry will determinethe geometry of the output
-    out_file: '"structural_undumped.nii"'
+    out_file:
     # type=file: assembled file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/unifize.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/unifize.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -58,42 +58,39 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dUnifize
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: unifized file
     # type=file|default=<undefined>: output image file name
-    scale_file: Path
+    scale_file: generic/file
     # type=file: scale factor file
     # type=file|default=<undefined>: output file name to save the scale factor used at each voxel 
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: medimage/nifti1
-    # type=file: unifized file
-    # type=file|default=<undefined>: output image file name
     scale_file: generic/file
     # type=file: scale factor file
     # type=file|default=<undefined>: output file name to save the scale factor used at each voxel 
+    out_file: medimage/nifti1
+    # type=file: unifized file
+    # type=file|default=<undefined>: output image file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -132,15 +129,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -151,19 +148,19 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dUnifize
-    out_file: '"structural_unifized.nii"'
+    out_file:
     # type=file: unifized file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -178,15 +175,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dUnifize
-    out_file: '"structural_unifized.nii"'
+    out_file:
     # type=file: unifized file
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/volreg.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/volreg.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -47,58 +47,55 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
-    basefile: medimage/nifti1
-    # type=file|default=<undefined>: base file for registration
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dvolreg
-    md1d_file: Path
+    out_file: medimage-afni/r1
+    # type=file: registered file
+    # type=file|default=<undefined>: output image file name
+    basefile: medimage/nifti1
+    # type=file|default=<undefined>: base file for registration
+    md1d_file: generic/file
     # type=file: max displacement info file
     # type=file|default=<undefined>: max displacement output file
-    oned_file: Path
+    oned_file: medimage-afni/one-d
     # type=file: movement parameters info file
     # type=file|default=<undefined>: 1D movement parameters output file
-    oned_matrix_save: Path
+    oned_matrix_save: medimage-afni/one-d
     # type=file: matrix transformation from base to input
     # type=file|default=<undefined>: Save the matrix transformation
-    out_file: Path
-    # type=file: registered file
-    # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
     # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
     # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
     # from the nipype interface, but you may want to be more specific, particularly
     # for file types, where specifying the format also specifies the file that will be
     # passed to the field in the automatically generated unittests.
+    out_file: medimage-afni/r1
+    # type=file: registered file
+    # type=file|default=<undefined>: output image file name
     md1d_file: generic/file
     # type=file: max displacement info file
     # type=file|default=<undefined>: max displacement output file
     oned_file: medimage-afni/one-d
     # type=file: movement parameters info file
     # type=file|default=<undefined>: 1D movement parameters output file
     oned_matrix_save: medimage-afni/one-d
     # type=file: matrix transformation from base to input
     # type=file|default=<undefined>: Save the matrix transformation
-    out_file: medimage-afni/r1
-    # type=file: registered file
-    # type=file|default=<undefined>: output image file name
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
@@ -139,15 +136,15 @@
       outputtype:
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
       args:
       # type=str|default='': Additional parameters to the command
       environ:
       # type=dict|default={}: Environment variables
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -165,15 +162,15 @@
       args: '"-Fourier -twopass"'
       # type=str|default='': Additional parameters to the command
       zpad: "4"
       # type=int|default=0: Zeropad around the edges by 'n' voxels during rotations
       outputtype: '"NIFTI"'
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -192,25 +189,25 @@
       # type=enum|default='Fourier'|allowed['Fourier','cubic','heptic','linear','quintic']: spatial interpolation methods [default = heptic]
       verbose: "True"
       # type=bool|default=False: more detailed description of the process
       zpad: "1"
       # type=int|default=0: Zeropad around the edges by 'n' voxels during rotations
       basefile:
       # type=file|default=<undefined>: base file for registration
-      out_file: '"rm.epi.volreg.r1"'
+      out_file:
       # type=file: registered file
       # type=file|default=<undefined>: output image file name
-      oned_file: '"dfile.r1.1D"'
+      oned_file:
       # type=file: movement parameters info file
       # type=file|default=<undefined>: 1D movement parameters output file
-      oned_matrix_save: '"mat.r1.tshift+orig.1D"'
+      oned_matrix_save:
       # type=file: matrix transformation from base to input
       # type=file|default=<undefined>: Save the matrix transformation
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     expected_outputs:
     # dict[str, str] - expected values for selected outputs, noting that tests will typically
     # be terminated before they complete for time-saving reasons, and therefore
     # these values will be ignored, when running in CI
     timeout: 10
     # int - the value to set for the timeout in the generated test,
@@ -232,15 +229,15 @@
       args: '"-Fourier -twopass"'
       # type=str|default='': Additional parameters to the command
       zpad: "4"
       # type=int|default=0: Zeropad around the edges by 'n' voxels during rotations
       outputtype: '"NIFTI"'
       # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
   - cmdline: 3dvolreg -cubic -1Dfile dfile.r1.1D -1Dmatrix_save mat.r1.tshift+orig.1D -prefix rm.epi.volreg.r1 -verbose -base functional.nii -zpad 1 -maxdisp1D functional_md.1D functional.nii
     # str - the expected cmdline output
     inputs:
       # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
@@ -252,21 +249,21 @@
       # type=enum|default='Fourier'|allowed['Fourier','cubic','heptic','linear','quintic']: spatial interpolation methods [default = heptic]
       verbose: "True"
       # type=bool|default=False: more detailed description of the process
       zpad: "1"
       # type=int|default=0: Zeropad around the edges by 'n' voxels during rotations
       basefile:
       # type=file|default=<undefined>: base file for registration
-      out_file: '"rm.epi.volreg.r1"'
+      out_file:
       # type=file: registered file
       # type=file|default=<undefined>: output image file name
-      oned_file: '"dfile.r1.1D"'
+      oned_file:
       # type=file: movement parameters info file
       # type=file|default=<undefined>: 1D movement parameters output file
-      oned_matrix_save: '"mat.r1.tshift+orig.1D"'
+      oned_matrix_save:
       # type=file: matrix transformation from base to input
       # type=file|default=<undefined>: Save the matrix transformation
     imports:
-    # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+    # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
     # consisting of 'module', 'name', and optionally 'alias' keys
     directive:
     # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/warp.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/warp.yaml`

 * *Files 4% similar despite different names*

```diff
@@ -42,28 +42,25 @@
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    gridset: generic/file
-    # type=file|default=<undefined>: copy grid of specified dataset
     in_file: medimage/nifti1
     # type=file|default=<undefined>: input file to 3dWarp
+    out_file: medimage/nifti-gz
+    # type=file: Warped file.
+    # type=file|default=<undefined>: output image file name
     matparent: generic/file
     # type=file|default=<undefined>: apply transformation from 3dWarpDrive
     oblique_parent: generic/file
     # type=file|default=<undefined>: Read in the oblique transformation matrix from an oblique dataset and make cardinal dataset oblique to match
-    out_file: Path
-    # type=file: Warped file.
-    # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    gridset: generic/file
+    # type=file|default=<undefined>: copy grid of specified dataset
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -121,15 +118,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -142,19 +139,19 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dWarp
     deoblique: 'True'
     # type=bool|default=False: transform dataset from oblique to cardinal
-    out_file: '"trans.nii.gz"'
+    out_file:
     # type=file: Warped file.
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -167,19 +164,19 @@
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
     # type=file|default=<undefined>: input file to 3dWarp
     newgrid: '1.0'
     # type=float|default=0.0: specify grid of this size (mm)
-    out_file: '"trans.nii.gz"'
+    out_file:
     # type=file: Warped file.
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -196,33 +193,33 @@
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dWarp
     deoblique: 'True'
     # type=bool|default=False: transform dataset from oblique to cardinal
-    out_file: '"trans.nii.gz"'
+    out_file:
     # type=file: Warped file.
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
 - cmdline: 3dWarp -newgrid 1.000000 -prefix trans.nii.gz structural.nii
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
     # type=file|default=<undefined>: input file to 3dWarp
     newgrid: '1.0'
     # type=float|default=0.0: specify grid of this size (mm)
-    out_file: '"trans.nii.gz"'
+    out_file:
     # type=file: Warped file.
     # type=file|default=<undefined>: output image file name
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/z_cut_up.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/onedtoolpy.yaml`

 * *Files 18% similar despite different names*

```diff
@@ -1,147 +1,136 @@
 # This file is used to manually specify the semi-automatic conversion of
-# 'nipype.interfaces.afni.utils.ZCutUp' from Nipype to Pydra.
+# 'nipype.interfaces.afni.utils.OneDToolPy' from Nipype to Pydra.
 #
 # Please fill-in/edit the fields below where appropriate
 #
+# Inputs
+# ------
+# in_file : file
+#    input file to OneDTool
+# set_nruns : int
+#    treat the input data as if it has nruns
+# derivative : bool
+#    take the temporal derivative of each vector (done as first backward difference)
+# demean : bool
+#    demean each run (new mean of each run = 0.0)
+# out_file : file
+#    write the current 1D data to FILE
+# show_censor_count : bool
+#    display the total number of censored TRs  Note : if input is a valid xmat.1D dataset, then the count will come from the header.  Otherwise the input is assumed to be a binary censorfile, and zeros are simply counted.
+# censor_motion : tuple
+#    Tuple of motion limit and outfile prefix. need to also set set_nruns -r set_run_lengths
+# censor_prev_TR : bool
+#    for each censored TR, also censor previous
+# show_trs_uncensored : enum
+#    display a list of TRs which were not censored in the specified style
+# show_cormat_warnings : file
+#    Write cormat warnings to a file
+# show_indices_interest : bool
+#    display column indices for regs of interest
+# show_trs_run : int
+#    restrict -show_trs_[un]censored to the given 1-based run
+# outputtype : enum
+#    AFNI output filetype
+# py27_path : traitcompound
+#    
+# args : str
+#    Additional parameters to the command
+# environ : dict
+#    Environment variables
+#
+# Outputs
+# -------
+# out_file : file
+#    output of 1D_tool.py
+#
 # Docs
 # ----
-# Cut z-slices from a volume using AFNI 3dZcutup command
-# 
-#     For complete details, see the `3dZcutup Documentation.
-#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dZcutup.html>`_
+# This program is meant to read/manipulate/write/diagnose 1D datasets.
+#     Input can be specified using AFNI sub-brick[]/time{} selectors.
 # 
-#     Examples
-#     --------
 #     >>> from nipype.interfaces import afni
-#     >>> zcutup = afni.ZCutUp()
-#     >>> zcutup.inputs.in_file = 'functional.nii'
-#     >>> zcutup.inputs.out_file = 'functional_zcutup.nii'
-#     >>> zcutup.inputs.keep= '0 10'
-#     >>> zcutup.cmdline
-#     '3dZcutup -keep 0 10 -prefix functional_zcutup.nii functional.nii'
-#     >>> res = zcutup.run()  # doctest: +SKIP
-# 
-#     
-task_name: ZCutUp
-nipype_name: ZCutUp
+#     >>> odt = afni.OneDToolPy()
+#     >>> odt.inputs.in_file = 'f1.1D'
+#     >>> odt.inputs.set_nruns = 3
+#     >>> odt.inputs.demean = True
+#     >>> odt.inputs.out_file = 'motion_dmean.1D'
+#     >>> odt.cmdline # doctest: +ELLIPSIS
+#     'python2 ...1d_tool.py -demean -infile f1.1D -write motion_dmean.1D -set_nruns 3'
+#      >>> res = odt.run()  # doctest: +SKIP
+task_name: one_d_tool_py
+nipype_name: OneDToolPy
 nipype_module: nipype.interfaces.afni.utils
 inputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    in_file: medimage/nifti1
-    # type=file|default=<undefined>: input file to 3dZcutup
-    out_file: Path
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    in_file: generic/file
+    out_file: generic/file
+    show_cormat_warnings: generic/file
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
   types:
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
-    out_file: medimage/nifti1
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
+    out_file: generic/file
   callables:
   # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
   # to set to the `callable` attribute of output fields
   templates:
   # dict[str, str] - `output_file_template` values to be provided to output fields
   requirements:
   # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
 tests:
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_file:
-    # type=file|default=<undefined>: input file to 3dZcutup
+    set_nruns: '3'
+    demean: 'True'
     out_file:
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-    keep:
-    # type=str|default='': slice range to keep in output
-    num_threads:
-    # type=int|default=1: set number of threads
-    outputtype:
-    # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
-    args:
-    # type=str|default='': Additional parameters to the command
-    environ:
-    # type=dict|default={}: Environment variables
-  imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
-  # consisting of 'module', 'name', and optionally 'alias' keys
-  expected_outputs:
-  # dict[str, str] - expected values for selected outputs, noting that tests will typically
-  # be terminated before they complete for time-saving reasons, and therefore
-  # these values will be ignored, when running in CI
-  timeout: 10
-  # int - the value to set for the timeout in the generated test, 
-  # after which the test will be considered to have been initialised 
-  # successfully. Set to 0 to disable the timeout (warning, this could
-  # lead to the unittests taking a very long time to complete)
-  xfail: true
-  # bool - whether the unittest is expected to fail or not. Set to false
-  # when you are satisfied with the edits you have made to this file
-- inputs:
-  # dict[str, str] - values to provide to inputs fields in the task initialisation
-  # (if not specified, will try to choose a sensible value)
-    in_file:
-    # type=file|default=<undefined>: input file to 3dZcutup
-    out_file: '"functional_zcutup.nii"'
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-    keep: '"0 10"'
-    # type=str|default='': slice range to keep in output
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
   # after which the test will be considered to have been initialised 
   # successfully. Set to 0 to disable the timeout (warning, this could
   # lead to the unittests taking a very long time to complete)
   xfail: true
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 doctests:
-- cmdline: 3dZcutup -keep 0 10 -prefix functional_zcutup.nii functional.nii
+- cmdline: python2 ...1d_tool.py -demean -infile f1.1D -write motion_dmean.1D -set_nruns 3
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_file:
-    # type=file|default=<undefined>: input file to 3dZcutup
-    out_file: '"functional_zcutup.nii"'
-    # type=file: output file
-    # type=file|default=<undefined>: output image file name
-    keep: '"0 10"'
-    # type=str|default='': slice range to keep in output
+    set_nruns: '3'
+    demean: 'True'
+    out_file:
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
-  directive:
+  directive: ''''
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/zcat.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zcat.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -34,20 +34,17 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_files: medimage/nifti1+list-of
     # type=inputmultiobject|default=[]: 
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'zcat')
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -89,15 +86,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -108,19 +105,19 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_files:
     # type=inputmultiobject|default=[]: 
-    out_file: '"cat_functional.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'zcat')
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -135,15 +132,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_files:
     # type=inputmultiobject|default=[]: 
-    out_file: '"cat_functional.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'zcat')
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/nipype-auto-conv/specs/zeropad.yaml` & `pydra_afni-0.3.2/nipype-auto-conv/specs/interfaces/zeropad.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -39,22 +39,19 @@
   # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
   # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
   # from the nipype interface, but you may want to be more specific, particularly
   # for file types, where specifying the format also specifies the file that will be
   # passed to the field in the automatically generated unittests.
     in_files: medimage/nifti1
     # type=file|default=<undefined>: input dataset
-    master: generic/file
-    # type=file|default=<undefined>: match the volume described in dataset 'mset', where mset must have the same orientation and grid spacing as dataset to be padded. the goal of -master is to make the output dataset from 3dZeropad match the spatial 'extents' of mset by adding or subtracting slices as needed. You can't use -I,-S,..., or -mm with -master
-    out_file: Path
+    out_file: medimage/nifti1
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'zeropad')
-  callable_defaults:
-  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
-  # to set as the `default` method of input fields
+    master: generic/file
+    # type=file|default=<undefined>: match the volume described in dataset 'mset', where mset must have the same orientation and grid spacing as dataset to be padded. the goal of -master is to make the output dataset from 3dZeropad match the spatial 'extents' of mset by adding or subtracting slices as needed. You can't use -I,-S,..., or -mm with -master
   metadata:
   # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
 outputs:
   omit:
   # list[str] - fields to omit from the Pydra interface
   rename:
   # dict[str, str] - fields to rename in the Pydra interface
@@ -112,15 +109,15 @@
     outputtype:
     # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
     args:
     # type=str|default='': Additional parameters to the command
     environ:
     # type=dict|default={}: Environment variables
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -131,15 +128,15 @@
   # bool - whether the unittest is expected to fail or not. Set to false
   # when you are satisfied with the edits you have made to this file
 - inputs:
   # dict[str, str] - values to provide to inputs fields in the task initialisation
   # (if not specified, will try to choose a sensible value)
     in_files:
     # type=file|default=<undefined>: input dataset
-    out_file: '"pad_functional.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'zeropad')
     I: '10'
     # type=int|default=0: adds 'n' planes of zero at the Inferior edge
     S: '10'
     # type=int|default=0: adds 'n' planes of zero at the Superior edge
     A: '10'
@@ -147,15 +144,15 @@
     P: '10'
     # type=int|default=0: adds 'n' planes of zero at the Posterior edge
     R: '10'
     # type=int|default=0: adds 'n' planes of zero at the Right edge
     L: '10'
     # type=int|default=0: adds 'n' planes of zero at the Left edge
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   expected_outputs:
   # dict[str, str] - expected values for selected outputs, noting that tests will typically
   # be terminated before they complete for time-saving reasons, and therefore
   # these values will be ignored, when running in CI
   timeout: 10
   # int - the value to set for the timeout in the generated test, 
@@ -170,15 +167,15 @@
   # str - the expected cmdline output
   inputs:
   # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
   # If the field is of file-format type and the value is None, then the
   # '.mock()' method of the corresponding class is used instead.
     in_files:
     # type=file|default=<undefined>: input dataset
-    out_file: '"pad_functional.nii"'
+    out_file:
     # type=file: output file
     # type=file|default=<undefined>: output dataset prefix name (default 'zeropad')
     I: '10'
     # type=int|default=0: adds 'n' planes of zero at the Inferior edge
     S: '10'
     # type=int|default=0: adds 'n' planes of zero at the Superior edge
     A: '10'
@@ -186,11 +183,11 @@
     P: '10'
     # type=int|default=0: adds 'n' planes of zero at the Posterior edge
     R: '10'
     # type=int|default=0: adds 'n' planes of zero at the Right edge
     L: '10'
     # type=int|default=0: adds 'n' planes of zero at the Left edge
   imports:
-  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
+  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
   # consisting of 'module', 'name', and optionally 'alias' keys
   directive:
   # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/__init__.py` & `pydra_afni-0.3.2/pydra/tasks/afni/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,37 +1,38 @@
 """
 This is a basic doctest demonstrating that the package and pydra can both be successfully
 imported.
 
 >>> import pydra.engine
 >>> import pydra.tasks.afni
 """
+
 from warnings import warn
 from pathlib import Path
 
 pkg_path = Path(__file__).parent.parent
 
 try:
     from ._version import __version__
 except ImportError:
     raise RuntimeError(
         "pydra-afni has not been properly installed, please run "
         f"`pip install -e {str(pkg_path)}` to install a development version"
     )
 if "nipype" not in __version__:
     try:
-        from .auto._version import nipype_version, nipype2pydra_version
+        from .auto._post_release import src_pkg_version, nipype2pydra_version
     except ImportError:
         warn(
             "Nipype interfaces haven't been automatically converted from their specs in "
             f"`nipype-auto-conv`. Please run `{str(pkg_path / 'nipype-auto-conv' / 'generate')}` "
             "to generated the converted Nipype interfaces in pydra.tasks.afni.auto"
         )
     else:
-        n_ver = nipype_version.replace(".", "_")
+        n_ver = src_pkg_version.replace(".", "_")
         n2p_ver = nipype2pydra_version.replace(".", "_")
         __version__ += (
             "_" if "+" in __version__ else "+"
         ) + f"nipype{n_ver}_nipype2pydra{n2p_ver}"
 
 
 __all__ = ["__version__"]
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/a_boverlap.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/automask.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,95 +1,92 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.text import TextFile
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file_a",
+        "in_file",
         Nifti1,
         {
-            "help_string": "input file A",
-            "argstr": "{in_file_a}",
+            "help_string": "input file to 3dAutomask",
+            "argstr": "{in_file}",
             "copyfile": False,
             "mandatory": True,
-            "position": -3,
+            "position": -1,
         },
     ),
     (
-        "in_file_b",
-        Nifti1,
+        "out_file",
+        Path,
         {
-            "help_string": "input file B",
-            "argstr": "{in_file_b}",
-            "copyfile": False,
-            "mandatory": True,
-            "position": -2,
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_mask",
         },
     ),
     (
-        "out_file",
+        "brain_file",
         Path,
         {
-            "help_string": "collect output to a file",
-            "argstr": " |& tee {out_file}",
-            "position": -1,
+            "help_string": "output file from 3dAutomask",
+            "argstr": "-apply_prefix {brain_file}",
+            "output_file_template": "{in_file}_masked",
         },
     ),
     (
-        "no_automask",
-        bool,
-        {"help_string": "consider input datasets as masks", "argstr": "-no_automask"},
-    ),
-    (
-        "quiet",
-        bool,
+        "clfrac",
+        float,
         {
-            "help_string": "be as quiet as possible (without being entirely mute)",
-            "argstr": "-quiet",
+            "help_string": "sets the clip level fraction (must be 0.1-0.9). A small value will tend to make the mask larger [default = 0.5].",
+            "argstr": "-clfrac {clfrac}",
         },
     ),
     (
-        "verb",
-        bool,
-        {
-            "help_string": "print out some progress reports (to stderr)",
-            "argstr": "-verb",
-        },
+        "dilate",
+        int,
+        {"help_string": "dilate the mask outwards", "argstr": "-dilate {dilate}"},
+    ),
+    (
+        "erode",
+        int,
+        {"help_string": "erode the mask inwards", "argstr": "-erode {erode}"},
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-ABoverlap_input_spec = specs.SpecInfo(
+Automask_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", TextFile, {"help_string": "output file"})]
-ABoverlap_output_spec = specs.SpecInfo(
+output_fields = []
+Automask_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class ABoverlap(ShellCommandTask):
+class Automask(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.text import TextFile
-    >>> from pydra.tasks.afni.auto.a_boverlap import ABoverlap
-
-    >>> task = ABoverlap()
-    >>> task.inputs.in_file_a = Nifti1.mock()
-    >>> task.inputs.in_file_b = Nifti1.mock()
-    >>> task.inputs.out_file = " "out.mask_ae_overlap.txt""
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.automask import Automask
+
+    >>> task = Automask()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.dilate = 1
+    >>> task.inputs.outputtype = "NIFTI"
     >>> task.cmdline
-    '3dABoverlap functional.nii structural.nii |& tee out.mask_ae_overlap.txt'
+    '3dAutomask -apply_prefix functional_masked.nii -dilate 1 -prefix functional_mask.nii functional.nii'
 
 
     """
 
-    input_spec = ABoverlap_input_spec
-    output_spec = ABoverlap_output_spec
-    executable = "3dABoverlap"
+    input_spec = Automask_input_spec
+    output_spec = Automask_output_spec
+    executable = "3dAutomask"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/afn_ito_nifti.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/afn_ito_nifti.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,28 +1,32 @@
+from fileformats.medimage import Nifti1
 from fileformats.medimage_afni import ThreeD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         ThreeD,
         {
             "help_string": "input file to 3dAFNItoNIFTI",
             "argstr": "{in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": -1,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file}.nii",
         },
     ),
     (
@@ -73,20 +77,21 @@
 
 
 class AFNItoNIFTI(ShellCommandTask):
     """
     Examples
     -------
 
+    >>> from fileformats.medimage import Nifti1
     >>> from fileformats.medimage_afni import ThreeD
-    >>> from pydra.tasks.afni.auto.afn_ito_nifti import AFNItoNIFTI
+    >>> from pydra.tasks.afni.auto.utils.afn_ito_nifti import AFNItoNIFTI
 
     >>> task = AFNItoNIFTI()
-    >>> task.inputs.in_file = ThreeD.mock()
-    >>> task.inputs.out_file = " "afni_output.nii""
+    >>> task.inputs.in_file = ThreeD.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
     '3dAFNItoNIFTI -prefix afni_output.nii afni_output.3D'
 
 
     """
 
     input_spec = AFNItoNIFTI_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/align_epi_anat_py.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/zeropad.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,170 +1,180 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "in_files",
         Nifti1,
         {
-            "help_string": "EPI dataset to align",
-            "argstr": "-epi {in_file}",
+            "help_string": "input dataset",
+            "argstr": "{in_files}",
             "copyfile": False,
             "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "anat",
+        "out_file",
         Nifti1,
         {
-            "help_string": "name of structural dataset",
-            "argstr": "-anat {anat}",
-            "copyfile": False,
-            "mandatory": True,
+            "help_string": "output dataset prefix name (default 'zeropad')",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "zeropad",
         },
     ),
     (
-        "epi_base",
-        ty.Any,
+        "I",
+        int,
         {
-            "help_string": "the epi base used in alignmentshould be one of (0/mean/median/max/subbrick#)",
-            "argstr": "-epi_base {epi_base}",
-            "mandatory": True,
+            "help_string": "adds 'n' planes of zero at the Inferior edge",
+            "argstr": "-I {I}",
+            "xor": ["master"],
         },
     ),
     (
-        "anat2epi",
-        bool,
+        "S",
+        int,
         {
-            "help_string": "align anatomical to EPI dataset (default)",
-            "argstr": "-anat2epi",
+            "help_string": "adds 'n' planes of zero at the Superior edge",
+            "argstr": "-S {S}",
+            "xor": ["master"],
         },
     ),
     (
-        "epi2anat",
-        bool,
-        {"help_string": "align EPI to anatomical dataset", "argstr": "-epi2anat"},
-    ),
-    (
-        "save_skullstrip",
-        bool,
+        "A",
+        int,
         {
-            "help_string": "save skull-stripped (not aligned)",
-            "argstr": "-save_skullstrip",
+            "help_string": "adds 'n' planes of zero at the Anterior edge",
+            "argstr": "-A {A}",
+            "xor": ["master"],
         },
     ),
     (
-        "suffix",
-        str,
-        "_al",
+        "P",
+        int,
         {
-            "help_string": 'append suffix to the original anat/epi dataset to usein the resulting dataset names (default is "_al")',
-            "argstr": "-suffix {suffix}",
+            "help_string": "adds 'n' planes of zero at the Posterior edge",
+            "argstr": "-P {P}",
+            "xor": ["master"],
         },
     ),
     (
-        "epi_strip",
-        ty.Any,
+        "L",
+        int,
         {
-            "help_string": "method to mask brain in EPI datashould be one of[3dSkullStrip]/3dAutomask/None)",
-            "argstr": "-epi_strip {epi_strip}",
+            "help_string": "adds 'n' planes of zero at the Left edge",
+            "argstr": "-L {L}",
+            "xor": ["master"],
         },
     ),
     (
-        "volreg",
-        ty.Any,
-        "on",
+        "R",
+        int,
         {
-            "help_string": "do volume registration on EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'",
-            "argstr": "-volreg {volreg}",
+            "help_string": "adds 'n' planes of zero at the Right edge",
+            "argstr": "-R {R}",
+            "xor": ["master"],
         },
     ),
     (
-        "tshift",
-        ty.Any,
-        "on",
+        "z",
+        int,
         {
-            "help_string": "do time shifting of EPI dataset before alignmentshould be 'on' or 'off', defaults to 'on'",
-            "argstr": "-tshift {tshift}",
+            "help_string": "adds 'n' planes of zero on EACH of the dataset z-axis (slice-direction) faces",
+            "argstr": "-z {z}",
+            "xor": ["master"],
         },
     ),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
-    ("py27_path", ty.Any, "python2", {"help_string": ""}),
-]
-AlignEpiAnatPy_input_spec = specs.SpecInfo(
-    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
-)
-
-output_fields = [
-    (
-        "anat_al_orig",
-        File,
-        {"help_string": "A version of the anatomy that is aligned to the EPI"},
-    ),
     (
-        "epi_al_orig",
-        File,
-        {"help_string": "A version of the EPI dataset aligned to the anatomy"},
+        "RL",
+        int,
+        {
+            "help_string": "specify that planes should be added or cut symmetrically to make the resulting volume haveN slices in the right-left direction",
+            "argstr": "-RL {RL}",
+            "xor": ["master"],
+        },
     ),
     (
-        "epi_tlrc_al",
-        File,
-        {"help_string": "A version of the EPI dataset aligned to a standard template"},
+        "AP",
+        int,
+        {
+            "help_string": "specify that planes should be added or cut symmetrically to make the resulting volume haveN slices in the anterior-posterior direction",
+            "argstr": "-AP {AP}",
+            "xor": ["master"],
+        },
     ),
-    ("anat_al_mat", File, {"help_string": "matrix to align anatomy to the EPI"}),
-    ("epi_al_mat", File, {"help_string": "matrix to align EPI to anatomy"}),
-    ("epi_vr_al_mat", File, {"help_string": "matrix to volume register EPI"}),
     (
-        "epi_reg_al_mat",
-        File,
-        {"help_string": "matrix to volume register and align epi to anatomy"},
+        "IS",
+        int,
+        {
+            "help_string": "specify that planes should be added or cut symmetrically to make the resulting volume haveN slices in the inferior-superior direction",
+            "argstr": "-IS {IS}",
+            "xor": ["master"],
+        },
     ),
     (
-        "epi_al_tlrc_mat",
-        File,
+        "mm",
+        bool,
         {
-            "help_string": "matrix to volume register and align epito anatomy and put into standard space"
+            "help_string": "pad counts 'n' are in mm instead of slices, where each 'n' is an integer and at least 'n' mm of slices will be added/removed; e.g., n =  3 and slice thickness = 2.5 mm ==> 2 slices added",
+            "argstr": "-mm",
+            "xor": ["master"],
         },
     ),
     (
-        "epi_vr_motion",
+        "master",
         File,
         {
-            "help_string": "motion parameters from EPI time-seriesregistration (tsh included in name if slicetiming correction is also included)."
+            "help_string": "match the volume described in dataset 'mset', where mset must have the same orientation and grid spacing as dataset to be padded. the goal of -master is to make the output dataset from 3dZeropad match the spatial 'extents' of mset by adding or subtracting slices as needed. You can't use -I,-S,..., or -mm with -master",
+            "argstr": "-master {master}",
+            "xor": ["I", "S", "A", "P", "L", "R", "z", "RL", "AP", "IS", "mm"],
         },
     ),
-    ("skullstrip", File, {"help_string": "skull-stripped (not aligned) volume"}),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-AlignEpiAnatPy_output_spec = specs.SpecInfo(
+Zeropad_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+Zeropad_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class AlignEpiAnatPy(ShellCommandTask):
+class Zeropad(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.align_epi_anat_py import AlignEpiAnatPy
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.zeropad import Zeropad
 
-    >>> task = AlignEpiAnatPy()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.anat = Nifti1.mock()
-    >>> task.inputs.epi_base = "0"
-    >>> task.inputs.save_skullstrip = "True"
-    >>> task.inputs.epi_strip = ""3dAutomask""
-    >>> task.inputs.volreg = ""off""
-    >>> task.inputs.tshift = ""off""
+    >>> task = Zeropad()
+    >>> task.inputs.in_files = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.I = 10
+    >>> task.inputs.S = 10
+    >>> task.inputs.A = 10
+    >>> task.inputs.P = 10
+    >>> task.inputs.L = 10
+    >>> task.inputs.R = 10
+    >>> task.inputs.master = File.mock()
     >>> task.cmdline
-    'python2 ...align_epi_anat.py -anat structural.nii -epi_base 0 -epi_strip 3dAutomask -epi functional.nii -save_skullstrip -suffix _al -tshift off -volreg off'
+    '3dZeropad -A 10 -I 10 -L 10 -P 10 -R 10 -S 10 -prefix pad_functional.nii functional.nii'
 
 
     """
 
-    input_spec = AlignEpiAnatPy_input_spec
-    output_spec = AlignEpiAnatPy_output_spec
-    executable = "align_epi_anat.py"
+    input_spec = Zeropad_input_spec
+    output_spec = Zeropad_output_spec
+    executable = "3dZeropad"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/allineate.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/allineate.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,19 @@
-from fileformats.datascience.data import TextMatrix
+from fileformats.datascience import TextMatrix
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
 from fileformats.text import TextFile
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dAllineate",
             "argstr": "-source {in_file}",
@@ -24,25 +27,25 @@
         {
             "help_string": "file to be used as reference, the first volume will be used if not given the reference will be the first volume of in_file.",
             "argstr": "-base {reference}",
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output file from 3dAllineate",
             "argstr": "-prefix {out_file}",
             "xor": ["allcostx"],
             "output_file_template": "{in_file}_allineate",
         },
     ),
     (
         "out_param_file",
-        Path,
+        File,
         {
             "help_string": "Save the warp parameters in ASCII (.1D) format.",
             "argstr": "-1Dparam_save {out_param_file}",
             "xor": ["in_param_file", "allcostx"],
         },
     ),
     (
@@ -52,15 +55,15 @@
             "help_string": "Read warp parameters from file and apply them to the source dataset, and produce a new dataset",
             "argstr": "-1Dparam_apply {in_param_file}",
             "xor": ["out_param_file"],
         },
     ),
     (
         "out_matrix",
-        Path,
+        File,
         {
             "help_string": "Save the transformation matrix for each volume.",
             "argstr": "-1Dmatrix_save {out_matrix}",
             "xor": ["in_matrix", "allcostx"],
         },
     ),
     (
@@ -79,15 +82,15 @@
         {
             "help_string": "overwrite output file if it already exists",
             "argstr": "-overwrite",
         },
     ),
     (
         "allcostx",
-        Path,
+        TextFile,
         {
             "help_string": "Compute and print ALL available cost functionals for the un-warped inputsAND THEN QUIT. If you use this option none of the other expected outputs will be produced",
             "argstr": "-allcostx |& tee {allcostx}",
             "position": -1,
             "xor": ["out_file", "out_matrix", "out_param_file", "out_weight_file"],
         },
     ),
@@ -258,15 +261,15 @@
         {
             "help_string": "Set the weighting for each voxel in the base dataset; larger weights mean that voxel count more in the cost function. If an image file is given, the volume must be defined on the same grid as the base dataset",
             "argstr": "-weight {weight}",
         },
     ),
     (
         "out_weight_file",
-        Path,
+        File,
         {
             "help_string": "Write the weight volume to disk as a dataset",
             "argstr": "-wtprefix {out_weight_file}",
             "xor": ["allcostx"],
         },
     ),
     (
@@ -429,55 +432,68 @@
 
 
 class Allineate(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.datascience.data import TextMatrix
+    >>> from fileformats.datascience import TextMatrix
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
+    >>> from fileformats.medimage import Nifti1
     >>> from fileformats.text import TextFile
-    >>> from pydra.tasks.afni.auto.allineate import Allineate
+    >>> from pydra.tasks.afni.auto.preprocess.allineate import Allineate
 
     >>> task = Allineate()
-    >>> task.inputs.in_file = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
     >>> task.inputs.reference = Nifti1.mock()
-    >>> task.inputs.out_file = ""functional_allineate.nii""
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.out_param_file = File.mock()
     >>> task.inputs.in_param_file = File.mock()
-    >>> task.inputs.in_matrix = TextMatrix.mock()
+    >>> task.inputs.out_matrix = File.mock()
+    >>> task.inputs.in_matrix = TextMatrix.mock(None)
+    >>> task.inputs.allcostx = TextFile.mock()
     >>> task.inputs.weight_file = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.source_mask = File.mock()
     >>> task.inputs.master = File.mock()
     >>> task.cmdline
     '3dAllineate -source functional.nii -prefix functional_allineate.nii -1Dmatrix_apply cmatrix.mat'
 
 
     >>> task = Allineate()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.reference = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.reference = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock()
+    >>> task.inputs.out_param_file = File.mock()
     >>> task.inputs.in_param_file = File.mock()
+    >>> task.inputs.out_matrix = File.mock()
     >>> task.inputs.in_matrix = TextMatrix.mock()
-    >>> task.inputs.allcostx = ""out.allcostX.txt""
+    >>> task.inputs.allcostx = TextFile.mock(None)
     >>> task.inputs.weight_file = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.source_mask = File.mock()
     >>> task.inputs.master = File.mock()
     >>> task.cmdline
     '3dAllineate -source functional.nii -base structural.nii -allcostx |& tee out.allcostX.txt'
 
 
     >>> task = Allineate()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.reference = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.reference = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock()
+    >>> task.inputs.out_param_file = File.mock()
     >>> task.inputs.in_param_file = File.mock()
+    >>> task.inputs.out_matrix = File.mock()
     >>> task.inputs.in_matrix = TextMatrix.mock()
+    >>> task.inputs.allcostx = TextFile.mock()
     >>> task.inputs.weight_file = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.source_mask = File.mock()
     >>> task.inputs.master = File.mock()
-    >>> task.inputs.nwarp_fixmot = "["X", "Y"]"
+    >>> task.inputs.nwarp_fixmot = ["X", "Y"]
     >>> task.cmdline
     '3dAllineate -source functional.nii -nwarp_fixmotX -nwarp_fixmotY -prefix functional_allineate -base structural.nii'
 
 
     """
 
     input_spec = Allineate_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/auto_tcorrelate.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/resample.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,94 +1,97 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "timeseries x space (volume or surface) file",
-            "argstr": "{in_file}",
+            "help_string": "input file to 3dresample",
+            "argstr": "-inset {in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": -1,
         },
     ),
     (
-        "polort",
-        int,
+        "out_file",
+        Path,
         {
-            "help_string": "Remove polynomical trend of order m or -1 for no detrending",
-            "argstr": "-polort {polort}",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_resample",
         },
     ),
-    ("eta2", bool, {"help_string": "eta^2 similarity", "argstr": "-eta2"}),
-    ("mask", Nifti1, {"help_string": "mask of voxels", "argstr": "-mask {mask}"}),
     (
-        "mask_only_targets",
-        bool,
+        "orientation",
+        str,
+        {"help_string": "new orientation code", "argstr": "-orient {orientation}"},
+    ),
+    (
+        "resample_mode",
+        ty.Any,
         {
-            "help_string": "use mask only on targets voxels",
-            "argstr": "-mask_only_targets",
-            "xor": ["mask_source"],
+            "help_string": 'resampling method from set {"NN", "Li", "Cu", "Bk"}. These are for "Nearest Neighbor", "Linear", "Cubic" and "Blocky"interpolation, respectively. Default is NN.',
+            "argstr": "-rmode {resample_mode}",
         },
     ),
     (
-        "mask_source",
-        File,
+        "voxel_size",
+        ty.Any,
         {
-            "help_string": "mask for source voxels",
-            "argstr": "-mask_source {mask_source}",
-            "xor": ["mask_only_targets"],
+            "help_string": "resample to new dx, dy and dz",
+            "argstr": "-dxyz {voxel_size[0]} {voxel_size[1]} {voxel_size[2]}",
         },
     ),
     (
-        "out_file",
-        Path,
+        "master",
+        File,
         {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_similarity_matrix.1D",
+            "help_string": "align dataset grid to a reference file",
+            "argstr": "-master {master}",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-AutoTcorrelate_input_spec = specs.SpecInfo(
+Resample_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-AutoTcorrelate_output_spec = specs.SpecInfo(
+Resample_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class AutoTcorrelate(ShellCommandTask):
+class Resample(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.auto_tcorrelate import AutoTcorrelate
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.resample import Resample
 
-    >>> task = AutoTcorrelate()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.polort = "-1"
-    >>> task.inputs.eta2 = "True"
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.mask_only_targets = "True"
-    >>> task.inputs.mask_source = File.mock()
+    >>> task = Resample()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.orientation = "RPI"
+    >>> task.inputs.master = File.mock()
+    >>> task.inputs.outputtype = "NIFTI"
     >>> task.cmdline
-    '3dAutoTcorrelate -eta2 -mask mask.nii -mask_only_targets -prefix functional_similarity_matrix.1D -polort -1 functional.nii'
+    '3dresample -orient RPI -prefix functional_resample.nii -inset functional.nii'
 
 
     """
 
-    input_spec = AutoTcorrelate_input_spec
-    output_spec = AutoTcorrelate_output_spec
-    executable = "3dAutoTcorrelate"
+    input_spec = Resample_input_spec
+    output_spec = Resample_output_spec
+    executable = "3dresample"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/auto_tlrc.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/auto_tlrc.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,17 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
     (
         "in_file",
         Nifti1,
         {
             "help_string": "Original anatomical volume (+orig).The skull is removed by this scriptunless instructed otherwise (-no_ss).",
@@ -46,21 +50,21 @@
 
 class AutoTLRC(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.auto_tlrc import AutoTLRC
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.auto_tlrc import AutoTLRC
 
     >>> task = AutoTLRC()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.base = ""TT_N27+tlrc""
-    >>> task.inputs.no_ss = "True"
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.base = "TT_N27+tlrc"
+    >>> task.inputs.no_ss = True
     >>> task.cmdline
     '@auto_tlrc -base TT_N27+tlrc -input structural.nii -no_ss'
 
 
     """
 
     input_spec = AutoTLRC_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/autobox.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/t_cat.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,125 +1,155 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
 
-def x_max_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["x_max"]
-
-
-def x_min_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["x_min"]
-
-
-def y_max_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["y_max"]
-
-
-def y_min_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["y_min"]
-
-
-def z_max_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["z_max"]
-
-
-def z_min_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["z_min"]
+logger = logging.getLogger(__name__)
 
 
 input_fields = [
     (
-        "in_file",
-        Nifti1,
+        "in_files",
+        ty.List[Nifti1],
         {
-            "help_string": "input file",
-            "argstr": "-input {in_file}",
+            "help_string": "input file to 3dTcat",
+            "argstr": " {in_files}",
             "copyfile": False,
             "mandatory": True,
+            "position": -1,
+        },
+    ),
+    (
+        "out_file",
+        Nifti1,
+        {
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_files}_tcat",
+        },
+    ),
+    (
+        "rlt",
+        ty.Any,
+        {
+            "help_string": "Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.",
+            "argstr": "-rlt{rlt}",
+            "position": 1,
         },
     ),
     (
-        "padding",
-        int,
+        "verbose",
+        bool,
+        {
+            "help_string": "Print out some verbose output as the program",
+            "argstr": "-verb",
+        },
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+t_cat_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+t_cat_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class t_cat(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.t_cat import t_cat
+
+    >>> task = t_cat()
+    >>> task.inputs.in_files = None
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.rlt = "+"
+    >>> task.cmdline
+    '3dTcat -rlt+ -prefix functional_tcat.nii functional.nii functional2.nii'
+
+
+    """
+
+    input_spec = t_cat_input_spec
+    output_spec = t_cat_output_spec
+    executable = "3dTcat"
+
+
+input_fields = [
+    (
+        "in_files",
+        ty.List[Nifti1],
         {
-            "help_string": "Number of extra voxels to pad on each side of box",
-            "argstr": "-npad {padding}",
+            "help_string": "input file to 3dTcat",
+            "argstr": " {in_files}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
-            "help_string": "",
+            "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_autobox",
+            "output_file_template": "{in_files}_tcat",
+        },
+    ),
+    (
+        "rlt",
+        ty.Any,
+        {
+            "help_string": "Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.",
+            "argstr": "-rlt{rlt}",
+            "position": 1,
         },
     ),
     (
-        "no_clustering",
+        "verbose",
         bool,
         {
-            "help_string": "Don't do any clustering to find box. Any non-zero voxel will be preserved in the cropped volume. The default method uses some clustering to find the cropping box, and will clip off small isolated blobs.",
-            "argstr": "-noclust",
+            "help_string": "Print out some verbose output as the program",
+            "argstr": "-verb",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Autobox_input_spec = specs.SpecInfo(
+TCat_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    ("x_min", int, {"callable": "x_min_callable"}),
-    ("x_max", int, {"callable": "x_max_callable"}),
-    ("y_min", int, {"callable": "y_min_callable"}),
-    ("y_max", int, {"callable": "y_max_callable"}),
-    ("z_min", int, {"callable": "z_min_callable"}),
-    ("z_max", int, {"callable": "z_max_callable"}),
-]
-Autobox_output_spec = specs.SpecInfo(
+output_fields = []
+TCat_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Autobox(ShellCommandTask):
+class TCat(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.autobox import Autobox
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.t_cat import TCat
 
-    >>> task = Autobox()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.padding = "5"
+    >>> task = TCat()
+    >>> task.inputs.in_files = None
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.rlt = "+"
     >>> task.cmdline
-    '3dAutobox -input structural.nii -prefix structural_autobox -npad 5'
+    '3dTcat -rlt+ -prefix functional_tcat.nii functional.nii functional2.nii'
 
 
     """
 
-    input_spec = Autobox_input_spec
-    output_spec = Autobox_output_spec
-    executable = "3dAutobox"
+    input_spec = TCat_input_spec
+    output_spec = TCat_output_spec
+    executable = "3dTcat"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/automask.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/blur_to_fwhm.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,88 +1,106 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input file to 3dAutomask",
-            "argstr": "{in_file}",
-            "copyfile": False,
+            "help_string": "The dataset that will be smoothed",
+            "argstr": "-input {in_file}",
             "mandatory": True,
-            "position": -1,
         },
     ),
     (
-        "out_file",
-        Path,
+        "automask",
+        bool,
         {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_mask",
+            "help_string": "Create an automask from the input dataset.",
+            "argstr": "-automask",
         },
     ),
     (
-        "brain_file",
-        Path,
+        "fwhm",
+        float,
         {
-            "help_string": "output file from 3dAutomask",
-            "argstr": "-apply_prefix {brain_file}",
-            "output_file_template": "{in_file}_masked",
+            "help_string": "Blur until the 3D FWHM reaches this value (in mm)",
+            "argstr": "-FWHM {fwhm}",
         },
     ),
     (
-        "clfrac",
+        "fwhmxy",
         float,
         {
-            "help_string": "sets the clip level fraction (must be 0.1-0.9). A small value will tend to make the mask larger [default = 0.5].",
-            "argstr": "-clfrac {clfrac}",
+            "help_string": "Blur until the 2D (x,y)-plane FWHM reaches this value (in mm)",
+            "argstr": "-FWHMxy {fwhmxy}",
         },
     ),
     (
-        "dilate",
-        int,
-        {"help_string": "dilate the mask outwards", "argstr": "-dilate {dilate}"},
+        "blurmaster",
+        File,
+        {
+            "help_string": "The dataset whose smoothness controls the process.",
+            "argstr": "-blurmaster {blurmaster}",
+        },
     ),
     (
-        "erode",
-        int,
-        {"help_string": "erode the mask inwards", "argstr": "-erode {erode}"},
+        "mask",
+        File,
+        {
+            "help_string": "Mask dataset, if desired. Voxels NOT in mask will be set to zero in output.",
+            "argstr": "-mask {mask}",
+        },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+    (
+        "out_file",
+        Path,
+        {
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_afni",
+        },
+    ),
 ]
-Automask_input_spec = specs.SpecInfo(
+BlurToFWHM_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Automask_output_spec = specs.SpecInfo(
+BlurToFWHM_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Automask(ShellCommandTask):
+class BlurToFWHM(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.automask import Automask
-
-    >>> task = Automask()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.dilate = "1"
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.blur_to_fwhm import BlurToFWHM
+
+    >>> task = BlurToFWHM()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.fwhm = 2.5
+    >>> task.inputs.blurmaster = File.mock()
+    >>> task.inputs.mask = File.mock()
     >>> task.cmdline
-    '3dAutomask -apply_prefix functional_masked.nii -dilate 1 -prefix functional_mask.nii functional.nii'
+    '3dBlurToFWHM -FWHM 2.500000 -input epi.nii -prefix epi_afni'
 
 
     """
 
-    input_spec = Automask_input_spec
-    output_spec = Automask_output_spec
-    executable = "3dAutomask"
+    input_spec = BlurToFWHM_input_spec
+    output_spec = BlurToFWHM_output_spec
+    executable = "3dBlurToFWHM"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/axialize.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/axialize.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,28 +1,31 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3daxialize",
             "argstr": "{in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": -2,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file}_axialize",
         },
     ),
     ("verb", bool, {"help_string": "Print out a progerss report", "argstr": "-verb"}),
@@ -72,20 +75,20 @@
 
 
 class Axialize(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.axialize import Axialize
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.axialize import Axialize
 
     >>> task = Axialize()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""axialized.nii""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
     '3daxialize -prefix axialized.nii functional.nii'
 
 
     """
 
     input_spec = Axialize_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/bandpass.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/bandpass.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dBandpass",
             "argstr": "{in_file}",
@@ -152,21 +156,21 @@
 
 class Bandpass(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.bandpass import Bandpass
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.bandpass import Bandpass
 
     >>> task = Bandpass()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.lowpass = "0.1"
-    >>> task.inputs.highpass = "0.005"
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.lowpass = 0.1
+    >>> task.inputs.highpass = 0.005
     >>> task.inputs.mask = File.mock()
     >>> task.inputs.orthogonalize_dset = File.mock()
     >>> task.cmdline
     '3dBandpass -prefix functional_bp 0.005000 0.100000 functional.nii'
 
 
     """
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/blur_in_mask.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/s_v_m_test.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,115 +1,109 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
-        Nifti1,
+        "model",
+        str,
         {
-            "help_string": "input file to 3dSkullStrip",
-            "argstr": "-input {in_file}",
-            "copyfile": False,
+            "help_string": "modname is the basename for the brik containing the SVM model",
+            "argstr": "-model {model}",
             "mandatory": True,
-            "position": 1,
         },
     ),
     (
-        "out_file",
-        Path,
+        "in_file",
+        File,
         {
-            "help_string": "output to the file",
-            "argstr": "-prefix {out_file}",
-            "position": -1,
-            "output_file_template": "{in_file}_blur",
+            "help_string": "A 3D or 3D+t AFNI brik dataset to be used for testing.",
+            "argstr": "-testvol {in_file}",
+            "mandatory": True,
         },
     ),
     (
-        "mask",
-        Nifti1,
+        "out_file",
+        Path,
         {
-            "help_string": "Mask dataset, if desired.  Blurring will occur only within the mask. Voxels NOT in the mask will be set to zero in the output.",
-            "argstr": "-mask {mask}",
+            "help_string": "filename for .1D prediction file(s).",
+            "argstr": "-predictions {out_file}",
+            "output_file_template": "%s_predictions",
         },
     ),
     (
-        "multimask",
+        "testlabels",
         File,
         {
-            "help_string": "Multi-mask dataset -- each distinct nonzero value in dataset will be treated as a separate mask for blurring purposes.",
-            "argstr": "-Mmask {multimask}",
+            "help_string": "*true* class category .1D labels for the test dataset. It is used to calculate the prediction accuracy performance",
+            "argstr": "-testlabels {testlabels}",
         },
     ),
     (
-        "automask",
+        "classout",
         bool,
         {
-            "help_string": "Create an automask from the input dataset.",
-            "argstr": "-automask",
+            "help_string": "Flag to specify that pname files should be integer-valued, corresponding to class category decisions.",
+            "argstr": "-classout",
         },
     ),
     (
-        "fwhm",
-        float,
+        "nopredcensord",
+        bool,
         {
-            "help_string": "fwhm kernel size",
-            "argstr": "-FWHM {fwhm}",
-            "mandatory": True,
+            "help_string": "Flag to prevent writing predicted values for censored time-points",
+            "argstr": "-nopredcensord",
         },
     ),
     (
-        "preserve",
+        "nodetrend",
         bool,
         {
-            "help_string": "Normally, voxels not in the mask will be set to zero in the output. If you want the original values in the dataset to be preserved in the output, use this option.",
-            "argstr": "-preserve",
+            "help_string": "Flag to specify that pname files should not be linearly detrended",
+            "argstr": "-nodetrend",
         },
     ),
     (
-        "float_out",
+        "multiclass",
         bool,
         {
-            "help_string": "Save dataset as floats, no matter what the input data type is.",
-            "argstr": "-float",
+            "help_string": "Specifies multiclass algorithm for classification",
+            "argstr": "-multiclass {multiclass}",
         },
     ),
-    ("options", str, {"help_string": "options", "argstr": "{options}", "position": 2}),
+    (
+        "options",
+        str,
+        {"help_string": "additional options for SVM-light", "argstr": "{options}"},
+    ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-BlurInMask_input_spec = specs.SpecInfo(
+s_v_m_test_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-BlurInMask_output_spec = specs.SpecInfo(
+s_v_m_test_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class BlurInMask(ShellCommandTask):
+class s_v_m_test(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.blur_in_mask import BlurInMask
-
-    >>> task = BlurInMask()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.multimask = File.mock()
-    >>> task.inputs.fwhm = "5.0"
-    >>> task.cmdline
-    '3dBlurInMask -input functional.nii -FWHM 5.000000 -mask mask.nii -prefix functional_blur'
-
+    >>> from pydra.tasks.afni.auto.svm.s_v_m_test import s_v_m_test
 
     """
 
-    input_spec = BlurInMask_input_spec
-    output_spec = BlurInMask_output_spec
-    executable = "3dBlurInMask"
+    input_spec = s_v_m_test_input_spec
+    output_spec = s_v_m_test_output_spec
+    executable = "3dsvm"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/blur_to_fwhm.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/blur_to_f_w_h_m.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "The dataset that will be smoothed",
             "argstr": "-input {in_file}",
@@ -63,40 +67,40 @@
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file}_afni",
         },
     ),
 ]
-BlurToFWHM_input_spec = specs.SpecInfo(
+blur_to_f_w_h_m_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-BlurToFWHM_output_spec = specs.SpecInfo(
+blur_to_f_w_h_m_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class BlurToFWHM(ShellCommandTask):
+class blur_to_f_w_h_m(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.blur_to_fwhm import BlurToFWHM
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.blur_to_f_w_h_m import blur_to_f_w_h_m
 
-    >>> task = BlurToFWHM()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.fwhm = "2.5"
+    >>> task = blur_to_f_w_h_m()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.fwhm = 2.5
     >>> task.inputs.blurmaster = File.mock()
     >>> task.inputs.mask = File.mock()
     >>> task.cmdline
     '3dBlurToFWHM -FWHM 2.500000 -input epi.nii -prefix epi_afni'
 
 
     """
 
-    input_spec = BlurToFWHM_input_spec
-    output_spec = BlurToFWHM_output_spec
+    input_spec = blur_to_f_w_h_m_input_spec
+    output_spec = blur_to_f_w_h_m_output_spec
     executable = "3dBlurToFWHM"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/bucket.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/bucket.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,12 +1,16 @@
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         list,
         {
             "help_string": "List of tuples of input datasets and subbrick selection strings\nas described in more detail in the following afni help string\nInput dataset specified using one of these forms:\n``prefix+view``, ``prefix+view.HEAD``, or ``prefix+view.BRIK``.\nYou can also add a sub-brick selection list after the end of the\ndataset name.  This allows only a subset of the sub-bricks to be\nincluded into the output (by default, all of the input dataset\nis copied into the output).  A sub-brick selection list looks like\none of the following forms::\n\n    fred+orig[5]                     ==> use only sub-brick #5\n    fred+orig[5,9,17]                ==> use #5, #9, and #17\n    fred+orig[5..8]     or [5-8]     ==> use #5, #6, #7, and #8\n    fred+orig[5..13(2)] or [5-13(2)] ==> use #5, #7, #9, #11, and #13\n\nSub-brick indexes start at 0.  You can use the character '$'\nto indicate the last sub-brick in a dataset; for example, you\ncan select every third sub-brick by using the selection list\n``fred+orig[0..$(3)]``\nN.B.: The sub-bricks are output in the order specified, which may\nnot be the order in the original datasets.  For example, using\n``fred+orig[0..$(2),1..$(2)]``\nwill cause the sub-bricks in fred+orig to be output into the\nnew dataset in an interleaved fashion. Using ``fred+orig[$..0]``\nwill reverse the order of the sub-bricks in the output.\nN.B.: Bucket datasets have multiple sub-bricks, but do NOT have\na time dimension.  You can input sub-bricks from a 3D+time dataset\ninto a bucket dataset.  You can use the '3dinfo' program to see\nhow many sub-bricks a 3D+time or a bucket dataset contains.\nN.B.: In non-bucket functional datasets (like the 'fico' datasets\noutput by FIM, or the 'fitt' datasets output by 3dttest), sub-brick\n``[0]`` is the 'intensity' and sub-brick [1] is the statistical parameter\nused as a threshold.  Thus, to create a bucket dataset using the\nintensity from dataset A and the threshold from dataset B, and\ncalling the output dataset C, you would type::\n\n    3dbucket -prefix C -fbuc 'A+orig[0]' -fbuc 'B+orig[1]\n\n",
             "argstr": "{in_file}",
@@ -37,19 +41,19 @@
 
 
 class Bucket(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from pydra.tasks.afni.auto.bucket import Bucket
+    >>> from pydra.tasks.afni.auto.utils.bucket import Bucket
 
     >>> task = Bucket()
-    >>> task.inputs.in_file = "[('functional.nii',"{2..$}"), ('functional.nii',"{1}")]"
-    >>> task.inputs.out_file = ""vr_base""
+    >>> task.inputs.in_file = [('functional.nii',"{2..$}"), ('functional.nii',"{1}")]
+    >>> task.inputs.out_file = None
     >>> task.cmdline
     '3dbucket -prefix vr_base functional.nii"{2..$}" functional.nii"{1}"'
 
 
     """
 
     input_spec = Bucket_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/calc.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/eval.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,52 +1,56 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage_afni import OneD
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file_a",
-        Nifti1,
+        OneD,
         {
-            "help_string": "input file to 3dcalc",
+            "help_string": "input file to 1deval",
             "argstr": "-a {in_file_a}",
             "mandatory": True,
             "position": 0,
         },
     ),
     (
         "in_file_b",
-        Nifti1,
+        OneD,
         {
-            "help_string": "operand file to 3dcalc",
+            "help_string": "operand file to 1deval",
             "argstr": "-b {in_file_b}",
             "position": 1,
         },
     ),
     (
         "in_file_c",
         File,
         {
-            "help_string": "operand file to 3dcalc",
+            "help_string": "operand file to 1deval",
             "argstr": "-c {in_file_c}",
             "position": 2,
         },
     ),
     (
         "out_file",
-        Path,
+        OneD,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file_a}_calc",
         },
     ),
+    ("out1D", bool, {"help_string": "output in 1D", "argstr": "-1D"}),
     (
         "expr",
         str,
         {
             "help_string": "expr",
             "argstr": '-expr "{expr}"',
             "mandatory": True,
@@ -60,60 +64,47 @@
     ),
     (
         "stop_idx",
         int,
         {"help_string": "stop index for in_file_a", "requires": ["start_idx"]},
     ),
     ("single_idx", int, {"help_string": "volume index for in_file_a"}),
-    ("overwrite", bool, {"help_string": "overwrite output", "argstr": "-overwrite"}),
     ("other", File, {"help_string": "other options", "argstr": ""}),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Calc_input_spec = specs.SpecInfo(
+Eval_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Calc_output_spec = specs.SpecInfo(
+Eval_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Calc(ShellCommandTask):
+class Eval(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.calc import Calc
-
-    >>> task = Calc()
-    >>> task.inputs.in_file_a = Nifti1.mock()
-    >>> task.inputs.in_file_b = Nifti1.mock()
-    >>> task.inputs.in_file_c = File.mock()
-    >>> task.inputs.out_file = " "functional_calc.nii.gz""
-    >>> task.inputs.expr = ""a*b""
-    >>> task.inputs.other = File.mock()
-    >>> task.inputs.outputtype = ""NIFTI""
-    >>> task.cmdline
-    '3dcalc -a functional.nii -b functional2.nii -expr "a*b" -prefix functional_calc.nii.gz'
-
+    >>> from fileformats.medimage_afni import OneD
+    >>> from pydra.tasks.afni.auto.utils.eval import Eval
 
-    >>> task = Calc()
-    >>> task.inputs.in_file_a = Nifti1.mock()
-    >>> task.inputs.in_file_b = Nifti1.mock()
+    >>> task = Eval()
+    >>> task.inputs.in_file_a = OneD.mock(None)
+    >>> task.inputs.in_file_b = OneD.mock(None)
     >>> task.inputs.in_file_c = File.mock()
-    >>> task.inputs.out_file = ""rm.epi.all1""
-    >>> task.inputs.expr = ""1""
-    >>> task.inputs.overwrite = "True"
+    >>> task.inputs.out_file = OneD.mock(None)
+    >>> task.inputs.out1D = True
+    >>> task.inputs.expr = "a*b"
     >>> task.inputs.other = File.mock()
     >>> task.cmdline
-    '3dcalc -a functional.nii -expr "1" -prefix rm.epi.all1 -overwrite'
+    '1deval -a seed.1D -b resp.1D -expr "a*b" -1D -prefix data_calc.1D'
 
 
     """
 
-    input_spec = Calc_input_spec
-    output_spec = Calc_output_spec
-    executable = "3dcalc"
+    input_spec = Eval_input_spec
+    output_spec = Eval_output_spec
+    executable = "1deval"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/cat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/cat.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,25 @@
 from fileformats.medimage_afni import OneD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_files",
         ty.List[OneD],
         {"help_string": "", "argstr": "{in_files}", "mandatory": True, "position": -2},
     ),
     (
         "out_file",
-        Path,
+        OneD,
         {
             "help_string": "output (concatenated) file name",
             "argstr": "> {out_file}",
             "mandatory": True,
             "position": -1,
         },
     ),
@@ -120,20 +123,20 @@
 
 class Cat(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.cat import Cat
+    >>> from pydra.tasks.afni.auto.utils.cat import Cat
 
     >>> task = Cat()
     >>> task.inputs.in_files = None
-    >>> task.inputs.out_file = ""catout.1d""
-    >>> task.inputs.sel = ""'[0,2]'""
+    >>> task.inputs.out_file = OneD.mock(None)
+    >>> task.inputs.sel = "'[0,2]'"
     >>> task.cmdline
     '1dcat -sel "[0,2]" f1.1D f2.1D > catout.1d'
 
 
     """
 
     input_spec = Cat_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/cat_matvec.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/fim.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,86 +1,96 @@
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
-        list,
+        Nifti1,
         {
-            "help_string": "list of tuples of mfiles and associated opkeys",
-            "argstr": "{in_file}",
+            "help_string": "input file to 3dfim+",
+            "argstr": "-input {in_file}",
+            "copyfile": False,
             "mandatory": True,
-            "position": -2,
+            "position": 1,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
-            "help_string": "File to write concattenated matvecs to",
-            "argstr": " > {out_file}",
-            "mandatory": True,
-            "position": -1,
-            "output_file_template": "{in_file}_cat.aff12.1D",
+            "help_string": "output image file name",
+            "argstr": "-bucket {out_file}",
+            "output_file_template": "{in_file}_fim",
         },
     ),
     (
-        "matrix",
-        bool,
+        "ideal_file",
+        OneD,
         {
-            "help_string": "indicates that the resulting matrix willbe written to outfile in the 'MATRIX(...)' format (FORM 3).This feature could be used, with clever scripting, to inputa matrix directly on the command line to program 3dWarp.",
-            "argstr": "-MATRIX",
-            "xor": ["oneline", "fourxfour"],
+            "help_string": "ideal time series file name",
+            "argstr": "-ideal_file {ideal_file}",
+            "mandatory": True,
+            "position": 2,
         },
     ),
     (
-        "oneline",
-        bool,
+        "fim_thr",
+        float,
         {
-            "help_string": "indicates that the resulting matrixwill simply be written as 12 numbers on one line.",
-            "argstr": "-ONELINE",
-            "xor": ["matrix", "fourxfour"],
+            "help_string": "fim internal mask threshold value",
+            "argstr": "-fim_thr {fim_thr}",
+            "position": 3,
         },
     ),
     (
-        "fourxfour",
-        bool,
+        "out",
+        str,
         {
-            "help_string": "Output matrix in augmented form (last row is 0 0 0 1)This option does not work with -MATRIX or -ONELINE",
-            "argstr": "-4x4",
-            "xor": ["matrix", "oneline"],
+            "help_string": "Flag to output the specified parameter",
+            "argstr": "-out {out}",
+            "position": 4,
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-CatMatvec_input_spec = specs.SpecInfo(
+Fim_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-CatMatvec_output_spec = specs.SpecInfo(
+Fim_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class CatMatvec(ShellCommandTask):
+class Fim(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from pydra.tasks.afni.auto.cat_matvec import CatMatvec
-
-    >>> task = CatMatvec()
-    >>> task.inputs.in_file = "[("structural.BRIK::WARP_DATA","I")]"
-    >>> task.inputs.out_file = ""warp.anat.Xat.1D""
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.medimage_afni import OneD
+    >>> from pydra.tasks.afni.auto.preprocess.fim import Fim
+
+    >>> task = Fim()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.ideal_file = OneD.mock(None)
+    >>> task.inputs.fim_thr = 0.0009
+    >>> task.inputs.out = "Correlation"
     >>> task.cmdline
-    'cat_matvec structural.BRIK::WARP_DATA -I > warp.anat.Xat.1D'
+    '3dfim+ -input functional.nii -ideal_file seed.1D -fim_thr 0.000900 -out Correlation -bucket functional_corr.nii'
 
 
     """
 
-    input_spec = CatMatvec_input_spec
-    output_spec = CatMatvec_output_spec
-    executable = "cat_matvec"
+    input_spec = Fim_input_spec
+    output_spec = Fim_output_spec
+    executable = "3dfim+"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/center_mass.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/calc.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,111 +1,124 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1, NiftiGz
+from fileformats.medimage_afni import All1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "in_file_a",
         Nifti1,
         {
-            "help_string": "input file to 3dCM",
-            "argstr": "{in_file}",
-            "copyfile": True,
+            "help_string": "input file to 3dcalc",
+            "argstr": "-a {in_file_a}",
             "mandatory": True,
-            "position": -2,
+            "position": 0,
         },
     ),
     (
-        "cm_file",
-        Path,
+        "in_file_b",
+        Nifti1,
         {
-            "help_string": "File to write center of mass to",
-            "argstr": "> {cm_file}",
-            "position": -1,
-            "output_file_template": "{in_file}_cm.out",
+            "help_string": "operand file to 3dcalc",
+            "argstr": "-b {in_file_b}",
+            "position": 1,
         },
     ),
     (
-        "mask_file",
+        "in_file_c",
         File,
         {
-            "help_string": "Only voxels with nonzero values in the provided mask will be averaged.",
-            "argstr": "-mask {mask_file}",
+            "help_string": "operand file to 3dcalc",
+            "argstr": "-c {in_file_c}",
+            "position": 2,
         },
     ),
     (
-        "automask",
-        bool,
-        {"help_string": "Generate the mask automatically", "argstr": "-automask"},
-    ),
-    (
-        "set_cm",
-        ty.Any,
+        "out_file",
+        ty.Union[All1, NiftiGz],
         {
-            "help_string": "After computing the center of mass, set the origin fields in the header so that the center of mass will be at (x,y,z) in DICOM coords.",
-            "argstr": "-set {set_cm[0]} {set_cm[1]} {set_cm[2]}",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file_a}_calc",
         },
     ),
     (
-        "local_ijk",
-        bool,
+        "expr",
+        str,
         {
-            "help_string": "Output values as (i,j,k) in local orientation",
-            "argstr": "-local_ijk",
+            "help_string": "expr",
+            "argstr": '-expr "{expr}"',
+            "mandatory": True,
+            "position": 3,
         },
     ),
     (
-        "roi_vals",
-        list,
-        {
-            "help_string": "Compute center of mass for each blob with voxel value of v0, v1, v2, etc. This option is handy for getting ROI centers of mass.",
-            "argstr": "-roi_vals {roi_vals}",
-        },
+        "start_idx",
+        int,
+        {"help_string": "start index for in_file_a", "requires": ["stop_idx"]},
     ),
     (
-        "all_rois",
-        bool,
-        {
-            "help_string": "Don't bother listing the values of ROIs you want: The program will find all of them and produce a full list",
-            "argstr": "-all_rois",
-        },
+        "stop_idx",
+        int,
+        {"help_string": "stop index for in_file_a", "requires": ["start_idx"]},
     ),
+    ("single_idx", int, {"help_string": "volume index for in_file_a"}),
+    ("overwrite", bool, {"help_string": "overwrite output", "argstr": "-overwrite"}),
+    ("other", File, {"help_string": "other options", "argstr": ""}),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-CenterMass_input_spec = specs.SpecInfo(
+Calc_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    ("out_file", File, {"help_string": "output file"}),
-    ("cm", list, {"help_string": "center of mass"}),
-]
-CenterMass_output_spec = specs.SpecInfo(
+output_fields = []
+Calc_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class CenterMass(ShellCommandTask):
+class Calc(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.center_mass import CenterMass
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from fileformats.medimage_afni import All1
+    >>> from pydra.tasks.afni.auto.utils.calc import Calc
+
+    >>> task = Calc()
+    >>> task.inputs.in_file_a = Nifti1.mock(None)
+    >>> task.inputs.in_file_b = Nifti1.mock(None)
+    >>> task.inputs.in_file_c = File.mock()
+    >>> task.inputs.out_file = None
+    >>> task.inputs.expr = "a*b"
+    >>> task.inputs.other = File.mock()
+    >>> task.inputs.outputtype = "NIFTI"
+    >>> task.cmdline
+    '3dcalc -a functional.nii -b functional2.nii -expr "a*b" -prefix functional_calc.nii.gz'
+
 
-    >>> task = CenterMass()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.cm_file = ""cm.txt""
-    >>> task.inputs.mask_file = File.mock()
-    >>> task.inputs.roi_vals = "[2, 10]"
+    >>> task = Calc()
+    >>> task.inputs.in_file_a = Nifti1.mock(None)
+    >>> task.inputs.in_file_b = Nifti1.mock()
+    >>> task.inputs.in_file_c = File.mock()
+    >>> task.inputs.out_file = None
+    >>> task.inputs.expr = "1"
+    >>> task.inputs.overwrite = True
+    >>> task.inputs.other = File.mock()
     >>> task.cmdline
-    '3dCM -roi_vals 2 10 structural.nii > cm.txt'
+    '3dcalc -a functional.nii -expr "1" -prefix rm.epi.all1 -overwrite'
 
 
     """
 
-    input_spec = CenterMass_input_spec
-    output_spec = CenterMass_output_spec
-    executable = "3dCM"
+    input_spec = Calc_input_spec
+    output_spec = Calc_output_spec
+    executable = "3dcalc"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/clip_level.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/hist.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,87 +1,100 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pathlib import Path
+from pydra.engine import ShellCommandTask, specs
 
 
-def clip_val_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["clip_val"]
+logger = logging.getLogger(__name__)
 
 
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input file to 3dClipLevel",
-            "argstr": "{in_file}",
+            "help_string": "input file to 3dHist",
+            "argstr": "-input {in_file}",
+            "copyfile": False,
             "mandatory": True,
-            "position": -1,
+            "position": 1,
         },
     ),
     (
-        "mfrac",
-        float,
+        "out_file",
+        Path,
         {
-            "help_string": "Use the number ff instead of 0.50 in the algorithm",
-            "argstr": "-mfrac {mfrac}",
-            "position": 2,
+            "help_string": "Write histogram to niml file with this prefix",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_hist",
         },
     ),
     (
-        "doall",
+        "showhist",
         bool,
+        False,
+        {"help_string": "write a text visual histogram", "argstr": "-showhist"},
+    ),
+    (
+        "out_show",
+        Path,
         {
-            "help_string": "Apply the algorithm to each sub-brick separately.",
-            "argstr": "-doall",
-            "position": 3,
-            "xor": "grad",
+            "help_string": "output image file name",
+            "argstr": "> {out_show}",
+            "position": -1,
+            "output_file_template": "{in_file}_hist.out",
         },
     ),
     (
-        "grad",
+        "mask",
         File,
-        {
-            "help_string": "Also compute a 'gradual' clip level as a function of voxel position, and output that to a dataset.",
-            "argstr": "-grad {grad}",
-            "position": 3,
-            "xor": "doall",
-        },
+        {"help_string": "matrix to align input file", "argstr": "-mask {mask}"},
+    ),
+    ("nbin", int, {"help_string": "number of bins", "argstr": "-nbin {nbin}"}),
+    (
+        "max_value",
+        float,
+        {"help_string": "maximum intensity value", "argstr": "-max {max_value}"},
+    ),
+    (
+        "min_value",
+        float,
+        {"help_string": "minimum intensity value", "argstr": "-min {min_value}"},
+    ),
+    (
+        "bin_width",
+        float,
+        {"help_string": "bin width", "argstr": "-binwidth {bin_width}"},
     ),
 ]
-ClipLevel_input_spec = specs.SpecInfo(
+Hist_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    ("clip_val", float, {"help_string": "output", "callable": "clip_val_callable"})
-]
-ClipLevel_output_spec = specs.SpecInfo(
+output_fields = []
+Hist_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class ClipLevel(ShellCommandTask):
+class Hist(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.clip_level import ClipLevel
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.hist import Hist
 
-    >>> task = ClipLevel()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.grad = File.mock()
+    >>> task = Hist()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = File.mock()
     >>> task.cmdline
-    '3dClipLevel anatomical.nii'
+    '3dHist -input functional.nii -prefix functional_hist'
 
 
     """
 
-    input_spec = ClipLevel_input_spec
-    output_spec = ClipLevel_output_spec
-    executable = "3dClipLevel"
+    input_spec = Hist_input_spec
+    output_spec = Hist_output_spec
+    executable = "3dHist"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/convert_dset.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/zcat.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,73 +1,97 @@
-from fileformats.medimage.surface import Gifti
-from fileformats.medimage_afni import Dset
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
-        Gifti,
+        "in_files",
+        ty.List[Nifti1],
         {
-            "help_string": "input file to ConvertDset",
-            "argstr": "-input {in_file}",
+            "help_string": "",
+            "argstr": "{in_files}",
+            "copyfile": False,
             "mandatory": True,
-            "position": -2,
+            "position": -1,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
-            "help_string": "output file for ConvertDset",
+            "help_string": "output dataset prefix name (default 'zcat')",
             "argstr": "-prefix {out_file}",
-            "mandatory": True,
-            "position": -1,
+            "output_file_template": "{in_files}_zcat",
         },
     ),
     (
-        "out_type",
+        "datum",
         ty.Any,
         {
-            "help_string": "output type",
-            "argstr": "-o_{out_type}",
-            "mandatory": True,
-            "position": 0,
+            "help_string": "specify data type for output. Valid types are 'byte', 'short' and 'float'.",
+            "argstr": "-datum {datum}",
+        },
+    ),
+    (
+        "verb",
+        bool,
+        {
+            "help_string": "print out some verbositiness as the program proceeds.",
+            "argstr": "-verb",
+        },
+    ),
+    (
+        "fscale",
+        bool,
+        {
+            "help_string": "Force scaling of the output to the maximum integer range.  This only has effect if the output datum is byte or short (either forced or defaulted). This option is sometimes necessary to eliminate unpleasant truncation artifacts.",
+            "argstr": "-fscale",
+            "xor": ["nscale"],
+        },
+    ),
+    (
+        "nscale",
+        bool,
+        {
+            "help_string": "Don't do any scaling on output to byte or short datasets. This may be especially useful when operating on mask datasets whose output values are only 0's and 1's.",
+            "argstr": "-nscale",
+            "xor": ["fscale"],
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-ConvertDset_input_spec = specs.SpecInfo(
+Zcat_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", Dset, {"help_string": "output file"})]
-ConvertDset_output_spec = specs.SpecInfo(
+output_fields = []
+Zcat_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class ConvertDset(ShellCommandTask):
+class Zcat(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.surface import Gifti
-    >>> from fileformats.medimage_afni import Dset
-    >>> from pydra.tasks.afni.auto.convert_dset import ConvertDset
-
-    >>> task = ConvertDset()
-    >>> task.inputs.in_file = Gifti.mock()
-    >>> task.inputs.out_file = ""lh.pial_converted.niml.dset""
-    >>> task.inputs.out_type = ""niml_asc""
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.zcat import Zcat
+
+    >>> task = Zcat()
+    >>> task.inputs.in_files = None
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
-    'ConvertDset -o_niml_asc -input lh.pial_converted.gii -prefix lh.pial_converted.niml.dset'
+    '3dZcat -prefix cat_functional.nii functional2.nii functional3.nii'
 
 
     """
 
-    input_spec = ConvertDset_input_spec
-    output_spec = ConvertDset_output_spec
-    executable = "ConvertDset"
+    input_spec = Zcat_input_spec
+    output_spec = Zcat_output_spec
+    executable = "3dZcat"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/copy.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/copy.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,29 +1,31 @@
-from copy import deepcopy
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dcopy",
             "argstr": "{in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": -2,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "{out_file}",
             "position": -1,
             "output_file_template": "{in_file}_copy",
         },
     ),
@@ -43,40 +45,43 @@
 
 class Copy(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from copy import deepcopy
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.copy import Copy
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.copy import Copy
 
     >>> task = Copy()
-    >>> task.inputs.in_file = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock()
     >>> task.cmdline
     '3dcopy functional.nii functional_copy'
 
 
     >>> task = Copy()
     >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> task.inputs.out_file = Nifti1.mock()
+    >>> task.inputs.outputtype = "NIFTI"
     >>> task.cmdline
     '3dcopy functional.nii functional_copy.nii'
 
 
     >>> task = Copy()
     >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.outputtype = ""NIFTI_GZ""
+    >>> task.inputs.out_file = Nifti1.mock()
+    >>> task.inputs.outputtype = "NIFTI_GZ"
     >>> task.cmdline
     '3dcopy functional.nii functional_copy.nii.gz'
 
 
     >>> task = Copy()
     >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""new_func.nii""
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
     '3dcopy functional.nii new_func.nii'
 
 
     """
 
     input_spec = Copy_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/deconvolve.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/model/deconvolve.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
 from fileformats.medimage_afni import OneD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_files",
         ty.List[Nifti1],
         {
             "help_string": "filenames of 3D+time input datasets. More than one filename can be given and the datasets will be auto-catenated in time. You can input a 1D time series file here, but the time axis should run along the ROW direction, not the COLUMN direction as in the 'input1D' option.",
             "argstr": "-input {in_files}",
@@ -199,15 +202,15 @@
         {
             "help_string": "this option lets you input a rectangular array of 1 or more baseline vectors from a file. This method is a fast way to include a lot of baseline regressors in one step. ",
             "argstr": "-ortvec {ortvec[0]} {ortvec[1]}",
         },
     ),
     (
         "x1D",
-        Path,
+        OneD,
         {"help_string": "specify name for saved X matrix", "argstr": "-x1D {x1D}"},
     ),
     (
         "x1D_stop",
         bool,
         {
             "help_string": "stop running after writing .xmat.1D file",
@@ -220,15 +223,15 @@
         {
             "help_string": "Name for dataset in which to save the regression coefficients (no statistics). This dataset will be used in a -xrestore run [not yet implemented] instead of the bucket dataset, if possible.",
             "argstr": "-cbucket {cbucket}",
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {"help_string": "output statistics file", "argstr": "-bucket {out_file}"},
     ),
     (
         "num_threads",
         int,
         {
             "help_string": "run the program with provided number of sub-processes",
@@ -378,30 +381,30 @@
 
 class Deconvolve(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
+    >>> from fileformats.medimage import Nifti1
     >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.deconvolve import Deconvolve
+    >>> from pydra.tasks.afni.auto.model.deconvolve import Deconvolve
 
     >>> task = Deconvolve()
     >>> task.inputs.in_files = None
     >>> task.inputs.input1D = File.mock()
     >>> task.inputs.mask = File.mock()
     >>> task.inputs.STATmask = File.mock()
     >>> task.inputs.censor = File.mock()
-    >>> task.inputs.x1D = ""output.1D""
-    >>> task.inputs.out_file = ""output.nii""
-    >>> task.inputs.stim_times = "stim_times"
-    >>> task.inputs.stim_label = "[(1, "Houses")]"
-    >>> task.inputs.gltsym = "["SYM: +Houses"]"
-    >>> task.inputs.glt_label = "[(1, "Houses")]"
+    >>> task.inputs.x1D = OneD.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.stim_times = stim_times
+    >>> task.inputs.stim_label = [(1, "Houses")]
+    >>> task.inputs.gltsym = ["SYM: +Houses"]
+    >>> task.inputs.glt_label = [(1, "Houses")]
     >>> task.cmdline
     '3dDeconvolve -input functional.nii functional2.nii -bucket output.nii -x1D output.1D -num_stimts 1 -stim_times 1 timeseries.txt "SPMG1(4)" -stim_label 1 Houses -num_glt 1 -gltsym "SYM: +Houses" -glt_label 1 Houses'
 
 
     """
 
     input_spec = Deconvolve_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/degree_centrality.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/means.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,118 +1,109 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "in_file_a",
         Nifti1,
         {
-            "help_string": "input file to 3dDegreeCentrality",
-            "argstr": "{in_file}",
-            "copyfile": False,
+            "help_string": "input file to 3dMean",
+            "argstr": "{in_file_a}",
             "mandatory": True,
-            "position": -1,
+            "position": -2,
         },
     ),
     (
-        "sparsity",
-        float,
+        "in_file_b",
+        Nifti1,
         {
-            "help_string": "only take the top percent of connections",
-            "argstr": "-sparsity {sparsity}",
+            "help_string": "another input file to 3dMean",
+            "argstr": "{in_file_b}",
+            "position": -1,
         },
     ),
     (
-        "oned_file",
+        "datum",
         str,
         {
-            "help_string": "output filepath to text dump of correlation matrix",
-            "argstr": "-out1D {oned_file}",
+            "help_string": "Sets the data type of the output dataset",
+            "argstr": "-datum {datum}",
         },
     ),
     (
-        "mask",
+        "out_file",
         Nifti1,
-        {"help_string": "mask file to mask input data", "argstr": "-mask {mask}"},
-    ),
-    (
-        "thresh",
-        float,
         {
-            "help_string": "threshold to exclude connections where corr <= thresh",
-            "argstr": "-thresh {thresh}",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file_a}_mean",
         },
     ),
-    ("polort", int, {"help_string": "", "argstr": "-polort {polort}"}),
+    ("scale", str, {"help_string": "scaling of output", "argstr": "-{scale}scale"}),
     (
-        "autoclip",
+        "non_zero",
         bool,
-        {
-            "help_string": "Clip off low-intensity regions in the dataset",
-            "argstr": "-autoclip",
-        },
+        {"help_string": "use only non-zero values", "argstr": "-non_zero"},
     ),
+    ("std_dev", bool, {"help_string": "calculate std dev", "argstr": "-stdev"}),
+    ("sqr", bool, {"help_string": "mean square instead of value", "argstr": "-sqr"}),
+    ("summ", bool, {"help_string": "take sum, (not average)", "argstr": "-sum"}),
     (
-        "automask",
+        "count",
         bool,
-        {
-            "help_string": "Mask the dataset to target brain-only voxels",
-            "argstr": "-automask",
-        },
+        {"help_string": "compute count of non-zero voxels", "argstr": "-count"},
     ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
     (
-        "out_file",
-        Path,
-        {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_afni",
-        },
+        "mask_inter",
+        bool,
+        {"help_string": "create intersection mask", "argstr": "-mask_inter"},
     ),
+    ("mask_union", bool, {"help_string": "create union mask", "argstr": "-mask_union"}),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-DegreeCentrality_input_spec = specs.SpecInfo(
+Means_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    (
-        "oned_file",
-        File,
-        {
-            "help_string": "The text output of the similarity matrix computed after thresholding with one-dimensional and ijk voxel indices, correlations, image extents, and affine matrix."
-        },
-    )
-]
-DegreeCentrality_output_spec = specs.SpecInfo(
+output_fields = []
+Means_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class DegreeCentrality(ShellCommandTask):
+class Means(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.degree_centrality import DegreeCentrality
-
-    >>> task = DegreeCentrality()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.sparsity = "1 # keep the top one percent of connections"
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.out_file = ""out.nii""
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.means import Means
+
+    >>> task = Means()
+    >>> task.inputs.in_file_a = Nifti1.mock(None)
+    >>> task.inputs.in_file_b = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.cmdline
+    '3dMean -prefix output.nii im1.nii im2.nii'
+
+
+    >>> task = Means()
+    >>> task.inputs.in_file_a = Nifti1.mock(None)
+    >>> task.inputs.in_file_b = Nifti1.mock()
+    >>> task.inputs.datum = "short"
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
-    '3dDegreeCentrality -mask mask.nii -prefix out.nii -sparsity 1.000000 functional.nii'
+    '3dMean -datum short -prefix output.nii im1.nii'
 
 
     """
 
-    input_spec = DegreeCentrality_input_spec
-    output_spec = DegreeCentrality_output_spec
-    executable = "3dDegreeCentrality"
+    input_spec = Means_input_spec
+    output_spec = Means_output_spec
+    executable = "3dMean"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/despike.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/despike.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,17 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dDespike",
             "argstr": "{in_file}",
@@ -39,19 +43,19 @@
 
 
 class Despike(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.despike import Despike
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.despike import Despike
 
     >>> task = Despike()
-    >>> task.inputs.in_file = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
     >>> task.cmdline
     '3dDespike -prefix functional_despike functional.nii'
 
 
     """
 
     input_spec = Despike_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/detrend.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/detrend.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,17 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dDetrend",
             "argstr": "{in_file}",
@@ -39,20 +43,20 @@
 
 
 class Detrend(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.detrend import Detrend
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.detrend import Detrend
 
     >>> task = Detrend()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.outputtype = ""AFNI""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.outputtype = "AFNI"
     >>> task.cmdline
     '3dDetrend -polort 2 -prefix functional_detrend functional.nii'
 
 
     """
 
     input_spec = Detrend_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/dot.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/dot.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,28 +1,31 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti
 from fileformats.text import TextFile
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_files",
-        ty.List[Nifti1],
+        ty.List[Nifti],
         {
             "help_string": "list of input files, possibly with subbrick selectors",
             "argstr": "{in_files} ...",
             "position": -2,
         },
     ),
     (
         "out_file",
-        Path,
+        TextFile,
         {
             "help_string": "collect output to a file",
             "argstr": " |& tee {out_file}",
             "position": -1,
         },
     ),
     (
@@ -127,23 +130,23 @@
 
 class Dot(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
+    >>> from fileformats.medimage import Nifti
     >>> from fileformats.text import TextFile
-    >>> from pydra.tasks.afni.auto.dot import Dot
+    >>> from pydra.tasks.afni.auto.utils.dot import Dot
 
     >>> task = Dot()
     >>> task.inputs.in_files = None
-    >>> task.inputs.out_file = ""out.mask_ae_dice.txt""
+    >>> task.inputs.out_file = TextFile.mock(None)
     >>> task.inputs.mask = File.mock()
-    >>> task.inputs.dodice = "True"
+    >>> task.inputs.dodice = True
     >>> task.cmdline
     '3dDot -dodice functional.nii[0] structural.nii |& tee out.mask_ae_dice.txt'
 
 
     """
 
     input_spec = Dot_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/ecm.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/ecm.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,16 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dECM",
             "argstr": "{in_file}",
@@ -110,15 +113,15 @@
             "argstr": "-automask",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file}_afni",
         },
     ),
 ]
@@ -133,22 +136,22 @@
 
 
 class ECM(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.ecm import ECM
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.ecm import ECM
 
     >>> task = ECM()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.sparsity = "0.1 # keep top 0.1% of connections"
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.out_file = ""out.nii""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.sparsity = 0.1 # keep top 0.1% of connections
+    >>> task.inputs.mask = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
     '3dECM -mask mask.nii -prefix out.nii -sparsity 0.100000 functional.nii'
 
 
     """
 
     input_spec = ECM_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/edge_3.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/model/synthesize.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,113 +1,109 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "cbucket",
         Nifti1,
         {
-            "help_string": "input file to 3dedge3",
-            "argstr": "-input {in_file}",
+            "help_string": "Read the dataset output from 3dDeconvolve via the '-cbucket' option.",
+            "argstr": "-cbucket {cbucket}",
             "copyfile": False,
             "mandatory": True,
-            "position": 0,
         },
     ),
     (
-        "out_file",
-        Path,
-        {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "position": -1,
-        },
-    ),
-    (
-        "datum",
-        ty.Any,
+        "matrix",
+        OneD,
         {
-            "help_string": "specify data type for output. Valid types are 'byte', 'short' and 'float'.",
-            "argstr": "-datum {datum}",
+            "help_string": "Read the matrix output from 3dDeconvolve via the '-x1D' option.",
+            "argstr": "-matrix {matrix}",
+            "copyfile": False,
+            "mandatory": True,
         },
     ),
     (
-        "fscale",
-        bool,
+        "select",
+        list,
         {
-            "help_string": "Force scaling of the output to the maximum integer range.",
-            "argstr": "-fscale",
-            "xor": ["gscale", "nscale", "scale_floats"],
+            "help_string": "A list of selected columns from the matrix (and the corresponding coefficient sub-bricks from the cbucket). Valid types include 'baseline',  'polort', 'allfunc', 'allstim', 'all', Can also provide 'something' where something matches a stim_label from 3dDeconvolve, and 'digits' where digits are the numbers of the select matrix columns by numbers (starting at 0), or number ranges of the form '3..7' and '3-7'.",
+            "argstr": "-select {select}",
+            "mandatory": True,
         },
     ),
     (
-        "gscale",
-        bool,
+        "out_file",
+        Path,
         {
-            "help_string": "Same as '-fscale', but also forces each output sub-brick to to get the same scaling factor.",
-            "argstr": "-gscale",
-            "xor": ["fscale", "nscale", "scale_floats"],
+            "help_string": "output dataset prefix name (default 'syn')",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "syn",
         },
     ),
     (
-        "nscale",
+        "dry_run",
         bool,
         {
-            "help_string": "Don't do any scaling on output to byte or short datasets.",
-            "argstr": "-nscale",
-            "xor": ["fscale", "gscale", "scale_floats"],
+            "help_string": "Don't compute the output, just check the inputs.",
+            "argstr": "-dry",
         },
     ),
     (
-        "scale_floats",
+        "TR",
         float,
         {
-            "help_string": "Multiply input by VAL, but only if the input datum is float. This is needed when the input dataset has a small range, like 0 to 2.0 for instance. With such a range, very few edges are detected due to what I suspect to be truncation problems. Multiplying such a dataset by 10000 fixes the problem and the scaling is undone at the output.",
-            "argstr": "-scale_floats {scale_floats}",
-            "xor": ["fscale", "gscale", "nscale"],
+            "help_string": "TR to set in the output.  The default value of TR is read from the header of the matrix file.",
+            "argstr": "-TR {TR}",
         },
     ),
     (
-        "verbose",
-        bool,
+        "cenfill",
+        ty.Any,
         {
-            "help_string": "Print out some information along the way.",
-            "argstr": "-verbose",
+            "help_string": "Determines how censored time points from the 3dDeconvolve run will be filled. Valid types are 'zero', 'nbhr' and 'none'.",
+            "argstr": "-cenfill {cenfill}",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Edge3_input_spec = specs.SpecInfo(
+Synthesize_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", Nifti1, {"help_string": "output file"})]
-Edge3_output_spec = specs.SpecInfo(
+output_fields = []
+Synthesize_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Edge3(ShellCommandTask):
+class Synthesize(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.edge_3 import Edge3
-
-    >>> task = Edge3()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""edges.nii""
-    >>> task.inputs.datum = ""byte""
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.medimage_afni import OneD
+    >>> from pydra.tasks.afni.auto.model.synthesize import Synthesize
+
+    >>> task = Synthesize()
+    >>> task.inputs.cbucket = Nifti1.mock(None)
+    >>> task.inputs.matrix = OneD.mock(None)
+    >>> task.inputs.select = ["baseline"]
     >>> task.cmdline
-    '3dedge3 -input functional.nii -datum byte -prefix edges.nii'
+    '3dSynthesize -cbucket functional.nii -matrix output.1D -select baseline'
 
 
     """
 
-    input_spec = Edge3_input_spec
-    output_spec = Edge3_output_spec
-    executable = "3dedge3"
+    input_spec = Synthesize_input_spec
+    output_spec = Synthesize_output_spec
+    executable = "3dSynthesize"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/eval.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/z_cut_up.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,107 +1,131 @@
-from fileformats.generic import File
-from fileformats.medimage_afni import OneD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file_a",
-        OneD,
+        "in_file",
+        Nifti1,
         {
-            "help_string": "input file to 1deval",
-            "argstr": "-a {in_file_a}",
+            "help_string": "input file to 3dZcutup",
+            "argstr": "{in_file}",
+            "copyfile": False,
             "mandatory": True,
-            "position": 0,
+            "position": -1,
         },
     ),
     (
-        "in_file_b",
-        OneD,
+        "out_file",
+        Nifti1,
         {
-            "help_string": "operand file to 1deval",
-            "argstr": "-b {in_file_b}",
-            "position": 1,
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_zcutup",
         },
     ),
     (
-        "in_file_c",
-        File,
+        "keep",
+        str,
+        {"help_string": "slice range to keep in output", "argstr": "-keep {keep}"},
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+ZCutUp_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+ZCutUp_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class ZCutUp(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.z_cut_up import ZCutUp
+
+    >>> task = ZCutUp()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.keep = "0 10"
+    >>> task.cmdline
+    '3dZcutup -keep 0 10 -prefix functional_zcutup.nii functional.nii'
+
+
+    """
+
+    input_spec = ZCutUp_input_spec
+    output_spec = ZCutUp_output_spec
+    executable = "3dZcutup"
+
+
+input_fields = [
+    (
+        "in_file",
+        Nifti1,
         {
-            "help_string": "operand file to 1deval",
-            "argstr": "-c {in_file_c}",
-            "position": 2,
+            "help_string": "input file to 3dZcutup",
+            "argstr": "{in_file}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file_a}_calc",
+            "output_file_template": "{in_file}_zcutup",
         },
     ),
-    ("out1D", bool, {"help_string": "output in 1D", "argstr": "-1D"}),
     (
-        "expr",
+        "keep",
         str,
-        {
-            "help_string": "expr",
-            "argstr": '-expr "{expr}"',
-            "mandatory": True,
-            "position": 3,
-        },
+        {"help_string": "slice range to keep in output", "argstr": "-keep {keep}"},
     ),
-    (
-        "start_idx",
-        int,
-        {"help_string": "start index for in_file_a", "requires": ["stop_idx"]},
-    ),
-    (
-        "stop_idx",
-        int,
-        {"help_string": "stop index for in_file_a", "requires": ["start_idx"]},
-    ),
-    ("single_idx", int, {"help_string": "volume index for in_file_a"}),
-    ("other", File, {"help_string": "other options", "argstr": ""}),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Eval_input_spec = specs.SpecInfo(
+z_cut_up_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Eval_output_spec = specs.SpecInfo(
+z_cut_up_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Eval(ShellCommandTask):
+class z_cut_up(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.eval import Eval
-
-    >>> task = Eval()
-    >>> task.inputs.in_file_a = OneD.mock()
-    >>> task.inputs.in_file_b = OneD.mock()
-    >>> task.inputs.in_file_c = File.mock()
-    >>> task.inputs.out_file = " "data_calc.1D""
-    >>> task.inputs.out1D = "True"
-    >>> task.inputs.expr = ""a*b""
-    >>> task.inputs.other = File.mock()
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.z_cut_up import z_cut_up
+
+    >>> task = z_cut_up()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.keep = "0 10"
     >>> task.cmdline
-    '1deval -a seed.1D -b resp.1D -expr "a*b" -1D -prefix data_calc.1D'
+    '3dZcutup -keep 0 10 -prefix functional_zcutup.nii functional.nii'
 
 
     """
 
-    input_spec = Eval_input_spec
-    output_spec = Eval_output_spec
-    executable = "1deval"
+    input_spec = z_cut_up_input_spec
+    output_spec = z_cut_up_output_spec
+    executable = "3dZcutup"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/fim.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_corr_1_d.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,93 +1,116 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "xset",
         Nifti1,
         {
-            "help_string": "input file to 3dfim+",
-            "argstr": "-input {in_file}",
+            "help_string": "3d+time dataset input",
+            "argstr": " {xset}",
             "copyfile": False,
             "mandatory": True,
-            "position": 1,
+            "position": -2,
+        },
+    ),
+    (
+        "y_1d",
+        File,
+        {
+            "help_string": "1D time series file input",
+            "argstr": " {y_1d}",
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
         "out_file",
         Path,
         {
-            "help_string": "output image file name",
-            "argstr": "-bucket {out_file}",
-            "output_file_template": "{in_file}_fim",
+            "help_string": "output filename prefix",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{xset}_correlation.nii.gz",
         },
     ),
     (
-        "ideal_file",
-        OneD,
+        "pearson",
+        bool,
         {
-            "help_string": "ideal time series file name",
-            "argstr": "-ideal_file {ideal_file}",
-            "mandatory": True,
-            "position": 2,
+            "help_string": "Correlation is the normal Pearson correlation coefficient",
+            "argstr": " -pearson",
+            "position": 1,
+            "xor": ["spearman", "quadrant", "ktaub"],
         },
     ),
     (
-        "fim_thr",
-        float,
+        "spearman",
+        bool,
         {
-            "help_string": "fim internal mask threshold value",
-            "argstr": "-fim_thr {fim_thr}",
-            "position": 3,
+            "help_string": "Correlation is the Spearman (rank) correlation coefficient",
+            "argstr": " -spearman",
+            "position": 1,
+            "xor": ["pearson", "quadrant", "ktaub"],
         },
     ),
     (
-        "out",
-        str,
+        "quadrant",
+        bool,
         {
-            "help_string": "Flag to output the specified parameter",
-            "argstr": "-out {out}",
-            "position": 4,
+            "help_string": "Correlation is the quadrant correlation coefficient",
+            "argstr": " -quadrant",
+            "position": 1,
+            "xor": ["pearson", "spearman", "ktaub"],
+        },
+    ),
+    (
+        "ktaub",
+        bool,
+        {
+            "help_string": "Correlation is the Kendall's tau_b correlation coefficient",
+            "argstr": " -ktaub",
+            "position": 1,
+            "xor": ["pearson", "spearman", "quadrant"],
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Fim_input_spec = specs.SpecInfo(
+t_corr1_d_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Fim_output_spec = specs.SpecInfo(
+t_corr1_d_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Fim(ShellCommandTask):
+class t_corr1_d(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.fim import Fim
-
-    >>> task = Fim()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""functional_corr.nii""
-    >>> task.inputs.ideal_file = OneD.mock()
-    >>> task.inputs.fim_thr = "0.0009"
-    >>> task.inputs.out = ""Correlation""
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.t_corr_1_d import t_corr1_d
+
+    >>> task = t_corr1_d()
+    >>> task.inputs.xset = Nifti1.mock(None)
+    >>> task.inputs.y_1d = File.mock(None)
     >>> task.cmdline
-    '3dfim+ -input functional.nii -ideal_file seed.1D -fim_thr 0.000900 -out Correlation -bucket functional_corr.nii'
+    '3dTcorr1D -prefix u_rc1s1_Template_correlation.nii.gz u_rc1s1_Template.nii seed.1D'
 
 
     """
 
-    input_spec = Fim_input_spec
-    output_spec = Fim_output_spec
-    executable = "3dfim+"
+    input_spec = t_corr1_d_input_spec
+    output_spec = t_corr1_d_output_spec
+    executable = "3dTcorr1D"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/fourier.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/fourier.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,17 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dFourier",
             "argstr": "{in_file}",
@@ -61,22 +65,22 @@
 
 
 class Fourier(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.fourier import Fourier
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.fourier import Fourier
 
     >>> task = Fourier()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.lowpass = "0.1"
-    >>> task.inputs.highpass = "0.005"
-    >>> task.inputs.retrend = "True"
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.lowpass = 0.1
+    >>> task.inputs.highpass = 0.005
+    >>> task.inputs.retrend = True
     >>> task.cmdline
     '3dFourier -highpass 0.005000 -lowpass 0.100000 -prefix functional_fourier -retrend functional.nii'
 
 
     """
 
     input_spec = Fourier_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/fwh_mx.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/refit.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,188 +1,179 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
 
-def acf_param_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["acf_param"]
-
-
-def fwhm_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["fwhm"]
+logger = logging.getLogger(__name__)
 
 
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input dataset",
-            "argstr": "-input {in_file}",
+            "help_string": "input file to 3drefit",
+            "argstr": "{in_file}",
+            "copyfile": True,
             "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "out_file",
-        Path,
+        "deoblique",
+        bool,
         {
-            "help_string": "output file",
-            "argstr": "> {out_file}",
-            "position": -1,
-            "output_file_template": "{in_file}_fwhmx.out",
+            "help_string": "replace current transformation matrix with cardinal matrix",
+            "argstr": "-deoblique",
         },
     ),
     (
-        "out_subbricks",
-        Path,
+        "xorigin",
+        str,
         {
-            "help_string": "output file listing the subbricks FWHM",
-            "argstr": "-out {out_subbricks}",
-            "output_file_template": "{in_file}_subbricks.out",
+            "help_string": "x distance for edge voxel offset",
+            "argstr": "-xorigin {xorigin}",
         },
     ),
     (
-        "mask",
-        File,
+        "yorigin",
+        str,
         {
-            "help_string": "use only voxels that are nonzero in mask",
-            "argstr": "-mask {mask}",
+            "help_string": "y distance for edge voxel offset",
+            "argstr": "-yorigin {yorigin}",
         },
     ),
     (
-        "automask",
-        bool,
-        False,
+        "zorigin",
+        str,
         {
-            "help_string": "compute a mask from THIS dataset, a la 3dAutomask",
-            "argstr": "-automask",
+            "help_string": "z distance for edge voxel offset",
+            "argstr": "-zorigin {zorigin}",
         },
     ),
     (
-        "detrend",
-        ty.Any,
-        False,
+        "duporigin_file",
+        File,
         {
-            "help_string": "instead of demed (0th order detrending), detrend to the specified order.  If order is not given, the program picks q=NT/30. -detrend disables -demed, and includes -unif.",
-            "argstr": "-detrend",
-            "xor": ["demed"],
+            "help_string": "Copies the xorigin, yorigin, and zorigin values from the header of the given dataset",
+            "argstr": "-duporigin {duporigin_file}",
         },
     ),
     (
-        "demed",
-        bool,
+        "xdel",
+        float,
+        {"help_string": "new x voxel dimension in mm", "argstr": "-xdel {xdel}"},
+    ),
+    (
+        "ydel",
+        float,
+        {"help_string": "new y voxel dimension in mm", "argstr": "-ydel {ydel}"},
+    ),
+    (
+        "zdel",
+        float,
+        {"help_string": "new z voxel dimension in mm", "argstr": "-zdel {zdel}"},
+    ),
+    (
+        "xyzscale",
+        float,
         {
-            "help_string": "If the input dataset has more than one sub-brick (e.g., has a time axis), then subtract the median of each voxel's time series before processing FWHM. This will tend to remove intrinsic spatial structure and leave behind the noise.",
-            "argstr": "-demed",
-            "xor": ["detrend"],
+            "help_string": "Scale the size of the dataset voxels by the given factor",
+            "argstr": "-xyzscale {xyzscale}",
         },
     ),
     (
-        "unif",
-        bool,
+        "space",
+        ty.Any,
         {
-            "help_string": "If the input dataset has more than one sub-brick, then normalize each voxel's time series to have the same MAD before processing FWHM.",
-            "argstr": "-unif",
+            "help_string": "Associates the dataset with a specific template type, e.g. TLRC, MNI, ORIG",
+            "argstr": "-space {space}",
         },
     ),
     (
-        "out_detrend",
-        Path,
+        "atrcopy",
+        ty.Any,
         {
-            "help_string": "Save the detrended file into a dataset",
-            "argstr": "-detprefix {out_detrend}",
-            "output_file_template": "{in_file}_detrend",
+            "help_string": "Copy AFNI header attribute from the given file into the header of the dataset(s) being modified. For more information on AFNI header attributes, see documentation file README.attributes. More than one '-atrcopy' option can be used. For AFNI advanced users only. Do NOT use -atrcopy or -atrstring with other modification options. See also -copyaux.",
+            "argstr": "-atrcopy {atrcopy[0]} {atrcopy[1]}",
         },
     ),
     (
-        "geom",
-        bool,
+        "atrstring",
+        ty.Any,
         {
-            "help_string": "if in_file has more than one sub-brick, compute the final estimate as the geometric mean of the individual sub-brick FWHM estimates",
-            "argstr": "-geom",
-            "xor": ["arith"],
+            "help_string": "Copy the last given string into the dataset(s) being modified, giving it the attribute name given by the last string.To be safe, the last string should be in quotes.",
+            "argstr": "-atrstring {atrstring[0]} {atrstring[1]}",
         },
     ),
     (
-        "arith",
-        bool,
+        "atrfloat",
+        ty.Any,
         {
-            "help_string": "if in_file has more than one sub-brick, compute the final estimate as the arithmetic mean of the individual sub-brick FWHM estimates",
-            "argstr": "-arith",
-            "xor": ["geom"],
+            "help_string": "Create or modify floating point attributes. The input values may be specified as a single string in quotes or as a 1D filename or string, example '1 0.2 0 0 -0.2 1 0 0 0 0 1 0' or flipZ.1D or '1D:1,0.2,2@0,-0.2,1,2@0,2@0,1,0'",
+            "argstr": "-atrfloat {atrfloat[0]} {atrfloat[1]}",
         },
     ),
     (
-        "combine",
-        bool,
+        "atrint",
+        ty.Any,
         {
-            "help_string": "combine the final measurements along each axis",
-            "argstr": "-combine",
+            "help_string": "Create or modify integer attributes. The input values may be specified as a single string in quotes or as a 1D filename or string, example '1 0 0 0 0 1 0 0 0 0 1 0' or flipZ.1D or '1D:1,0,2@0,-0,1,2@0,2@0,1,0'",
+            "argstr": "-atrint {atrint[0]} {atrint[1]}",
         },
     ),
     (
-        "compat",
+        "saveatr",
         bool,
-        {"help_string": "be compatible with the older 3dFWHM", "argstr": "-compat"},
+        {
+            "help_string": "(default) Copy the attributes that are known to AFNI into the dset->dblk structure thereby forcing changes to known attributes to be present in the output. This option only makes sense with -atrcopy.",
+            "argstr": "-saveatr",
+        },
     ),
     (
-        "acf",
-        ty.Any,
-        False,
-        {"help_string": "computes the spatial autocorrelation", "argstr": "-acf"},
+        "nosaveatr",
+        bool,
+        {"help_string": "Opposite of -saveatr", "argstr": "-nosaveatr"},
     ),
 ]
-FWHMx_input_spec = specs.SpecInfo(
+Refit_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    (
-        "fwhm",
-        ty.Any,
-        {"help_string": "FWHM along each axis", "callable": "fwhm_callable"},
-    ),
-    (
-        "acf_param",
-        ty.Any,
-        {
-            "help_string": "fitted ACF model parameters",
-            "callable": "acf_param_callable",
-        },
-    ),
-    ("out_acf", File, {"help_string": "output acf file"}),
-]
-FWHMx_output_spec = specs.SpecInfo(
+output_fields = [("out_file", File, {"help_string": "output file"})]
+Refit_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class FWHMx(ShellCommandTask):
+class Refit(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.fwh_mx import FWHMx
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.refit import Refit
+
+    >>> task = Refit()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.deoblique = True
+    >>> task.inputs.duporigin_file = File.mock()
+    >>> task.cmdline
+    '3drefit -deoblique structural.nii'
+
 
-    >>> task = FWHMx()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = File.mock()
+    >>> task = Refit()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.duporigin_file = File.mock()
+    >>> task.inputs.atrfloat = ("IJK_TO_DICOM_REAL", "'1 0.2 0 0 -0.2 1 0 0 0 0 1 0'")
     >>> task.cmdline
-    '3dFWHMx -input functional.nii -out functional_subbricks.out > functional_fwhmx.out'
+    '3drefit -atrfloat IJK_TO_DICOM_REAL "1 0.2 0 0 -0.2 1 0 0 0 0 1 0" structural.nii'
 
 
     """
 
-    input_spec = FWHMx_input_spec
-    output_spec = FWHMx_output_spec
-    executable = "3dFWHMx"
+    input_spec = Refit_input_spec
+    output_spec = Refit_output_spec
+    executable = "3drefit"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/gcor.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/gcor.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,18 +1,14 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 
 
-def out_callable(output_dir, inputs, stdout, stderr):
-    outputs = _list_outputs(
-        output_dir=output_dir, inputs=inputs, stdout=stdout, stderr=stderr
-    )
-    return outputs["out"]
+logger = logging.getLogger(__name__)
 
 
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
@@ -49,39 +45,33 @@
         },
     ),
 ]
 GCOR_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    (
-        "out",
-        float,
-        {"help_string": "global correlation value", "callable": "out_callable"},
-    )
-]
+output_fields = [("out", float, {"help_string": "global correlation value"})]
 GCOR_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
 class GCOR(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.gcor import GCOR
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.gcor import GCOR
 
     >>> task = GCOR()
-    >>> task.inputs.in_file = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
     >>> task.inputs.mask = File.mock()
-    >>> task.inputs.nfirst = "4"
+    >>> task.inputs.nfirst = 4
     >>> task.cmdline
     '@compute_gcor -nfirst 4 -input structural.nii'
 
 
     """
 
     input_spec = GCOR_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/hist.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/skull_strip.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,96 +1,118 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
+import typing as ty
+
+
+logger = logging.getLogger(__name__)
+
 
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input file to 3dHist",
+            "help_string": "input file to 3dSkullStrip",
             "argstr": "-input {in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": 1,
         },
     ),
     (
         "out_file",
         Path,
         {
-            "help_string": "Write histogram to niml file with this prefix",
+            "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_hist",
+            "output_file_template": "{in_file}_skullstrip",
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+skull_strip_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+skull_strip_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class skull_strip(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.skull_strip import skull_strip
+
+    >>> task = skull_strip()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.cmdline
+    '3dSkullStrip -input functional.nii -o_ply -prefix functional_skullstrip'
+
+
+    """
+
+    input_spec = skull_strip_input_spec
+    output_spec = skull_strip_output_spec
+    executable = "3dSkullStrip"
+
+
+input_fields = [
     (
-        "showhist",
-        bool,
-        False,
-        {"help_string": "write a text visual histogram", "argstr": "-showhist"},
+        "in_file",
+        Nifti1,
+        {
+            "help_string": "input file to 3dSkullStrip",
+            "argstr": "-input {in_file}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": 1,
+        },
     ),
     (
-        "out_show",
+        "out_file",
         Path,
         {
             "help_string": "output image file name",
-            "argstr": "> {out_show}",
-            "position": -1,
-            "output_file_template": "{in_file}_hist.out",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_skullstrip",
         },
     ),
-    (
-        "mask",
-        File,
-        {"help_string": "matrix to align input file", "argstr": "-mask {mask}"},
-    ),
-    ("nbin", int, {"help_string": "number of bins", "argstr": "-nbin {nbin}"}),
-    (
-        "max_value",
-        float,
-        {"help_string": "maximum intensity value", "argstr": "-max {max_value}"},
-    ),
-    (
-        "min_value",
-        float,
-        {"help_string": "minimum intensity value", "argstr": "-min {min_value}"},
-    ),
-    (
-        "bin_width",
-        float,
-        {"help_string": "bin width", "argstr": "-binwidth {bin_width}"},
-    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Hist_input_spec = specs.SpecInfo(
+SkullStrip_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Hist_output_spec = specs.SpecInfo(
+SkullStrip_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Hist(ShellCommandTask):
+class SkullStrip(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.hist import Hist
-
-    >>> task = Hist()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = File.mock()
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.skull_strip import SkullStrip
+
+    >>> task = SkullStrip()
+    >>> task.inputs.in_file = Nifti1.mock(None)
     >>> task.cmdline
-    '3dHist -input functional.nii -prefix functional_hist'
+    '3dSkullStrip -input functional.nii -o_ply -prefix functional_skullstrip'
 
 
     """
 
-    input_spec = Hist_input_spec
-    output_spec = Hist_output_spec
-    executable = "3dHist"
+    input_spec = SkullStrip_input_spec
+    output_spec = SkullStrip_output_spec
+    executable = "3dSkullStrip"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/lfcd.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/lfcd.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,13 +1,16 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dLFCD",
             "argstr": "{in_file}",
@@ -46,15 +49,15 @@
             "argstr": "-automask",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file}_afni",
         },
     ),
 ]
@@ -69,22 +72,22 @@
 
 
 class LFCD(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.lfcd import LFCD
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.lfcd import LFCD
 
     >>> task = LFCD()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.thresh = "0.8 # keep all connections with corr >= 0.8"
-    >>> task.inputs.out_file = ""out.nii""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = Nifti1.mock(None)
+    >>> task.inputs.thresh = 0.8 # keep all connections with corr >= 0.8
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
     '3dLFCD -mask mask.nii -prefix out.nii -thresh 0.800000 functional.nii'
 
 
     """
 
     input_spec = LFCD_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/local_bistat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/unifize.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,123 +1,145 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
-from pydra.engine.specs import MultiInputObj
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file1",
+        "in_file",
         Nifti1,
         {
-            "help_string": "Filename of the first image",
-            "argstr": "{in_file1}",
+            "help_string": "input file to 3dUnifize",
+            "argstr": "-input {in_file}",
+            "copyfile": False,
             "mandatory": True,
-            "position": -2,
+            "position": -1,
         },
     ),
     (
-        "in_file2",
+        "out_file",
         Nifti1,
         {
-            "help_string": "Filename of the second image",
-            "argstr": "{in_file2}",
-            "mandatory": True,
-            "position": -1,
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_unifized",
         },
     ),
     (
-        "neighborhood",
-        ty.Any,
+        "t2",
+        bool,
         {
-            "help_string": "The region around each voxel that will be extracted for the statistics calculation. Possible regions are: 'SPHERE', 'RHDD' (rhombic dodecahedron), 'TOHD' (truncated octahedron) with a given radius in mm or 'RECT' (rectangular block) with dimensions to specify in mm.",
-            "argstr": "-nbhd '{neighborhood[0]}({neighborhood[1]})'",
-            "mandatory": True,
+            "help_string": "Treat the input as if it were T2-weighted, rather than T1-weighted. This processing is done simply by inverting the image contrast, processing it as if that result were T1-weighted, and then re-inverting the results counts of voxel overlap, i.e., each voxel will contain the number of masks that it is set in.",
+            "argstr": "-T2",
         },
     ),
     (
-        "stat",
-        MultiInputObj,
+        "gm",
+        bool,
         {
-            "help_string": "Statistics to compute. Possible names are:\n\n  * pearson  = Pearson correlation coefficient\n  * spearman = Spearman correlation coefficient\n  * quadrant = Quadrant correlation coefficient\n  * mutinfo  = Mutual Information\n  * normuti  = Normalized Mutual Information\n  * jointent = Joint entropy\n  * hellinger= Hellinger metric\n  * crU      = Correlation ratio (Unsymmetric)\n  * crM      = Correlation ratio (symmetrized by Multiplication)\n  * crA      = Correlation ratio (symmetrized by Addition)\n  * L2slope  = slope of least-squares (L2) linear regression of\n               the data from dataset1 vs. the dataset2\n               (i.e., d2 = a + b*d1 ==> this is 'b')\n  * L1slope  = slope of least-absolute-sum (L1) linear\n               regression of the data from dataset1 vs.\n               the dataset2\n  * num      = number of the values in the region:\n               with the use of -mask or -automask,\n               the size of the region around any given\n               voxel will vary; this option lets you\n               map that size.\n  * ALL      = all of the above, in that order\n\nMore than one option can be used.",
-            "argstr": "-stat {stat}...",
-            "mandatory": True,
+            "help_string": "Also scale to unifize 'gray matter' = lower intensity voxels (to aid in registering images from different scanners).",
+            "argstr": "-GM",
+        },
+    ),
+    (
+        "urad",
+        float,
+        {
+            "help_string": "Sets the radius (in voxels) of the ball used for the sneaky trick. Default value is 18.3, and should be changed proportionally if the dataset voxel size differs significantly from 1 mm.",
+            "argstr": "-Urad {urad}",
         },
     ),
     (
-        "mask_file",
+        "scale_file",
         File,
         {
-            "help_string": "mask image file name. Voxels NOT in the mask will not be used in the neighborhood of any voxel. Also, a voxel NOT in the mask will have its statistic(s) computed as zero (0).",
-            "argstr": "-mask {mask_file}",
+            "help_string": "output file name to save the scale factor used at each voxel ",
+            "argstr": "-ssave {scale_file}",
         },
     ),
     (
-        "automask",
+        "no_duplo",
         bool,
         {
-            "help_string": "Compute the mask as in program 3dAutomask.",
-            "argstr": "-automask",
-            "xor": ["weight_file"],
+            "help_string": "Do NOT use the 'duplo down' step; this can be useful for lower resolution datasets.",
+            "argstr": "-noduplo",
         },
     ),
     (
-        "weight_file",
-        File,
+        "epi",
+        bool,
         {
-            "help_string": "File name of an image to use as a weight.  Only applies to 'pearson' statistics.",
-            "argstr": "-weight {weight_file}",
-            "xor": ["automask"],
+            "help_string": "Assume the input dataset is a T2 (or T2\\*) weighted EPI time series. After computing the scaling, apply it to ALL volumes (TRs) in the input dataset. That is, a given voxel will be scaled by the same factor at each TR. This option also implies '-noduplo' and '-T2'.This option turns off '-GM' if you turned it on.",
+            "argstr": "-EPI",
+            "requires": ["no_duplo", "t2"],
+            "xor": ["gm"],
         },
     ),
     (
-        "out_file",
-        Path,
+        "rbt",
+        ty.Any,
         {
-            "help_string": "Output dataset.",
-            "argstr": "-prefix {out_file}",
-            "position": 0,
-            "output_file_template": "{in_file1}_bistat",
+            "help_string": "Option for AFNI experts only.Specify the 3 parameters for the algorithm:\nR = radius; same as given by option '-Urad', [default=18.3]\nb = bottom percentile of normalizing data range, [default=70.0]\nr = top percentile of normalizing data range, [default=80.0]\n",
+            "argstr": "-rbt {rbt[0]} {rbt[1]} {rbt[2]}",
+        },
+    ),
+    (
+        "t2_up",
+        float,
+        {
+            "help_string": "Option for AFNI experts only.Set the upper percentile point used for T2-T1 inversion. Allowed to be anything between 90 and 100 (inclusive), with default to 98.5  (for no good reason).",
+            "argstr": "-T2up {t2_up}",
         },
     ),
+    (
+        "cl_frac",
+        float,
+        {
+            "help_string": "Option for AFNI experts only.Set the automask 'clip level fraction'. Must be between 0.1 and 0.9. A small fraction means to make the initial threshold for clipping (a la 3dClipLevel) smaller, which will tend to make the mask larger.  [default=0.1]",
+            "argstr": "-clfrac {cl_frac}",
+        },
+    ),
+    (
+        "quiet",
+        bool,
+        {"help_string": "Don't print the progress messages.", "argstr": "-quiet"},
+    ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-LocalBistat_input_spec = specs.SpecInfo(
+Unifize_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-LocalBistat_output_spec = specs.SpecInfo(
+output_fields = [("scale_file", File, {"help_string": "scale factor file"})]
+Unifize_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class LocalBistat(ShellCommandTask):
+class Unifize(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.engine.specs import MultiInputObj
-    >>> from pydra.tasks.afni.auto.local_bistat import LocalBistat
-
-    >>> task = LocalBistat()
-    >>> task.inputs.in_file1 = Nifti1.mock()
-    >>> task.inputs.in_file2 = Nifti1.mock()
-    >>> task.inputs.neighborhood = "("SPHERE", 1.2)"
-    >>> task.inputs.stat = ""pearson""
-    >>> task.inputs.mask_file = File.mock()
-    >>> task.inputs.weight_file = File.mock()
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.unifize import Unifize
+
+    >>> task = Unifize()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.scale_file = File.mock()
     >>> task.cmdline
-    '3dLocalBistat -prefix functional_bistat.nii -nbhd "SPHERE(1.2)" -stat pearson functional.nii structural.nii'
+    '3dUnifize -prefix structural_unifized.nii -input structural.nii'
 
 
     """
 
-    input_spec = LocalBistat_input_spec
-    output_spec = LocalBistat_output_spec
-    executable = "3dLocalBistat"
+    input_spec = Unifize_input_spec
+    output_spec = Unifize_output_spec
+    executable = "3dUnifize"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/localstat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/localstat.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,18 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.generic import File
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
-from pydra.engine.specs import MultiInputObj
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input dataset",
             "argstr": "{in_file}",
@@ -24,15 +27,15 @@
             "help_string": "The region around each voxel that will be extracted for the statistics calculation. Possible regions are: 'SPHERE', 'RHDD' (rhombic dodecahedron), 'TOHD' (truncated octahedron) with a given radius in mm or 'RECT' (rectangular block) with dimensions to specify in mm.",
             "argstr": "-nbhd '{neighborhood[0]}({neighborhood[1]})'",
             "mandatory": True,
         },
     ),
     (
         "stat",
-        MultiInputObj,
+        ty.List[File],
         {
             "help_string": "statistics to compute. Possible names are:\n\n * mean   = average of the values\n * stdev  = standard deviation\n * var    = variance (stdev\\*stdev)\n * cvar   = coefficient of variation = stdev/fabs(mean)\n * median = median of the values\n * MAD    = median absolute deviation\n * min    = minimum\n * max    = maximum\n * absmax = maximum of the absolute values\n * num    = number of the values in the region:\n            with the use of -mask or -automask,\n            the size of the region around any given\n            voxel will vary; this option lets you\n            map that size.  It may be useful if you\n            plan to compute a t-statistic (say) from\n            the mean and stdev outputs.\n * sum    = sum of the values in the region\n * FWHM   = compute (like 3dFWHM) image smoothness\n            inside each voxel's neighborhood.  Results\n            are in 3 sub-bricks: FWHMx, FHWMy, and FWHMz.\n            Places where an output is -1 are locations\n            where the FWHM value could not be computed\n            (e.g., outside the mask).\n * FWHMbar= Compute just the average of the 3 FWHM values\n            (normally would NOT do this with FWHM also).\n * perc:P0:P1:Pstep =\n            Compute percentiles between P0 and P1 with a\n            step of Pstep.\n            Default P1 is equal to P0 and default P2 = 1\n * rank   = rank of the voxel's intensity\n * frank  = rank / number of voxels in neighborhood\n * P2skew = Pearson's second skewness coefficient\n             3 \\* (mean - median) / stdev\n * ALL    = all of the above, in that order\n            (except for FWHMbar and perc).\n * mMP2s  = Exactly the same output as:\n            median, MAD, P2skew,\n            but a little faster\n * mmMP2s = Exactly the same output as:\n            mean, median, MAD, P2skew\n\nMore than one option can be used.",
             "argstr": "-stat {stat}...",
             "mandatory": True,
         },
     ),
     (
@@ -135,26 +138,25 @@
 
 
 class Localstat(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.medimage.nifti import NiftiGz
-    >>> from pydra.engine.specs import MultiInputObj
-    >>> from pydra.tasks.afni.auto.localstat import Localstat
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.localstat import Localstat
 
     >>> task = Localstat()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.neighborhood = "("SPHERE", 45)"
-    >>> task.inputs.stat = ""mean""
-    >>> task.inputs.mask_file = NiftiGz.mock()
-    >>> task.inputs.nonmask = "True"
-    >>> task.inputs.outputtype = ""NIFTI_GZ""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.neighborhood = ("SPHERE", 45)
+    >>> task.inputs.stat = None
+    >>> task.inputs.mask_file = NiftiGz.mock(None)
+    >>> task.inputs.nonmask = True
+    >>> task.inputs.outputtype = "NIFTI_GZ"
     >>> task.cmdline
     '3dLocalstat -prefix functional_localstat.nii -mask skeleton_mask.nii.gz -nbhd "SPHERE(45.0)" -use_nonmask -stat mean functional.nii'
 
 
     """
 
     input_spec = Localstat_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/mask_tool.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/retroicor.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,129 +1,127 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
-        ty.List[Nifti1],
+        Nifti1,
         {
-            "help_string": "input file or files to 3dmask_tool",
-            "argstr": "-input {in_file}",
+            "help_string": "input file to 3dretroicor",
+            "argstr": "{in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": -1,
         },
     ),
     (
         "out_file",
         Path,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_mask",
+            "position": 1,
+            "output_file_template": "{in_file}_retroicor",
         },
     ),
     (
-        "count",
-        bool,
+        "card",
+        OneD,
         {
-            "help_string": "Instead of created a binary 0/1 mask dataset, create one with counts of voxel overlap, i.e., each voxel will contain the number of masks that it is set in.",
-            "argstr": "-count",
-            "position": 2,
+            "help_string": "1D cardiac data file for cardiac correction",
+            "argstr": "-card {card}",
+            "position": -2,
         },
     ),
     (
-        "datum",
-        ty.Any,
-        {"help_string": "specify data type for output.", "argstr": "-datum {datum}"},
-    ),
-    (
-        "dilate_inputs",
-        str,
+        "resp",
+        OneD,
         {
-            "help_string": "Use this option to dilate and/or erode datasets as they are read. ex. '5 -5' to dilate and erode 5 times",
-            "argstr": "-dilate_inputs {dilate_inputs}",
+            "help_string": "1D respiratory waveform data for correction",
+            "argstr": "-resp {resp}",
+            "position": -3,
         },
     ),
     (
-        "dilate_results",
-        str,
-        {
-            "help_string": "dilate and/or erode combined mask at the given levels.",
-            "argstr": "-dilate_results {dilate_results}",
-        },
-    ),
-    (
-        "frac",
-        float,
+        "threshold",
+        int,
         {
-            "help_string": "When combining masks (across datasets and sub-bricks), use this option to restrict the result to a certain fraction of the set of volumes",
-            "argstr": "-frac {frac}",
+            "help_string": "Threshold for detection of R-wave peaks in input (Make sure it is above the background noise level, Try 3/4 or 4/5 times range plus minimum)",
+            "argstr": "-threshold {threshold}",
+            "position": -4,
         },
     ),
     (
-        "inter",
-        bool,
-        {"help_string": "intersection, this means -frac 1.0", "argstr": "-inter"},
-    ),
-    ("union", bool, {"help_string": "union, this means -frac 0", "argstr": "-union"}),
-    (
-        "fill_holes",
-        bool,
+        "order",
+        int,
         {
-            "help_string": "This option can be used to fill holes in the resulting mask, i.e. after all other processing has been done.",
-            "argstr": "-fill_holes",
+            "help_string": "The order of the correction (2 is typical)",
+            "argstr": "-order {order}",
+            "position": -5,
         },
     ),
     (
-        "fill_dirs",
-        str,
+        "cardphase",
+        File,
         {
-            "help_string": "fill holes only in the given directions. This option is for use with -fill holes. should be a single string that specifies 1-3 of the axes using {x,y,z} labels (i.e. dataset axis order), or using the labels in {R,L,A,P,I,S}.",
-            "argstr": "-fill_dirs {fill_dirs}",
-            "requires": ["fill_holes"],
+            "help_string": "Filename for 1D cardiac phase output",
+            "argstr": "-cardphase {cardphase}",
+            "position": -6,
         },
     ),
     (
-        "verbose",
-        int,
+        "respphase",
+        File,
         {
-            "help_string": "specify verbosity level, for 0 to 3",
-            "argstr": "-verb {verbose}",
+            "help_string": "Filename for 1D resp phase output",
+            "argstr": "-respphase {respphase}",
+            "position": -7,
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-MaskTool_input_spec = specs.SpecInfo(
+Retroicor_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-MaskTool_output_spec = specs.SpecInfo(
+Retroicor_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class MaskTool(ShellCommandTask):
+class Retroicor(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.mask_tool import MaskTool
-
-    >>> task = MaskTool()
-    >>> task.inputs.in_file = None
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.medimage_afni import OneD
+    >>> from pydra.tasks.afni.auto.preprocess.retroicor import Retroicor
+
+    >>> task = Retroicor()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.card = OneD.mock(None)
+    >>> task.inputs.resp = OneD.mock(None)
+    >>> task.inputs.cardphase = File.mock()
+    >>> task.inputs.respphase = File.mock()
+    >>> task.inputs.outputtype = "NIFTI"
     >>> task.cmdline
-    '3dmask_tool -prefix functional_mask.nii -input functional.nii'
+    '3dretroicor -prefix functional_retroicor.nii -resp resp.1D -card mask.1D functional.nii'
 
 
     """
 
-    input_spec = MaskTool_input_spec
-    output_spec = MaskTool_output_spec
-    executable = "3dmask_tool"
+    input_spec = Retroicor_input_spec
+    output_spec = Retroicor_output_spec
+    executable = "3dretroicor"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/maskave.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/maskave.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,13 +1,17 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dmaskave",
             "argstr": "{in_file}",
@@ -58,21 +62,21 @@
 
 
 class Maskave(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.maskave import Maskave
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.maskave import Maskave
 
     >>> task = Maskave()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.quiet = "True"
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = Nifti1.mock(None)
+    >>> task.inputs.quiet = True
     >>> task.cmdline
     '3dmaskave -mask seed_mask.nii -quiet functional.nii > functional_maskave.1D'
 
 
     """
 
     input_spec = Maskave_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/means.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/to_3d.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,106 +1,95 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file_a",
+        "out_file",
         Nifti1,
         {
-            "help_string": "input file to 3dMean",
-            "argstr": "{in_file_a}",
-            "mandatory": True,
-            "position": -2,
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_folder}",
         },
     ),
     (
-        "in_file_b",
-        Nifti1,
+        "in_folder",
+        ty.Any,
         {
-            "help_string": "another input file to 3dMean",
-            "argstr": "{in_file_b}",
+            "help_string": "folder with DICOM images to convert",
+            "argstr": "{in_folder}/*.dcm",
+            "mandatory": True,
             "position": -1,
         },
     ),
     (
-        "datum",
-        str,
-        {
-            "help_string": "Sets the data type of the output dataset",
-            "argstr": "-datum {datum}",
-        },
+        "filetype",
+        ty.Any,
+        {"help_string": "type of datafile being converted", "argstr": "-{filetype}"},
     ),
     (
-        "out_file",
-        Path,
-        {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file_a}_mean",
-        },
+        "skipoutliers",
+        bool,
+        {"help_string": "skip the outliers check", "argstr": "-skip_outliers"},
     ),
-    ("scale", str, {"help_string": "scaling of output", "argstr": "-{scale}scale"}),
     (
-        "non_zero",
+        "assumemosaic",
         bool,
-        {"help_string": "use only non-zero values", "argstr": "-non_zero"},
+        {
+            "help_string": "assume that Siemens image is mosaic",
+            "argstr": "-assume_dicom_mosaic",
+        },
     ),
-    ("std_dev", bool, {"help_string": "calculate std dev", "argstr": "-stdev"}),
-    ("sqr", bool, {"help_string": "mean square instead of value", "argstr": "-sqr"}),
-    ("summ", bool, {"help_string": "take sum, (not average)", "argstr": "-sum"}),
     (
-        "count",
-        bool,
-        {"help_string": "compute count of non-zero voxels", "argstr": "-count"},
+        "datatype",
+        ty.Any,
+        {"help_string": "set output file datatype", "argstr": "-datum {datatype}"},
     ),
     (
-        "mask_inter",
-        bool,
-        {"help_string": "create intersection mask", "argstr": "-mask_inter"},
+        "funcparams",
+        str,
+        {
+            "help_string": "parameters for functional data",
+            "argstr": "-time:zt {funcparams} alt+z2",
+        },
     ),
-    ("mask_union", bool, {"help_string": "create union mask", "argstr": "-mask_union"}),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Means_input_spec = specs.SpecInfo(
+To3D_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Means_output_spec = specs.SpecInfo(
+To3D_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Means(ShellCommandTask):
+class To3D(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.means import Means
-
-    >>> task = Means()
-    >>> task.inputs.in_file_a = Nifti1.mock()
-    >>> task.inputs.in_file_b = Nifti1.mock()
-    >>> task.inputs.out_file = " "output.nii""
-    >>> task.cmdline
-    '3dMean -prefix output.nii im1.nii im2.nii'
-
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.to_3d import To3D
 
-    >>> task = Means()
-    >>> task.inputs.in_file_a = Nifti1.mock()
-    >>> task.inputs.in_file_b = Nifti1.mock()
-    >>> task.inputs.datum = ""short""
-    >>> task.inputs.out_file = " "output.nii""
+    >>> task = To3D()
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.in_folder = "."
+    >>> task.inputs.filetype = "anat"
+    >>> task.inputs.datatype = "float"
     >>> task.cmdline
-    '3dMean -datum short -prefix output.nii im1.nii'
+    'to3d -datum float -anat -prefix dicomdir.nii ./*.dcm'
 
 
     """
 
-    input_spec = Means_input_spec
-    output_spec = Means_output_spec
-    executable = "3dMean"
+    input_spec = To3D_input_spec
+    output_spec = To3D_output_spec
+    executable = "to3d"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/merge.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/merge.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,28 +1,31 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_files",
         ty.List[Nifti1],
         {
             "help_string": "",
             "argstr": "{in_files}",
             "copyfile": False,
             "mandatory": True,
             "position": -1,
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_files}_merge",
         },
     ),
     (
@@ -52,22 +55,22 @@
 
 
 class Merge(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.merge import Merge
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.merge import Merge
 
     >>> task = Merge()
     >>> task.inputs.in_files = None
-    >>> task.inputs.out_file = ""e7.nii""
-    >>> task.inputs.doall = "True"
-    >>> task.inputs.blurfwhm = "4"
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.doall = True
+    >>> task.inputs.blurfwhm = 4
     >>> task.cmdline
     '3dmerge -1blur_fwhm 4 -doall -prefix e7.nii functional.nii functional2.nii'
 
 
     """
 
     input_spec = Merge_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/net_corr.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/re_ho.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,200 +1,254 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input time series file (4D data set)",
+            "help_string": "input dataset",
             "argstr": "-inset {in_file}",
             "mandatory": True,
+            "position": 1,
         },
     ),
     (
-        "in_rois",
-        Nifti1,
+        "out_file",
+        NiftiGz,
         {
-            "help_string": "input set of ROIs, each labelled with distinct integers",
-            "argstr": "-in_rois {in_rois}",
-            "mandatory": True,
+            "help_string": "Output dataset.",
+            "argstr": "-prefix {out_file}",
+            "position": 0,
+            "output_file_template": "{in_file}_reho",
         },
     ),
     (
-        "mask",
-        Nifti1,
+        "chi_sq",
+        bool,
         {
-            "help_string": "can include a whole brain mask within which to calculate correlation. Otherwise, data should be masked already",
-            "argstr": "-mask {mask}",
+            "help_string": "Output the Friedman chi-squared value in addition to the Kendall's W. This option is currently compatible only with the AFNI (BRIK/HEAD) output type; the chi-squared value will be the second sub-brick of the output dataset.",
+            "argstr": "-chi_sq",
         },
     ),
     (
-        "weight_ts",
+        "mask_file",
         File,
         {
-            "help_string": "input a 1D file WTS of weights that will be applied multiplicatively to each ROI's average time series. WTS can be a column- or row-file of values, but it must have the same length as the input time series volume. If the initial average time series was A[n] for n=0,..,(N-1) time points, then applying a set of weights W[n] of the same length from WTS would produce a new time series:  B[n] = A[n] * W[n]",
-            "argstr": "-weight_ts {weight_ts}",
+            "help_string": "Mask within which ReHo should be calculated voxelwise",
+            "argstr": "-mask {mask_file}",
         },
     ),
     (
-        "fish_z",
-        bool,
+        "neighborhood",
+        ty.Any,
         {
-            "help_string": "switch to also output a matrix of Fisher Z-transform values for the corr coefs (r): Z = atanh(r) , (with Z=4 being output along matrix diagonals where r=1, as the r-to-Z conversion is ceilinged at Z = atanh(r=0.999329) = 4, which is still *quite* a high Pearson-r value",
-            "argstr": "-fish_z",
+            "help_string": "\nvoxels in neighborhood. can be:\n``faces`` (for voxel and 6 facewise neighbors, only),\n``edges`` (for voxel and 18 face- and edge-wise neighbors),\n``vertices`` (for voxel and 26 face-, edge-, and node-wise neighbors).",
+            "argstr": "-nneigh {neighborhood}",
+            "xor": ["sphere", "ellipsoid"],
         },
     ),
     (
-        "part_corr",
-        bool,
+        "sphere",
+        float,
         {
-            "help_string": "output the partial correlation matrix",
-            "argstr": "-part_corr",
+            "help_string": "\\\nFor additional voxelwise neighborhood control, the\nradius R of a desired neighborhood can be put in; R is\na floating point number, and must be >1. Examples of\nthe numbers of voxels in a given radius are as follows\n(you can roughly approximate with the ol' :math:`4\\pi\\,R^3/3`\nthing):\n\n    * R=2.0 -> V=33\n    * R=2.3 -> V=57,\n    * R=2.9 -> V=93,\n    * R=3.1 -> V=123,\n    * R=3.9 -> V=251,\n    * R=4.5 -> V=389,\n    * R=6.1 -> V=949,\n\nbut you can choose most any value.",
+            "argstr": "-neigh_RAD {sphere}",
+            "xor": ["neighborhood", "ellipsoid"],
         },
     ),
     (
-        "ts_out",
-        bool,
+        "ellipsoid",
+        ty.Any,
         {
-            "help_string": "switch to output the mean time series of the ROIs that have been used to generate the correlation matrices. Output filenames mirror those of the correlation matrix files, with a '.netts' postfix",
-            "argstr": "-ts_out",
+            "help_string": "\\\nTuple indicating the x, y, and z radius of an ellipsoid\ndefining the neighbourhood of each voxel.\nThe 'hood is then made according to the following relation:\n:math:`(i/A)^2 + (j/B)^2 + (k/C)^2 \\le 1.`\nwhich will have approx. :math:`V=4 \\pi \\, A B C/3`. The impetus for\nthis freedom was for use with data having anisotropic\nvoxel edge lengths.",
+            "argstr": "-neigh_X {ellipsoid[0]} -neigh_Y {ellipsoid[1]} -neigh_Z {ellipsoid[2]}",
+            "xor": ["sphere", "neighborhood"],
         },
     ),
     (
-        "ts_label",
-        bool,
+        "label_set",
+        File,
         {
-            "help_string": "additional switch when using '-ts_out'. Using this option will insert the integer ROI label at the start of each line of the *.netts file created. Thus, for a time series of length N, each line will have N+1 numbers, where the first is the integer ROI label and the subsequent N are scientific notation values",
-            "argstr": "-ts_label",
+            "help_string": "a set of ROIs, each labelled with distinct integers. ReHo will then be calculated per ROI.",
+            "argstr": "-in_rois {label_set}",
         },
     ),
     (
-        "ts_indiv",
+        "overwrite",
         bool,
         {
-            "help_string": "switch to create a directory for each network that contains the average time series for each ROI in individual files (each file has one line). The directories are labelled PREFIX_000_INDIV/, PREFIX_001_INDIV/, etc. (one per network). Within each directory, the files are labelled ROI_001.netts, ROI_002.netts, etc., with the numbers given by the actual ROI integer labels",
-            "argstr": "-ts_indiv",
+            "help_string": "overwrite output file if it already exists",
+            "argstr": "-overwrite",
         },
     ),
+]
+ReHo_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [
     (
-        "ts_wb_corr",
-        bool,
+        "out_vals",
+        File,
+        {"help_string": "Table of labelwise regional homogeneity values"},
+    )
+]
+ReHo_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class ReHo(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.re_ho import ReHo
+
+    >>> task = ReHo()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = NiftiGz.mock(None)
+    >>> task.inputs.mask_file = File.mock()
+    >>> task.inputs.neighborhood = "vertices"
+    >>> task.inputs.label_set = File.mock()
+    >>> task.cmdline
+    '3dReHo -prefix reho.nii.gz -inset functional.nii -nneigh 27'
+
+
+    """
+
+    input_spec = ReHo_input_spec
+    output_spec = ReHo_output_spec
+    executable = "3dReHo"
+
+
+input_fields = [
+    (
+        "in_file",
+        Nifti1,
         {
-            "help_string": "switch to create a set of whole brain correlation maps. Performs whole brain correlation for each ROI's average time series; this will automatically create a directory for each network that contains the set of whole brain correlation maps (Pearson 'r's). The directories are labelled as above for '-ts_indiv' Within each directory, the files are labelled WB_CORR_ROI_001+orig, WB_CORR_ROI_002+orig, etc., with the numbers given by the actual ROI integer labels",
-            "argstr": "-ts_wb_corr",
+            "help_string": "input dataset",
+            "argstr": "-inset {in_file}",
+            "mandatory": True,
+            "position": 1,
         },
     ),
     (
-        "ts_wb_Z",
-        bool,
+        "out_file",
+        NiftiGz,
         {
-            "help_string": "same as above in '-ts_wb_corr', except that the maps have been Fisher transformed to Z-scores the relation: Z=atanh(r). To avoid infinities in the transform, Pearson values are effectively capped at |r| = 0.999329 (where |Z| = 4.0). Files are labelled WB_Z_ROI_001+orig, etc",
-            "argstr": "-ts_wb_Z",
+            "help_string": "Output dataset.",
+            "argstr": "-prefix {out_file}",
+            "position": 0,
+            "output_file_template": "{in_file}_reho",
         },
     ),
     (
-        "ts_wb_strlabel",
+        "chi_sq",
         bool,
         {
-            "help_string": "by default, '-ts_wb_{corr,Z}' output files are named using the int number of a given ROI, such as: WB_Z_ROI_001+orig. With this option, one can replace the int (such as '001') with the string label (such as 'L-thalamus') *if* one has a labeltable attached to the file",
-            "argstr": "-ts_wb_strlabel",
+            "help_string": "Output the Friedman chi-squared value in addition to the Kendall's W. This option is currently compatible only with the AFNI (BRIK/HEAD) output type; the chi-squared value will be the second sub-brick of the output dataset.",
+            "argstr": "-chi_sq",
         },
     ),
     (
-        "nifti",
-        bool,
+        "mask_file",
+        File,
         {
-            "help_string": "output any correlation map files as NIFTI files (default is BRIK/HEAD). Only useful if using '-ts_wb_corr' and/or '-ts_wb_Z'",
-            "argstr": "-nifti",
+            "help_string": "Mask within which ReHo should be calculated voxelwise",
+            "argstr": "-mask {mask_file}",
         },
     ),
     (
-        "output_mask_nonnull",
-        bool,
+        "neighborhood",
+        ty.Any,
         {
-            "help_string": "internally, this program checks for where there are nonnull time series, because we don't like those, in general.  With this flag, the user can output the determined mask of non-null time series.",
-            "argstr": "-output_mask_nonnull",
+            "help_string": "\nvoxels in neighborhood. can be:\n``faces`` (for voxel and 6 facewise neighbors, only),\n``edges`` (for voxel and 18 face- and edge-wise neighbors),\n``vertices`` (for voxel and 26 face-, edge-, and node-wise neighbors).",
+            "argstr": "-nneigh {neighborhood}",
+            "xor": ["sphere", "ellipsoid"],
         },
     ),
     (
-        "push_thru_many_zeros",
-        bool,
+        "sphere",
+        float,
         {
-            "help_string": "by default, this program will grind to a halt and refuse to calculate if any ROI contains >10 percent of voxels with null times series (i.e., each point is 0), as of April, 2017.  This is because it seems most likely that hidden badness is responsible. However, if the user still wants to carry on the calculation anyways, then this option will allow one to push on through.  However, if any ROI *only* has null time series, then the program will not calculate and the user will really, really, really need to address their masking",
-            "argstr": "-push_thru_many_zeros",
+            "help_string": "\\\nFor additional voxelwise neighborhood control, the\nradius R of a desired neighborhood can be put in; R is\na floating point number, and must be >1. Examples of\nthe numbers of voxels in a given radius are as follows\n(you can roughly approximate with the ol' :math:`4\\pi\\,R^3/3`\nthing):\n\n    * R=2.0 -> V=33\n    * R=2.3 -> V=57,\n    * R=2.9 -> V=93,\n    * R=3.1 -> V=123,\n    * R=3.9 -> V=251,\n    * R=4.5 -> V=389,\n    * R=6.1 -> V=949,\n\nbut you can choose most any value.",
+            "argstr": "-neigh_RAD {sphere}",
+            "xor": ["neighborhood", "ellipsoid"],
         },
     ),
     (
-        "ignore_LT",
-        bool,
+        "ellipsoid",
+        ty.Any,
         {
-            "help_string": "switch to ignore any label table labels in the '-in_rois' file, if there are any labels attached",
-            "argstr": "-ignore_LT",
+            "help_string": "\\\nTuple indicating the x, y, and z radius of an ellipsoid\ndefining the neighbourhood of each voxel.\nThe 'hood is then made according to the following relation:\n:math:`(i/A)^2 + (j/B)^2 + (k/C)^2 \\le 1.`\nwhich will have approx. :math:`V=4 \\pi \\, A B C/3`. The impetus for\nthis freedom was for use with data having anisotropic\nvoxel edge lengths.",
+            "argstr": "-neigh_X {ellipsoid[0]} -neigh_Y {ellipsoid[1]} -neigh_Z {ellipsoid[2]}",
+            "xor": ["sphere", "neighborhood"],
         },
     ),
     (
-        "out_file",
-        Path,
+        "label_set",
+        File,
         {
-            "help_string": "output file name part",
-            "argstr": "-prefix {out_file}",
-            "position": 1,
+            "help_string": "a set of ROIs, each labelled with distinct integers. ReHo will then be calculated per ROI.",
+            "argstr": "-in_rois {label_set}",
+        },
+    ),
+    (
+        "overwrite",
+        bool,
+        {
+            "help_string": "overwrite output file if it already exists",
+            "argstr": "-overwrite",
         },
     ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-NetCorr_input_spec = specs.SpecInfo(
+re_ho_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = [
     (
-        "out_corr_matrix",
+        "out_vals",
         File,
-        {
-            "help_string": "output correlation matrix between ROIs written to a text file with .netcc suffix"
-        },
-    ),
-    (
-        "out_corr_maps",
-        ty.List[File],
-        {"help_string": "output correlation maps in Pearson and/or Z-scores"},
-    ),
+        {"help_string": "Table of labelwise regional homogeneity values"},
+    )
 ]
-NetCorr_output_spec = specs.SpecInfo(
+re_ho_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class NetCorr(ShellCommandTask):
+class re_ho(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.net_corr import NetCorr
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.re_ho import re_ho
 
-    >>> task = NetCorr()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.in_rois = Nifti1.mock()
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.weight_ts = File.mock()
-    >>> task.inputs.fish_z = "True"
-    >>> task.inputs.ts_wb_corr = "True"
-    >>> task.inputs.ts_wb_Z = "True"
-    >>> task.inputs.out_file = ""sub0.tp1.ncorr""
+    >>> task = re_ho()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = NiftiGz.mock(None)
+    >>> task.inputs.mask_file = File.mock()
+    >>> task.inputs.neighborhood = "vertices"
+    >>> task.inputs.label_set = File.mock()
     >>> task.cmdline
-    '3dNetCorr -prefix sub0.tp1.ncorr -fish_z -inset functional.nii -in_rois maps.nii -mask mask.nii -ts_wb_Z -ts_wb_corr'
+    '3dReHo -prefix reho.nii.gz -inset functional.nii -nneigh 27'
 
 
     """
 
-    input_spec = NetCorr_input_spec
-    output_spec = NetCorr_output_spec
-    executable = "3dNetCorr"
+    input_spec = re_ho_input_spec
+    output_spec = re_ho_output_spec
+    executable = "3dReHo"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/notes.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/notes.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,17 @@
 from fileformats.generic import File
 from fileformats.medimage_afni import Head
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Head,
         {
             "help_string": "input file to 3dNotes",
             "argstr": "{in_file}",
@@ -40,15 +43,15 @@
     (
         "ses",
         bool,
         {"help_string": "print to stdout the expanded notes", "argstr": "-ses"},
     ),
     (
         "out_file",
-        Path,
+        File,
         {"help_string": "output image file name", "argstr": "{out_file}"},
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
 Notes_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
@@ -63,20 +66,21 @@
 class Notes(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
     >>> from fileformats.medimage_afni import Head
-    >>> from pydra.tasks.afni.auto.notes import Notes
+    >>> from pydra.tasks.afni.auto.utils.notes import Notes
 
     >>> task = Notes()
-    >>> task.inputs.in_file = Head.mock()
-    >>> task.inputs.add = ""This note is added.""
-    >>> task.inputs.add_history = ""This note is added to history.""
+    >>> task.inputs.in_file = Head.mock(None)
+    >>> task.inputs.add = "This note is added."
+    >>> task.inputs.add_history = "This note is added to history."
+    >>> task.inputs.out_file = File.mock()
     >>> task.cmdline
     '3dNotes -a "This note is added." -h "This note is added to history." functional.HEAD'
 
 
     """
 
     input_spec = Notes_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/nwarp_adjust.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/autobox.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,68 +1,86 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "warps",
-        ty.List[NiftiGz],
+        "in_file",
+        Nifti1,
         {
-            "help_string": "List of input 3D warp datasets",
-            "argstr": "-nwarp {warps}",
+            "help_string": "input file",
+            "argstr": "-input {in_file}",
+            "copyfile": False,
             "mandatory": True,
         },
     ),
     (
-        "in_files",
-        ty.List[File],
+        "padding",
+        int,
         {
-            "help_string": "List of input 3D datasets to be warped by the adjusted warp datasets.  There must be exactly as many of these datasets as there are input warps.",
-            "argstr": "-source {in_files}",
+            "help_string": "Number of extra voxels to pad on each side of box",
+            "argstr": "-npad {padding}",
         },
     ),
     (
         "out_file",
         Path,
         {
-            "help_string": "Output mean dataset, only needed if in_files are also given. The output dataset will be on the common grid shared by the source datasets.",
+            "help_string": "",
             "argstr": "-prefix {out_file}",
-            "requires": ["in_files"],
-            "output_file_template": "{in_files}_NwarpAdjust",
+            "output_file_template": "{in_file}_autobox",
+        },
+    ),
+    (
+        "no_clustering",
+        bool,
+        {
+            "help_string": "Don't do any clustering to find box. Any non-zero voxel will be preserved in the cropped volume. The default method uses some clustering to find the cropping box, and will clip off small isolated blobs.",
+            "argstr": "-noclust",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-NwarpAdjust_input_spec = specs.SpecInfo(
+Autobox_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-NwarpAdjust_output_spec = specs.SpecInfo(
+output_fields = [
+    ("x_min", int, {}),
+    ("x_max", int, {}),
+    ("y_min", int, {}),
+    ("y_max", int, {}),
+    ("z_min", int, {}),
+    ("z_max", int, {}),
+]
+Autobox_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class NwarpAdjust(ShellCommandTask):
+class Autobox(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import NiftiGz
-    >>> from pydra.tasks.afni.auto.nwarp_adjust import NwarpAdjust
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.autobox import Autobox
 
-    >>> task = NwarpAdjust()
-    >>> task.inputs.warps = None
+    >>> task = Autobox()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.padding = 5
     >>> task.cmdline
-    '3dNwarpAdjust -nwarp func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz'
+    '3dAutobox -input structural.nii -prefix structural_autobox -npad 5'
 
 
     """
 
-    input_spec = NwarpAdjust_input_spec
-    output_spec = NwarpAdjust_output_spec
-    executable = "3dNwarpAdjust"
+    input_spec = Autobox_input_spec
+    output_spec = Autobox_output_spec
+    executable = "3dAutobox"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/nwarp_apply.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/svm_test.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,117 +1,109 @@
 from fileformats.generic import File
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
-        ty.Any,
+        "model",
+        str,
         {
-            "help_string": "the name of the dataset to be warped can be multiple datasets",
-            "argstr": "-source {in_file}",
+            "help_string": "modname is the basename for the brik containing the SVM model",
+            "argstr": "-model {model}",
             "mandatory": True,
         },
     ),
     (
-        "warp",
-        ty.Any,
+        "in_file",
+        File,
         {
-            "help_string": "the name of the warp dataset. multiple warps can be concatenated (make sure they exist)",
-            "argstr": "-nwarp {warp}",
+            "help_string": "A 3D or 3D+t AFNI brik dataset to be used for testing.",
+            "argstr": "-testvol {in_file}",
             "mandatory": True,
         },
     ),
     (
-        "inv_warp",
-        bool,
+        "out_file",
+        Path,
         {
-            "help_string": "After the warp specified in '-nwarp' is computed, invert it",
-            "argstr": "-iwarp",
+            "help_string": "filename for .1D prediction file(s).",
+            "argstr": "-predictions {out_file}",
+            "output_file_template": "%s_predictions",
         },
     ),
     (
-        "master",
+        "testlabels",
         File,
         {
-            "help_string": "the name of the master dataset, which defines the output grid",
-            "argstr": "-master {master}",
+            "help_string": "*true* class category .1D labels for the test dataset. It is used to calculate the prediction accuracy performance",
+            "argstr": "-testlabels {testlabels}",
         },
     ),
     (
-        "interp",
-        ty.Any,
-        "wsinc5",
+        "classout",
+        bool,
         {
-            "help_string": "defines interpolation method to use during warp",
-            "argstr": "-interp {interp}",
+            "help_string": "Flag to specify that pname files should be integer-valued, corresponding to class category decisions.",
+            "argstr": "-classout",
         },
     ),
     (
-        "ainterp",
-        ty.Any,
+        "nopredcensord",
+        bool,
         {
-            "help_string": "specify a different interpolation method than might be used for the warp",
-            "argstr": "-ainterp {ainterp}",
+            "help_string": "Flag to prevent writing predicted values for censored time-points",
+            "argstr": "-nopredcensord",
         },
     ),
     (
-        "out_file",
-        Path,
+        "nodetrend",
+        bool,
         {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_Nwarp",
+            "help_string": "Flag to specify that pname files should not be linearly detrended",
+            "argstr": "-nodetrend",
         },
     ),
     (
-        "short",
+        "multiclass",
         bool,
         {
-            "help_string": "Write output dataset using 16-bit short integers, rather than the usual 32-bit floats.",
-            "argstr": "-short",
+            "help_string": "Specifies multiclass algorithm for classification",
+            "argstr": "-multiclass {multiclass}",
         },
     ),
     (
-        "quiet",
-        bool,
-        {"help_string": "don't be verbose :(", "argstr": "-quiet", "xor": ["verb"]},
-    ),
-    (
-        "verb",
-        bool,
-        {"help_string": "be extra verbose :)", "argstr": "-verb", "xor": ["quiet"]},
+        "options",
+        str,
+        {"help_string": "additional options for SVM-light", "argstr": "{options}"},
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-NwarpApply_input_spec = specs.SpecInfo(
+SVMTest_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-NwarpApply_output_spec = specs.SpecInfo(
+SVMTest_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class NwarpApply(ShellCommandTask):
+class SVMTest(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from pydra.tasks.afni.auto.nwarp_apply import NwarpApply
-
-    >>> task = NwarpApply()
-    >>> task.inputs.in_file = ""Fred+orig""
-    >>> task.inputs.warp = ""'Fred_WARP+tlrc Fred.Xaff12.1D'""
-    >>> task.inputs.master = File.mock()
-    >>> task.cmdline
-    '3dNwarpApply -source Fred+orig -interp wsinc5 -master NWARP -prefix Fred+orig_Nwarp -nwarp "Fred_WARP+tlrc Fred.Xaff12.1D"'
-
+    >>> from pydra.tasks.afni.auto.svm.svm_test import SVMTest
 
     """
 
-    input_spec = NwarpApply_input_spec
-    output_spec = NwarpApply_output_spec
-    executable = "3dNwarpApply"
+    input_spec = SVMTest_input_spec
+    output_spec = SVMTest_output_spec
+    executable = "3dsvm"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/nwarp_cat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/t_stat.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,88 +1,137 @@
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_files",
-        list,
+        "in_file",
+        Nifti1,
         {
-            "help_string": "list of tuples of 3D warps and associated functions",
-            "argstr": "{in_files}",
+            "help_string": "input file to 3dTstat",
+            "argstr": "{in_file}",
+            "copyfile": False,
             "mandatory": True,
             "position": -1,
         },
     ),
     (
-        "space",
-        ty.Any,
+        "out_file",
+        Path,
         {
-            "help_string": "string to attach to the output dataset as its atlas space marker.",
-            "argstr": "-space {space}",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_tstat",
         },
     ),
+    ("mask", File, {"help_string": "mask file", "argstr": "-mask {mask}"}),
     (
-        "inv_warp",
-        bool,
-        {"help_string": "invert the final warp before output", "argstr": "-iwarp"},
-    ),
-    (
-        "interp",
-        ty.Any,
-        "wsinc5",
-        {
-            "help_string": "specify a different interpolation method than might be used for the warp",
-            "argstr": "-interp {interp}",
-        },
+        "options",
+        str,
+        {"help_string": "selected statistical output", "argstr": "{options}"},
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+t_stat_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+t_stat_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class t_stat(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.t_stat import t_stat
+
+    >>> task = t_stat()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = None
+    >>> task.inputs.mask = File.mock()
+    >>> task.cmdline
+    '3dTstat -mean -prefix stats functional.nii'
+
+
+    """
+
+    input_spec = t_stat_input_spec
+    output_spec = t_stat_output_spec
+    executable = "3dTstat"
+
+
+input_fields = [
     (
-        "expad",
-        int,
+        "in_file",
+        Nifti1,
         {
-            "help_string": "Pad the nonlinear warps by the given number of voxels in all directions. The warp displacements are extended by linear extrapolation from the faces of the input grid..",
-            "argstr": "-expad {expad}",
+            "help_string": "input file to 3dTstat",
+            "argstr": "{in_file}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
         "out_file",
         Path,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_files}_NwarpCat",
+            "output_file_template": "{in_file}_tstat",
         },
     ),
-    ("verb", bool, {"help_string": "be verbose", "argstr": "-verb"}),
+    ("mask", File, {"help_string": "mask file", "argstr": "-mask {mask}"}),
+    (
+        "options",
+        str,
+        {"help_string": "selected statistical output", "argstr": "{options}"},
+    ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-NwarpCat_input_spec = specs.SpecInfo(
+TStat_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-NwarpCat_output_spec = specs.SpecInfo(
+TStat_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class NwarpCat(ShellCommandTask):
+class TStat(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from pydra.tasks.afni.auto.nwarp_cat import NwarpCat
-
-    >>> task = NwarpCat()
-    >>> task.inputs.in_files = "["Q25_warp+tlrc.HEAD", ("IDENT", "structural.nii")]"
-    >>> task.inputs.out_file = ""Fred_total_WARP""
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.t_stat import TStat
+
+    >>> task = TStat()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = None
+    >>> task.inputs.mask = File.mock()
     >>> task.cmdline
-    '3dNwarpCat -interp wsinc5 -prefix Fred_total_WARP Q25_warp+tlrc.HEAD "IDENT(structural.nii)"'
+    '3dTstat -mean -prefix stats functional.nii'
 
 
     """
 
-    input_spec = NwarpCat_input_spec
-    output_spec = NwarpCat_output_spec
-    executable = "3dNwarpCat"
+    input_spec = TStat_input_spec
+    output_spec = TStat_output_spec
+    executable = "3dTstat"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/one_d_tool_py.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/svm_train.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,145 +1,146 @@
 from fileformats.generic import File
-from fileformats.medimage_afni import OneD
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
-        OneD,
+        "ttype",
+        str,
         {
-            "help_string": "input file to OneDTool",
-            "argstr": "-infile {in_file}",
+            "help_string": "tname: classification or regression",
+            "argstr": "-type {ttype}",
             "mandatory": True,
         },
     ),
     (
-        "set_nruns",
-        int,
+        "in_file",
+        File,
         {
-            "help_string": "treat the input data as if it has nruns",
-            "argstr": "-set_nruns {set_nruns}",
+            "help_string": "A 3D+t AFNI brik dataset to be used for training.",
+            "argstr": "-trainvol {in_file}",
+            "copyfile": False,
+            "mandatory": True,
         },
     ),
     (
-        "derivative",
-        bool,
+        "out_file",
+        Path,
         {
-            "help_string": "take the temporal derivative of each vector (done as first backward difference)",
-            "argstr": "-derivative",
+            "help_string": "output sum of weighted linear support vectors file name",
+            "argstr": "-bucket {out_file}",
+            "output_file_template": "{in_file}_vectors",
         },
     ),
     (
-        "demean",
-        bool,
+        "model",
+        Path,
         {
-            "help_string": "demean each run (new mean of each run = 0.0)",
-            "argstr": "-demean",
+            "help_string": "basename for the brik containing the SVM model",
+            "argstr": "-model {model}",
+            "output_file_template": "{in_file}_model",
         },
     ),
     (
-        "out_file",
+        "alphas",
         Path,
         {
-            "help_string": "write the current 1D data to FILE",
-            "argstr": "-write {out_file}",
-            "xor": ["show_cormat_warnings"],
+            "help_string": "output alphas file name",
+            "argstr": "-alpha {alphas}",
+            "output_file_template": "{in_file}_alphas",
         },
     ),
     (
-        "show_censor_count",
-        bool,
+        "mask",
+        File,
         {
-            "help_string": "display the total number of censored TRs  Note : if input is a valid xmat.1D dataset, then the count will come from the header.  Otherwise the input is assumed to be a binary censorfile, and zeros are simply counted.",
-            "argstr": "-show_censor_count",
+            "help_string": "byte-format brik file used to mask voxels in the analysis",
+            "argstr": "-mask {mask}",
+            "copyfile": False,
+            "position": -1,
         },
     ),
     (
-        "censor_motion",
-        ty.Any,
+        "nomodelmask",
+        bool,
         {
-            "help_string": "Tuple of motion limit and outfile prefix. need to also set set_nruns -r set_run_lengths",
-            "argstr": "-censor_motion {censor_motion[0]} {censor_motion[1]}",
+            "help_string": "Flag to enable the omission of a mask file",
+            "argstr": "-nomodelmask",
         },
     ),
     (
-        "censor_prev_TR",
-        bool,
+        "trainlabels",
+        File,
         {
-            "help_string": "for each censored TR, also censor previous",
-            "argstr": "-censor_prev_TR",
+            "help_string": ".1D labels corresponding to the stimulus paradigm for the training data.",
+            "argstr": "-trainlabels {trainlabels}",
         },
     ),
     (
-        "show_trs_uncensored",
-        ty.Any,
+        "censor",
+        File,
         {
-            "help_string": "display a list of TRs which were not censored in the specified style",
-            "argstr": "-show_trs_uncensored {show_trs_uncensored}",
+            "help_string": ".1D censor file that allows the user to ignore certain samples in the training data.",
+            "argstr": "-censor {censor}",
         },
     ),
     (
-        "show_cormat_warnings",
-        File,
+        "kernel",
+        str,
         {
-            "help_string": "Write cormat warnings to a file",
-            "argstr": "-show_cormat_warnings |& tee {show_cormat_warnings}",
-            "position": -1,
-            "xor": ["out_file"],
+            "help_string": "string specifying type of kernel function:linear, polynomial, rbf, sigmoid",
+            "argstr": "-kernel {kernel}",
         },
     ),
     (
-        "show_indices_interest",
-        bool,
+        "max_iterations",
+        int,
         {
-            "help_string": "display column indices for regs of interest",
-            "argstr": "-show_indices_interest",
+            "help_string": "Specify the maximum number of iterations for the optimization.",
+            "argstr": "-max_iterations {max_iterations}",
         },
     ),
     (
-        "show_trs_run",
-        int,
+        "w_out",
+        bool,
         {
-            "help_string": "restrict -show_trs_[un]censored to the given 1-based run",
-            "argstr": "-show_trs_run {show_trs_run}",
+            "help_string": "output sum of weighted linear support vectors",
+            "argstr": "-wout",
         },
     ),
+    (
+        "options",
+        str,
+        {"help_string": "additional options for SVM-light", "argstr": "{options}"},
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
-    ("py27_path", ty.Any, "python2", {"help_string": ""}),
 ]
-OneDToolPy_input_spec = specs.SpecInfo(
+SVMTrain_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", OneD, {"help_string": "output of 1D_tool.py"})]
-OneDToolPy_output_spec = specs.SpecInfo(
+output_fields = []
+SVMTrain_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class OneDToolPy(ShellCommandTask):
+class SVMTrain(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.one_d_tool_py import OneDToolPy
-
-    >>> task = OneDToolPy()
-    >>> task.inputs.in_file = OneD.mock()
-    >>> task.inputs.set_nruns = "3"
-    >>> task.inputs.demean = "True"
-    >>> task.inputs.out_file = ""motion_dmean.1D""
-    >>> task.inputs.show_cormat_warnings = File.mock()
-    >>> task.cmdline
-    'python2 ...1d_tool.py -demean -infile f1.1D -write motion_dmean.1D -set_nruns 3'
-
+    >>> from pydra.tasks.afni.auto.svm.svm_train import SVMTrain
 
     """
 
-    input_spec = OneDToolPy_input_spec
-    output_spec = OneDToolPy_output_spec
-    executable = "1d_tool.py"
+    input_spec = SVMTrain_input_spec
+    output_spec = SVMTrain_output_spec
+    executable = "3dsvm"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/outlier_count.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/seg.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,135 +1,136 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input dataset",
-            "argstr": "{in_file}",
+            "help_string": "ANAT is the volume to segment",
+            "argstr": "-anat {in_file}",
+            "copyfile": True,
             "mandatory": True,
-            "position": -2,
+            "position": -1,
         },
     ),
     (
         "mask",
-        File,
+        ty.Any,
         {
-            "help_string": "only count voxels within the given mask",
+            "help_string": 'only non-zero voxels in mask are analyzed. mask can either be a dataset or the string "AUTO" which would use AFNI\'s automask function to create the mask.',
             "argstr": "-mask {mask}",
-            "xor": ["autoclip", "automask"],
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "qthr",
+        "blur_meth",
         ty.Any,
-        0.001,
         {
-            "help_string": "indicate a value for q to compute alpha",
-            "argstr": "-qthr {qthr:.5}",
+            "help_string": "set the blurring method for bias field estimation",
+            "argstr": "-blur_meth {blur_meth}",
         },
     ),
     (
-        "autoclip",
-        bool,
-        False,
+        "bias_fwhm",
+        float,
         {
-            "help_string": "clip off small voxels",
-            "argstr": "-autoclip",
-            "xor": ["mask"],
+            "help_string": "The amount of blurring used when estimating the field bias with the Wells method",
+            "argstr": "-bias_fwhm {bias_fwhm}",
         },
     ),
     (
-        "automask",
-        bool,
-        False,
+        "classes",
+        str,
         {
-            "help_string": "clip off small voxels",
-            "argstr": "-automask",
-            "xor": ["mask"],
+            "help_string": "CLASS_STRING is a semicolon delimited string of class labels",
+            "argstr": "-classes {classes}",
         },
     ),
     (
-        "fraction",
-        bool,
-        False,
+        "bmrf",
+        float,
         {
-            "help_string": "write out the fraction of masked voxels which are outliers at each timepoint",
-            "argstr": "-fraction",
+            "help_string": "Weighting factor controlling spatial homogeneity of the classifications",
+            "argstr": "-bmrf {bmrf}",
         },
     ),
     (
-        "interval",
-        bool,
-        False,
+        "bias_classes",
+        str,
         {
-            "help_string": "write out the median + 3.5 MAD of outlier count with each timepoint",
-            "argstr": "-range",
+            "help_string": "A semicolon delimited string of classes that contribute to the estimation of the bias field",
+            "argstr": "-bias_classes {bias_classes}",
         },
     ),
-    ("save_outliers", bool, False, {"help_string": "enables out_file option"}),
     (
-        "outliers_file",
-        File,
-        {"help_string": "output image file name", "argstr": "-save {outliers_file}"},
+        "prefix",
+        str,
+        {
+            "help_string": "the prefix for the output folder containing all output volumes",
+            "argstr": "-prefix {prefix}",
+        },
     ),
     (
-        "polort",
-        int,
+        "mixfrac",
+        str,
         {
-            "help_string": "detrend each voxel timeseries with polynomials",
-            "argstr": "-polort {polort}",
+            "help_string": "MIXFRAC sets up the volume-wide (within mask) tissue fractions while initializing the segmentation (see IGNORE for exception)",
+            "argstr": "-mixfrac {mixfrac}",
         },
     ),
     (
-        "legendre",
-        bool,
-        False,
-        {"help_string": "use Legendre polynomials", "argstr": "-legendre"},
+        "mixfloor",
+        float,
+        {
+            "help_string": "Set the minimum value for any class's mixing fraction",
+            "argstr": "-mixfloor {mixfloor}",
+        },
     ),
     (
-        "out_file",
-        Path,
+        "main_N",
+        int,
         {
-            "help_string": "capture standard output",
-            "output_file_template": "{in_file}_outliers",
+            "help_string": "Number of iterations to perform.",
+            "argstr": "-main_N {main_N}",
         },
     ),
 ]
-OutlierCount_input_spec = specs.SpecInfo(
+Seg_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_outliers", File, {"help_string": "output image file name"})]
-OutlierCount_output_spec = specs.SpecInfo(
+output_fields = [("out_file", File, {"help_string": "output file"})]
+Seg_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class OutlierCount(ShellCommandTask):
+class Seg(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.outlier_count import OutlierCount
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.seg import Seg
 
-    >>> task = OutlierCount()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = File.mock()
-    >>> task.inputs.outliers_file = File.mock()
+    >>> task = Seg()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = "AUTO"
     >>> task.cmdline
-    '3dToutcount -qthr 0.00100 functional.nii'
+    '3dSeg -mask AUTO -anat structural.nii'
 
 
     """
 
-    input_spec = OutlierCount_input_spec
-    output_spec = OutlierCount_output_spec
-    executable = "3dToutcount"
+    input_spec = Seg_input_spec
+    output_spec = Seg_output_spec
+    executable = "3dSeg"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/quality_index.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/a_f_n_ito_n_i_f_t_i.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,116 +1,99 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
+import typing as ty
+
+
+logger = logging.getLogger(__name__)
+
 
 input_fields = [
     (
         "in_file",
-        Nifti1,
+        File,
         {
-            "help_string": "input dataset",
+            "help_string": "input file to 3dAFNItoNIFTI",
             "argstr": "{in_file}",
+            "copyfile": False,
             "mandatory": True,
-            "position": -2,
-        },
-    ),
-    (
-        "mask",
-        File,
-        {
-            "help_string": "compute correlation only across masked voxels",
-            "argstr": "-mask {mask}",
-            "xor": ["autoclip", "automask"],
+            "position": -1,
         },
     ),
     (
-        "spearman",
-        bool,
-        False,
+        "out_file",
+        Nifti1,
         {
-            "help_string": "Quality index is 1 minus the Spearman (rank) correlation coefficient of each sub-brick with the median sub-brick. (default).",
-            "argstr": "-spearman",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}.nii",
         },
     ),
     (
-        "quadrant",
+        "pure",
         bool,
-        False,
         {
-            "help_string": "Similar to -spearman, but using 1 minus the quadrant correlation coefficient as the quality index.",
-            "argstr": "-quadrant",
+            "help_string": "Do NOT write an AFNI extension field into the output file. Only use this option if needed. You can also use the 'nifti_tool' program to strip extensions from a file.",
+            "argstr": "-pure",
         },
     ),
     (
-        "autoclip",
+        "denote",
         bool,
-        False,
         {
-            "help_string": "clip off small voxels",
-            "argstr": "-autoclip",
-            "xor": ["mask"],
+            "help_string": "When writing the AFNI extension field, remove text notes that might contain subject identifying information.",
+            "argstr": "-denote",
         },
     ),
     (
-        "automask",
+        "oldid",
         bool,
-        False,
         {
-            "help_string": "clip off small voxels",
-            "argstr": "-automask",
-            "xor": ["mask"],
+            "help_string": "Give the new dataset the input datasets AFNI ID code.",
+            "argstr": "-oldid",
+            "xor": ["newid"],
         },
     ),
-    ("clip", float, {"help_string": "clip off values below", "argstr": "-clip {clip}"}),
     (
-        "interval",
+        "newid",
         bool,
-        False,
-        {
-            "help_string": "write out the median + 3.5 MAD of outlier count with each timepoint",
-            "argstr": "-range",
-        },
-    ),
-    (
-        "out_file",
-        Path,
         {
-            "help_string": "capture standard output",
-            "argstr": "> {out_file}",
-            "position": -1,
-            "output_file_template": "{in_file}_tqual",
+            "help_string": "Give the new dataset a new AFNI ID code, to distinguish it from the input dataset.",
+            "argstr": "-newid",
+            "xor": ["oldid"],
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-QualityIndex_input_spec = specs.SpecInfo(
+a_f_n_ito_n_i_f_t_i_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-QualityIndex_output_spec = specs.SpecInfo(
+a_f_n_ito_n_i_f_t_i_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class QualityIndex(ShellCommandTask):
+class a_f_n_ito_n_i_f_t_i(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.quality_index import QualityIndex
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.a_f_n_ito_n_i_f_t_i import a_f_n_ito_n_i_f_t_i
 
-    >>> task = QualityIndex()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = File.mock()
+    >>> task = a_f_n_ito_n_i_f_t_i()
+    >>> task.inputs.in_file = File.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
     >>> task.cmdline
-    '3dTqual functional.nii > functional_tqual'
+    '3dAFNItoNIFTI -prefix afni_output.nii afni_output.3D'
 
 
     """
 
-    input_spec = QualityIndex_input_spec
-    output_spec = QualityIndex_output_spec
-    executable = "3dTqual"
+    input_spec = a_f_n_ito_n_i_f_t_i_input_spec
+    output_spec = a_f_n_ito_n_i_f_t_i_output_spec
+    executable = "3dAFNItoNIFTI"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/qwarp.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/qwarp.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1, NiftiGz
 from fileformats.medimage_afni import Head
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         ty.Union[Nifti1, NiftiGz],
         {
             "help_string": "Source image (opposite phase encoding direction than base image).",
             "argstr": "-source {in_file}",
@@ -26,15 +28,15 @@
             "argstr": "-base {base_file}",
             "copyfile": False,
             "mandatory": True,
         },
     ),
     (
         "out_file",
-        Path,
+        NiftiGz,
         {
             "help_string": "Sets the prefix/suffix for the output datasets.\n\n* The source dataset is warped to match the base\n  and gets prefix 'ppp'. (Except if '-plusminus' is used\n* The final interpolation to this output dataset is\n  done using the 'wsinc5' method.  See the output of\n  3dAllineate -HELP\n  (in the \"Modifying '-final wsinc5'\" section) for\n  the lengthy technical details.\n* The 3D warp used is saved in a dataset with\n  prefix 'ppp_WARP' -- this dataset can be used\n  with 3dNwarpApply and 3dNwarpCat, for example.\n* To be clear, this is the warp from source dataset\n  coordinates to base dataset coordinates, where the\n  values at each base grid point are the xyz displacements\n  needed to move that grid point's xyz values to the\n  corresponding xyz values in the source dataset:\n  base( (x,y,z) + WARP(x,y,z) ) matches source(x,y,z)\n  Another way to think of this warp is that it 'pulls'\n  values back from source space to base space.\n* 3dNwarpApply would use 'ppp_WARP' to transform datasets\n  aligned with the source dataset to be aligned with the\n  base dataset.\n\n**If you do NOT want this warp saved, use the option '-nowarp'**.\n(However, this warp is usually the most valuable possible output!)\n\n* If you want to calculate and save the inverse 3D warp,\n  use the option '-iwarp'.  This inverse warp will then be\n  saved in a dataset with prefix 'ppp_WARPINV'.\n* This inverse warp could be used to transform data from base\n  space to source space, if you need to do such an operation.\n* You can easily compute the inverse later, say by a command like\n  3dNwarpCat -prefix Z_WARPINV 'INV(Z_WARP+tlrc)'\n  or the inverse can be computed as needed in 3dNwarpApply, like\n  3dNwarpApply -nwarp 'INV(Z_WARP+tlrc)' -source Dataset.nii ...\n\n",
             "argstr": "-prefix {out_file}",
         },
     ),
     (
         "resample",
@@ -139,15 +141,15 @@
             "help_string": "Similar to '-wball', but here, you provide a dataset 'ws'\nthat indicates where to increase the weight.\n\n* The 'ws' dataset must be on the same 3D grid as the base dataset.\n* 'ws' is treated as a mask -- it only matters where it\n  is nonzero -- otherwise, the values inside are not used.\n* After 'ws' comes the factor 'f' by which to increase the\n  automatically computed weight.  Where 'ws' is nonzero,\n  the weighting will be multiplied by (1+f).\n* As with '-wball', the factor 'f' should be between 1 and 100.\n\n",
             "argstr": "-wpass {wmask[0]} {wmask[1]}",
             "xor": ["wball"],
         },
     ),
     (
         "out_weight_file",
-        Path,
+        File,
         {
             "help_string": "Write the weight volume to disk as a dataset",
             "argstr": "-wtprefix {out_weight_file}",
         },
     ),
     (
         "blur",
@@ -435,104 +437,114 @@
 
 class Qwarp(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.medimage.nifti import NiftiGz
+    >>> from fileformats.medimage import Nifti1, NiftiGz
     >>> from fileformats.medimage_afni import Head
-    >>> from pydra.tasks.afni.auto.qwarp import Qwarp
+    >>> from pydra.tasks.afni.auto.preprocess.qwarp import Qwarp
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
+    >>> task.inputs.out_file = NiftiGz.mock()
     >>> task.inputs.weight = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.gridlist = File.mock()
-    >>> task.inputs.plusminus = "True"
-    >>> task.inputs.nopadWARP = "True"
+    >>> task.inputs.plusminus = True
+    >>> task.inputs.nopadWARP = True
     >>> task.cmdline
     '3dQwarp -base sub-01_dir-RL_epi.nii.gz -source sub-01_dir-LR_epi.nii.gz -nopadWARP -prefix ppp_sub-01_dir-LR_epi -plusminus'
 
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
-    >>> task.inputs.resample = "True"
+    >>> task.inputs.out_file = NiftiGz.mock()
+    >>> task.inputs.resample = True
     >>> task.inputs.weight = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.gridlist = File.mock()
     >>> task.cmdline
     '3dQwarp -base mni.nii -source structural.nii -prefix ppp_structural -resample'
 
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
-    >>> task.inputs.out_file = ""anatSSQ.nii.gz""
-    >>> task.inputs.resample = "True"
-    >>> task.inputs.iwarp = "True"
+    >>> task.inputs.out_file = NiftiGz.mock(None)
+    >>> task.inputs.resample = True
+    >>> task.inputs.iwarp = True
     >>> task.inputs.weight = File.mock()
-    >>> task.inputs.blur = "[0,3]"
+    >>> task.inputs.out_weight_file = File.mock()
+    >>> task.inputs.blur = [0,3]
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.gridlist = File.mock()
-    >>> task.inputs.verb = "True"
-    >>> task.inputs.lpc = "True"
+    >>> task.inputs.verb = True
+    >>> task.inputs.lpc = True
     >>> task.cmdline
     '3dQwarp -base epi.nii -blur 0.0 3.0 -source structural.nii -iwarp -prefix anatSSQ.nii.gz -resample -verb -lpc'
 
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
+    >>> task.inputs.out_file = NiftiGz.mock()
     >>> task.inputs.weight = File.mock()
-    >>> task.inputs.blur = "[0,3]"
+    >>> task.inputs.out_weight_file = File.mock()
+    >>> task.inputs.blur = [0,3]
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.gridlist = File.mock()
-    >>> task.inputs.duplo = "True"
+    >>> task.inputs.duplo = True
     >>> task.cmdline
     '3dQwarp -base mni.nii -blur 0.0 3.0 -duplo -source structural.nii -prefix ppp_structural'
 
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
-    >>> task.inputs.out_file = ""Q25""
+    >>> task.inputs.out_file = NiftiGz.mock(None)
     >>> task.inputs.weight = File.mock()
-    >>> task.inputs.blur = "[0,3]"
+    >>> task.inputs.out_weight_file = File.mock()
+    >>> task.inputs.blur = [0,3]
     >>> task.inputs.emask = File.mock()
-    >>> task.inputs.minpatch = "25"
+    >>> task.inputs.minpatch = 25
     >>> task.inputs.gridlist = File.mock()
-    >>> task.inputs.duplo = "True"
+    >>> task.inputs.duplo = True
     >>> task.cmdline
     '3dQwarp -base mni.nii -blur 0.0 3.0 -duplo -source structural.nii -minpatch 25 -prefix Q25'
 
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
-    >>> task.inputs.out_file = ""Q11""
+    >>> task.inputs.out_file = NiftiGz.mock(None)
     >>> task.inputs.weight = File.mock()
-    >>> task.inputs.blur = "[0,2]"
+    >>> task.inputs.out_weight_file = File.mock()
+    >>> task.inputs.blur = [0,2]
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.iniwarp = None
-    >>> task.inputs.inilev = "7"
+    >>> task.inputs.inilev = 7
     >>> task.inputs.gridlist = File.mock()
     >>> task.cmdline
     '3dQwarp -base mni.nii -blur 0.0 2.0 -source structural.nii -inilev 7 -iniwarp Q25_warp+tlrc.HEAD -prefix Q11'
 
 
     >>> task = Qwarp()
     >>> task.inputs.in_file = None
     >>> task.inputs.base_file = None
-    >>> task.inputs.allineate = "True"
-    >>> task.inputs.allineate_opts = ""-cose lpa -verb""
+    >>> task.inputs.out_file = NiftiGz.mock()
+    >>> task.inputs.allineate = True
+    >>> task.inputs.allineate_opts = "-cose lpa -verb"
     >>> task.inputs.weight = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.gridlist = File.mock()
     >>> task.cmdline
     '3dQwarp -allineate -allineate_opts "-cose lpa -verb" -base mni.nii -source structural.nii -prefix ppp_structural'
 
 
     """
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/qwarp_plus_minus.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/qwarp_plus_minus.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,27 +1,495 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import NiftiGz
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import NiftiGz
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
+input_fields = [
+    (
+        "source_file",
+        File,
+        {
+            "help_string": "Source image (opposite phase encoding direction than base image)",
+            "argstr": "-source {source_file}",
+            "copyfile": False,
+        },
+    ),
+    (
+        "out_file",
+        File,
+        "Qwarp.nii.gz",
+        {"help_string": "Output file", "argstr": "-prefix {out_file}", "position": 0},
+    ),
+    (
+        "plusminus",
+        bool,
+        True,
+        {
+            "help_string": "Normally, the warp displacements dis(x) are defined to matchbase(x) to source(x+dis(x)).  With this option, the matchis between base(x-dis(x)) and source(x+dis(x)) -- the twoimages 'meet in the middle'. For more info, view Qwarp` interface",
+            "argstr": "-plusminus",
+            "position": 1,
+            "xor": ["duplo", "allsave", "iwarp"],
+        },
+    ),
+    (
+        "in_file",
+        NiftiGz,
+        {
+            "help_string": "Source image (opposite phase encoding direction than base image).",
+            "argstr": "-source {in_file}",
+            "copyfile": False,
+            "mandatory": True,
+        },
+    ),
+    (
+        "base_file",
+        NiftiGz,
+        {
+            "help_string": "Base image (opposite phase encoding direction than source image).",
+            "argstr": "-base {base_file}",
+            "copyfile": False,
+            "mandatory": True,
+        },
+    ),
+    (
+        "resample",
+        bool,
+        {
+            "help_string": "This option simply resamples the source dataset to match the\nbase dataset grid.  You can use this if the two datasets\noverlap well (as seen in the AFNI GUI), but are not on the\nsame 3D grid.\n\n* If they don't overlap well, allineate them first\n* The reampling here is done with the\n  'wsinc5' method, which has very little blurring artifact.\n* If the base and source datasets ARE on the same 3D grid,\n  then the -resample option will be ignored.\n* You CAN use -resample with these 3dQwarp options:\n  -plusminus  -inilev  -iniwarp  -duplo\n\n",
+            "argstr": "-resample",
+        },
+    ),
+    (
+        "allineate",
+        bool,
+        {
+            "help_string": "This option will make 3dQwarp run 3dAllineate first, to align the source dataset to the base with an affine transformation. It will then use that alignment as a starting point for the nonlinear warping.",
+            "argstr": "-allineate",
+        },
+    ),
+    (
+        "allineate_opts",
+        str,
+        {
+            "help_string": "add extra options to the 3dAllineate command to be run by 3dQwarp.",
+            "argstr": "-allineate_opts {allineate_opts}",
+            "requires": ["allineate"],
+        },
+    ),
+    (
+        "nowarp",
+        bool,
+        {"help_string": "Do not save the _WARP file.", "argstr": "-nowarp"},
+    ),
+    (
+        "iwarp",
+        bool,
+        {
+            "help_string": "Do compute and save the _WARPINV file.",
+            "argstr": "-iwarp",
+            "xor": ["plusminus"],
+        },
+    ),
+    (
+        "pear",
+        bool,
+        {
+            "help_string": "Use strict Pearson correlation for matching.Not usually recommended, since the 'clipped Pearson' methodused by default will reduce the impact of outlier values.",
+            "argstr": "-pear",
+        },
+    ),
+    (
+        "noneg",
+        bool,
+        {
+            "help_string": "Replace negative values in either input volume with 0.\n\n* If there ARE negative input values, and you do NOT use -noneg,\n  then strict Pearson correlation will be used, since the 'clipped'\n  method only is implemented for non-negative volumes.\n* '-noneg' is not the default, since there might be situations where\n  you want to align datasets with positive and negative values mixed.\n* But, in many cases, the negative values in a dataset are just the\n  result of interpolation artifacts (or other peculiarities), and so\n  they should be ignored.  That is what '-noneg' is for.\n\n",
+            "argstr": "-noneg",
+        },
+    ),
+    (
+        "nopenalty",
+        bool,
+        {
+            "help_string": "Replace negative values in either input volume with 0.\n\n* If there ARE negative input values, and you do NOT use -noneg,\n  then strict Pearson correlation will be used, since the 'clipped'\n  method only is implemented for non-negative volumes.\n* '-noneg' is not the default, since there might be situations where\n  you want to align datasets with positive and negative values mixed.\n* But, in many cases, the negative values in a dataset are just the\n  result of interpolation artifacts (or other peculiarities), and so\n  they should be ignored. That is what '-noneg' is for.\n\n",
+            "argstr": "-nopenalty",
+        },
+    ),
+    (
+        "penfac",
+        float,
+        {
+            "help_string": "Use this value to weight the penalty.\nThe default value is 1. Larger values mean the\npenalty counts more, reducing grid distortions,\ninsha'Allah; '-nopenalty' is the same as '-penfac 0'.\nIn 23 Sep 2013 Zhark increased the default value of\nthe penalty by a factor of 5, and also made it get\nprogressively larger with each level of refinement.\nThus, warping results will vary from earlier instances\nof 3dQwarp.\n\n* The progressive increase in the penalty at higher levels\n  means that the 'cost function' can actually look like the\n  alignment is getting worse when the levels change.\n* IF you wish to turn off this progression, for whatever\n  reason (e.g., to keep compatibility with older results),\n  use the option '-penold'.To be completely compatible with\n  the older 3dQwarp, you'll also have to use '-penfac 0.2'.\n\n",
+            "argstr": "-penfac {penfac}",
+        },
+    ),
+    (
+        "noweight",
+        bool,
+        {
+            "help_string": "If you want a binary weight (the old default), use this option.That is, each voxel in the base volume automask will beweighted the same in the computation of the cost functional.",
+            "argstr": "-noweight",
+        },
+    ),
+    (
+        "weight",
+        File,
+        {
+            "help_string": "Instead of computing the weight from the base dataset,directly input the weight volume from dataset 'www'.Useful if you know what over parts of the base image youwant to emphasize or de-emphasize the matching functional.",
+            "argstr": "-weight {weight}",
+        },
+    ),
+    (
+        "wball",
+        list,
+        {
+            "help_string": "\"``-wball x y z r f``\nEnhance automatic weight from '-useweight' by a factor\nof 1+f\\*Gaussian(FWHM=r) centered in the base image at\nDICOM coordinates (x,y,z) and with radius 'r'. The\ngoal of this option is to try and make the alignment\nbetter in a specific part of the brain.\nExample:  -wball 0 14 6 30 40\nto emphasize the thalamic area (in MNI/Talairach space).\n\n* The 'r' parameter must be positive!\n* The 'f' parameter must be between 1 and 100 (inclusive).\n* '-wball' does nothing if you input your own weight\n  with the '-weight' option.\n* '-wball' does change the binary weight created by\n  the '-noweight' option.\n* You can only use '-wball' once in a run of 3dQwarp.\n\n**The effect of '-wball' is not dramatic.** The example\nabove makes the average brain image across a collection\nof subjects a little sharper in the thalamic area, which\nmight have some small value.  If you care enough about\nalignment to use '-wball', then you should examine the\nresults from 3dQwarp for each subject, to see if the\nalignments are good enough for your purposes.",
+            "argstr": "-wball {wball}",
+            "xor": ["wmask"],
+        },
+    ),
+    (
+        "wmask",
+        ty.Any,
+        {
+            "help_string": "Similar to '-wball', but here, you provide a dataset 'ws'\nthat indicates where to increase the weight.\n\n* The 'ws' dataset must be on the same 3D grid as the base dataset.\n* 'ws' is treated as a mask -- it only matters where it\n  is nonzero -- otherwise, the values inside are not used.\n* After 'ws' comes the factor 'f' by which to increase the\n  automatically computed weight.  Where 'ws' is nonzero,\n  the weighting will be multiplied by (1+f).\n* As with '-wball', the factor 'f' should be between 1 and 100.\n\n",
+            "argstr": "-wpass {wmask[0]} {wmask[1]}",
+            "xor": ["wball"],
+        },
+    ),
+    (
+        "out_weight_file",
+        File,
+        {
+            "help_string": "Write the weight volume to disk as a dataset",
+            "argstr": "-wtprefix {out_weight_file}",
+        },
+    ),
+    (
+        "blur",
+        list,
+        {
+            "help_string": "Gaussian blur the input images by 'bb' (FWHM) voxels before\ndoing the alignment (the output dataset will not be blurred).\nThe default is 2.345 (for no good reason).\n\n* Optionally, you can provide 2 values for 'bb', and then\n  the first one is applied to the base volume, the second\n  to the source volume.\n  e.g., '-blur 0 3' to skip blurring the base image\n  (if the base is a blurry template, for example).\n* A negative blur radius means to use 3D median filtering,\n  rather than Gaussian blurring.  This type of filtering will\n  better preserve edges, which can be important in alignment.\n* If the base is a template volume that is already blurry,\n  you probably don't want to blur it again, but blurring\n  the source volume a little is probably a good idea, to\n  help the program avoid trying to match tiny features.\n* Note that -duplo will blur the volumes some extra\n  amount for the initial small-scale warping, to make\n  that phase of the program converge more rapidly.\n\n",
+            "argstr": "-blur {blur}",
+        },
+    ),
+    (
+        "pblur",
+        list,
+        {
+            "help_string": "Use progressive blurring; that is, for larger patch sizes,\nthe amount of blurring is larger.  The general idea is to\navoid trying to match finer details when the patch size\nand incremental warps are coarse.  When '-blur' is used\nas well, it sets a minimum amount of blurring that will\nbe used. [06 Aug 2014 -- '-pblur' may become the default someday].\n\n* You can optionally give the fraction of the patch size that\n  is used for the progressive blur by providing a value between\n  0 and 0.25 after '-pblur'.  If you provide TWO values, the\n  the first fraction is used for progressively blurring the\n  base image and the second for the source image.  The default\n  parameters when just '-pblur' is given is the same as giving\n  the options as '-pblur 0.09 0.09'.\n* '-pblur' is useful when trying to match 2 volumes with high\n  amounts of detail; e.g, warping one subject's brain image to\n  match another's, or trying to warp to match a detailed template.\n* Note that using negative values with '-blur' means that the\n  progressive blurring will be done with median filters, rather\n  than Gaussian linear blurring.\n\nNote: The combination of the -allineate and -pblur options will make\nthe results of using 3dQwarp to align to a template somewhat\nless sensitive to initial head position and scaling.",
+            "argstr": "-pblur {pblur}",
+        },
+    ),
+    (
+        "emask",
+        File,
+        {
+            "help_string": "Here, 'ee' is a dataset to specify a mask of voxelsto EXCLUDE from the analysis -- all voxels in 'ee'that are NONZERO will not be used in the alignment.The base image always automasked -- the emask isextra, to indicate voxels you definitely DON'T wantincluded in the matching process, even if they areinside the brain.",
+            "argstr": "-emask {emask}",
+            "copyfile": False,
+        },
+    ),
+    (
+        "noXdis",
+        bool,
+        {"help_string": "Warp will not displace in x direction", "argstr": "-noXdis"},
+    ),
+    (
+        "noYdis",
+        bool,
+        {"help_string": "Warp will not displace in y direction", "argstr": "-noYdis"},
+    ),
+    (
+        "noZdis",
+        bool,
+        {"help_string": "Warp will not displace in z direction", "argstr": "-noZdis"},
+    ),
+    (
+        "iniwarp",
+        ty.List[File],
+        {
+            "help_string": 'A dataset with an initial nonlinear warp to use.\n\n* If this option is not used, the initial warp is the identity.\n* You can specify a catenation of warps (in quotes) here, as in\n  program 3dNwarpApply.\n* As a special case, if you just input an affine matrix in a .1D\n  file, that will work also -- it is treated as giving the initial\n  warp via the string "IDENT(base_dataset) matrix_file.aff12.1D".\n* You CANNOT use this option with -duplo !!\n* -iniwarp is usually used with -inilev to re-start 3dQwarp from\n  a previous stopping point.\n\n',
+            "argstr": "-iniwarp {iniwarp}",
+            "xor": ["duplo"],
+        },
+    ),
+    (
+        "inilev",
+        int,
+        {
+            "help_string": "The initial refinement 'level' at which to start.\n\n* Usually used with -iniwarp; CANNOT be used with -duplo.\n* The combination of -inilev and -iniwarp lets you take the\n  results of a previous 3dQwarp run and refine them further:\n  Note that the source dataset in the second run is the SAME as\n  in the first run.  If you don't see why this is necessary,\n  then you probably need to seek help from an AFNI guru.\n\n",
+            "argstr": "-inilev {inilev}",
+            "xor": ["duplo"],
+        },
+    ),
+    (
+        "minpatch",
+        int,
+        {
+            "help_string": "The value of mm should be an odd integer.\n\n* The default value of mm is 25.\n* For more accurate results than mm=25, try 19 or 13.\n* The smallest allowed patch size is 5.\n* You may want stop at a larger patch size (say 7 or 9) and use\n  the -Qfinal option to run that final level with quintic warps,\n  which might run faster and provide the same degree of warp detail.\n* Trying to make two different brain volumes match in fine detail\n  is usually a waste of time, especially in humans.  There is too\n  much variability in anatomy to match gyrus to gyrus accurately.\n  For this reason, the default minimum patch size is 25 voxels.\n  Using a smaller '-minpatch' might try to force the warp to\n  match features that do not match, and the result can be useless\n  image distortions -- another reason to LOOK AT THE RESULTS.\n\n",
+            "argstr": "-minpatch {minpatch}",
+        },
+    ),
+    (
+        "maxlev",
+        int,
+        {
+            "help_string": "The initial refinement 'level' at which to start.\n\n* Usually used with -iniwarp; CANNOT be used with -duplo.\n* The combination of -inilev and -iniwarp lets you take the\n  results of a previous 3dQwarp run and refine them further:\n  Note that the source dataset in the second run is the SAME as\n  in the first run.  If you don't see why this is necessary,\n  then you probably need to seek help from an AFNI guru.\n\n",
+            "argstr": "-maxlev {maxlev}",
+            "position": -1,
+            "xor": ["duplo"],
+        },
+    ),
+    (
+        "gridlist",
+        File,
+        {
+            "help_string": "This option provides an alternate way to specify the patch\ngrid sizes used in the warp optimization process. 'gl' is\na 1D file with a list of patches to use -- in most cases,\nyou will want to use it in the following form:\n``-gridlist '1D: 0 151 101 75 51'``\n\n* Here, a 0 patch size means the global domain. Patch sizes\n  otherwise should be odd integers >= 5.\n* If you use the '0' patch size again after the first position,\n  you will actually get an iteration at the size of the\n  default patch level 1, where the patch sizes are 75% of\n  the volume dimension.  There is no way to force the program\n  to literally repeat the sui generis step of lev=0.\n\n",
+            "argstr": "-gridlist {gridlist}",
+            "copyfile": False,
+            "xor": ["duplo", "plusminus"],
+        },
+    ),
+    (
+        "allsave",
+        bool,
+        {
+            "help_string": '\nThis option lets you save the output warps from each level"\nof the refinement process.  Mostly used for experimenting."\nWill only save all the outputs if the program terminates"\nnormally -- if it crashes, or freezes, then all these"\nwarps are lost.',
+            "argstr": "-allsave",
+            "xor": ["nopadWARP", "duplo", "plusminus"],
+        },
+    ),
+    (
+        "duplo",
+        bool,
+        {
+            "help_string": 'Start off with 1/2 scale versions of the volumes,"\nfor getting a speedy coarse first alignment."\n\n* Then scales back up to register the full volumes."\n  The goal is greater speed, and it seems to help this"\n  positively piggish program to be more expeditious."\n* However, accuracy is somewhat lower with \'-duplo\',"\n  for reasons that currently elude Zhark; for this reason,"\n  the Emperor does not usually use \'-duplo\'.\n\n',
+            "argstr": "-duplo",
+            "xor": ["gridlist", "maxlev", "inilev", "iniwarp", "plusminus", "allsave"],
+        },
+    ),
+    (
+        "workhard",
+        bool,
+        {
+            "help_string": "Iterate more times, which can help when the volumes are\nhard to align at all, or when you hope to get a more precise\nalignment.\n\n* Slows the program down (possibly a lot), of course.\n* When you combine '-workhard'  with '-duplo', only the\n  full size volumes get the extra iterations.\n* For finer control over which refinement levels work hard,\n  you can use this option in the form (for example) ``-workhard:4:7``\n  which implies the extra iterations will be done at levels\n  4, 5, 6, and 7, but not otherwise.\n* You can also use '-superhard' to iterate even more, but\n  this extra option will REALLY slow things down.\n\n  * Under most circumstances, you should not need to use either\n    ``-workhard`` or ``-superhard``.\n  * The fastest way to register to a template image is via the\n    ``-duplo`` option, and without the ``-workhard`` or ``-superhard`` options.\n  * If you use this option in the form '-Workhard' (first letter\n    in upper case), then the second iteration at each level is\n    done with quintic polynomial warps.\n\n",
+            "argstr": "-workhard",
+            "xor": ["boxopt", "ballopt"],
+        },
+    ),
+    (
+        "Qfinal",
+        bool,
+        {
+            "help_string": "At the finest patch size (the final level), use Hermite\nquintic polynomials for the warp instead of cubic polynomials.\n\n* In a 3D 'patch', there are 2x2x2x3=24 cubic polynomial basis\n  function parameters over which to optimize (2 polynomials\n  dependent on each of the x,y,z directions, and 3 different\n  directions of displacement).\n* There are 3x3x3x3=81 quintic polynomial parameters per patch.\n* With -Qfinal, the final level will have more detail in\n  the allowed warps, at the cost of yet more CPU time.\n* However, no patch below 7x7x7 in size will be done with quintic\n  polynomials.\n* This option is also not usually needed, and is experimental.\n\n",
+            "argstr": "-Qfinal",
+        },
+    ),
+    (
+        "Qonly",
+        bool,
+        {
+            "help_string": "Use Hermite quintic polynomials at all levels.\n\n* Very slow (about 4 times longer).  Also experimental.\n* Will produce a (discrete representation of a) C2 warp.\n\n",
+            "argstr": "-Qonly",
+        },
+    ),
+    (
+        "nopad",
+        bool,
+        {
+            "help_string": "Do NOT use zero-padding on the 3D base and source images.\n[Default == zero-pad, if needed]\n\n* The underlying model for deformations goes to zero at the\n  edge of the volume being warped.  However, if there is\n  significant data near an edge of the volume, then it won't\n  get displaced much, and so the results might not be good.\n* Zero padding is designed as a way to work around this potential\n  problem.  You should NOT need the '-nopad' option for any\n  reason that Zhark can think of, but it is here to be symmetrical\n  with 3dAllineate.\n* Note that the output (warped from source) dataset will be on the\n  base dataset grid whether or not zero-padding is allowed.  However,\n  unless you use the following option, allowing zero-padding (i.e.,\n  the default operation) will make the output WARP dataset(s) be\n  on a larger grid (also see '-expad' below).\n\n",
+            "argstr": "-nopad",
+        },
+    ),
+    (
+        "nopadWARP",
+        bool,
+        {
+            "help_string": "If for some reason you require the warp volume tomatch the base volume, then use this option to have the outputWARP dataset(s) truncated.",
+            "argstr": "-nopadWARP",
+            "xor": ["allsave", "expad"],
+        },
+    ),
+    (
+        "expad",
+        int,
+        {
+            "help_string": "This option instructs the program to pad the warp by an extra'EE' voxels (and then 3dQwarp starts optimizing it).This option is seldom needed, but can be useful if youmight later catenate the nonlinear warp -- via 3dNwarpCat --with an affine transformation that contains a large shift.Under that circumstance, the nonlinear warp might be shiftedpartially outside its original grid, so expanding that gridcan avoid this problem.Note that this option perforce turns off '-nopadWARP'.",
+            "argstr": "-expad {expad}",
+            "xor": ["nopadWARP"],
+        },
+    ),
+    (
+        "ballopt",
+        bool,
+        {
+            "help_string": "Normally, the incremental warp parameters are optimized insidea rectangular 'box' (24 dimensional for cubic patches, 81 forquintic patches), whose limits define the amount of distortionallowed at each step.  Using '-ballopt' switches these limitsto be applied to a 'ball' (interior of a hypersphere), whichcan allow for larger incremental displacements.  Use thisoption if you think things need to be able to move farther.",
+            "argstr": "-ballopt",
+            "xor": ["workhard", "boxopt"],
+        },
+    ),
+    (
+        "baxopt",
+        bool,
+        {
+            "help_string": "Use the 'box' optimization limits instead of the 'ball'[this is the default at present].Note that if '-workhard' is used, then ball and box optimizationare alternated in the different iterations at each level, sothese two options have no effect in that case.",
+            "argstr": "-boxopt",
+            "xor": ["workhard", "ballopt"],
+        },
+    ),
+    (
+        "verb",
+        bool,
+        {
+            "help_string": "more detailed description of the process",
+            "argstr": "-verb",
+            "xor": ["quiet"],
+        },
+    ),
+    (
+        "quiet",
+        bool,
+        {
+            "help_string": "Cut out most of the fun fun fun progress messages :-(",
+            "argstr": "-quiet",
+            "xor": ["verb"],
+        },
+    ),
+    ("overwrite", bool, {"help_string": "Overwrite outputs", "argstr": "-overwrite"}),
+    (
+        "lpc",
+        bool,
+        {
+            "help_string": "Local Pearson minimization (i.e., EPI-T1 registration)This option has not be extensively testedIf you use '-lpc', then '-maxlev 0' is automatically set.If you want to go to more refined levels, you can set '-maxlev'This should be set up to have lpc as the second to last argumentand maxlev as the second to last argument, as needed by AFNIUsing maxlev > 1 is not recommended for EPI-T1 alignment.",
+            "argstr": "-lpc",
+            "position": -2,
+            "xor": ["nmi", "mi", "hel", "lpa", "pear"],
+        },
+    ),
+    (
+        "lpa",
+        bool,
+        {
+            "help_string": "Local Pearson maximization. This option has not be extensively tested",
+            "argstr": "-lpa",
+            "xor": ["nmi", "mi", "lpc", "hel", "pear"],
+        },
+    ),
+    (
+        "hel",
+        bool,
+        {
+            "help_string": "Hellinger distance: a matching function for the adventurousThis option has NOT be extensively tested for usefulnessand should be considered experimental at this infundibulum.",
+            "argstr": "-hel",
+            "xor": ["nmi", "mi", "lpc", "lpa", "pear"],
+        },
+    ),
+    (
+        "mi",
+        bool,
+        {
+            "help_string": "Mutual Information: a matching function for the adventurousThis option has NOT be extensively tested for usefulnessand should be considered experimental at this infundibulum.",
+            "argstr": "-mi",
+            "xor": ["mi", "hel", "lpc", "lpa", "pear"],
+        },
+    ),
+    (
+        "nmi",
+        bool,
+        {
+            "help_string": "Normalized Mutual Information: a matching function for the adventurousThis option has NOT been extensively tested for usefulnessand should be considered experimental at this infundibulum.",
+            "argstr": "-nmi",
+            "xor": ["nmi", "hel", "lpc", "lpa", "pear"],
+        },
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+qwarp_plus_minus_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [
+    (
+        "warped_source",
+        File,
+        {
+            "help_string": "Warped source file. If plusminus is used, this is the undistortedsource file."
+        },
+    ),
+    ("warped_base", File, {"help_string": "Undistorted base file."}),
+    (
+        "source_warp",
+        File,
+        {
+            "help_string": "Displacement in mm for the source image.If plusminus is used this is the field suceptibility correctionwarp (in 'mm') for source image."
+        },
+    ),
+    (
+        "base_warp",
+        File,
+        {
+            "help_string": "Displacement in mm for the base image.If plus minus is used, this is the field suceptibility correctionwarp (in 'mm') for base image. This is only output if plusminusor iwarp options are passed"
+        },
+    ),
+    ("weights", File, {"help_string": "Auto-computed weight volume."}),
+]
+qwarp_plus_minus_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class qwarp_plus_minus(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import NiftiGz
+    >>> from pydra.tasks.afni.auto.preprocess.qwarp_plus_minus import qwarp_plus_minus
+
+    >>> task = qwarp_plus_minus()
+    >>> task.inputs.source_file = File.mock()
+    >>> task.inputs.out_file = File.mock()
+    >>> task.inputs.in_file = NiftiGz.mock(None)
+    >>> task.inputs.base_file = NiftiGz.mock(None)
+    >>> task.inputs.weight = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
+    >>> task.inputs.emask = File.mock()
+    >>> task.inputs.gridlist = File.mock()
+    >>> task.inputs.nopadWARP = True
+    >>> task.cmdline
+    '3dQwarp -prefix Qwarp.nii.gz -plusminus -base sub-01_dir-RL_epi.nii.gz -source sub-01_dir-LR_epi.nii.gz -nopadWARP'
+
+
+    """
+
+    input_spec = qwarp_plus_minus_input_spec
+    output_spec = qwarp_plus_minus_output_spec
+    executable = "3dQwarp"
+
+
 input_fields = [
     (
         "source_file",
         File,
         {
             "help_string": "Source image (opposite phase encoding direction than base image)",
             "argstr": "-source {source_file}",
             "copyfile": False,
         },
     ),
     (
         "out_file",
-        Path,
+        File,
         "Qwarp.nii.gz",
         {"help_string": "Output file", "argstr": "-prefix {out_file}", "position": 0},
     ),
     (
         "plusminus",
         bool,
         True,
@@ -155,15 +623,15 @@
             "help_string": "Similar to '-wball', but here, you provide a dataset 'ws'\nthat indicates where to increase the weight.\n\n* The 'ws' dataset must be on the same 3D grid as the base dataset.\n* 'ws' is treated as a mask -- it only matters where it\n  is nonzero -- otherwise, the values inside are not used.\n* After 'ws' comes the factor 'f' by which to increase the\n  automatically computed weight.  Where 'ws' is nonzero,\n  the weighting will be multiplied by (1+f).\n* As with '-wball', the factor 'f' should be between 1 and 100.\n\n",
             "argstr": "-wpass {wmask[0]} {wmask[1]}",
             "xor": ["wball"],
         },
     ),
     (
         "out_weight_file",
-        Path,
+        File,
         {
             "help_string": "Write the weight volume to disk as a dataset",
             "argstr": "-wtprefix {out_weight_file}",
         },
     ),
     (
         "blur",
@@ -442,25 +910,27 @@
 
 class QwarpPlusMinus(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import NiftiGz
-    >>> from pydra.tasks.afni.auto.qwarp_plus_minus import QwarpPlusMinus
+    >>> from fileformats.medimage import NiftiGz
+    >>> from pydra.tasks.afni.auto.preprocess.qwarp_plus_minus import QwarpPlusMinus
 
     >>> task = QwarpPlusMinus()
     >>> task.inputs.source_file = File.mock()
-    >>> task.inputs.in_file = NiftiGz.mock()
-    >>> task.inputs.base_file = NiftiGz.mock()
+    >>> task.inputs.out_file = File.mock()
+    >>> task.inputs.in_file = NiftiGz.mock(None)
+    >>> task.inputs.base_file = NiftiGz.mock(None)
     >>> task.inputs.weight = File.mock()
+    >>> task.inputs.out_weight_file = File.mock()
     >>> task.inputs.emask = File.mock()
     >>> task.inputs.gridlist = File.mock()
-    >>> task.inputs.nopadWARP = "True"
+    >>> task.inputs.nopadWARP = True
     >>> task.cmdline
     '3dQwarp -prefix Qwarp.nii.gz -plusminus -base sub-01_dir-RL_epi.nii.gz -source sub-01_dir-LR_epi.nii.gz -nopadWARP'
 
 
     """
 
     input_spec = QwarpPlusMinus_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/re_ho.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/cat_matvec.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,128 +1,175 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
-        Nifti1,
+        list,
         {
-            "help_string": "input dataset",
-            "argstr": "-inset {in_file}",
+            "help_string": "list of tuples of mfiles and associated opkeys",
+            "argstr": "{in_file}",
             "mandatory": True,
-            "position": 1,
+            "position": -2,
         },
     ),
     (
         "out_file",
-        Path,
+        OneD,
         {
-            "help_string": "Output dataset.",
-            "argstr": "-prefix {out_file}",
-            "position": 0,
-            "output_file_template": "{in_file}_reho",
+            "help_string": "File to write concattenated matvecs to",
+            "argstr": " > {out_file}",
+            "mandatory": True,
+            "position": -1,
+            "output_file_template": "{in_file}_cat.aff12.1D",
         },
     ),
     (
-        "chi_sq",
+        "matrix",
         bool,
         {
-            "help_string": "Output the Friedman chi-squared value in addition to the Kendall's W. This option is currently compatible only with the AFNI (BRIK/HEAD) output type; the chi-squared value will be the second sub-brick of the output dataset.",
-            "argstr": "-chi_sq",
+            "help_string": "indicates that the resulting matrix willbe written to outfile in the 'MATRIX(...)' format (FORM 3).This feature could be used, with clever scripting, to inputa matrix directly on the command line to program 3dWarp.",
+            "argstr": "-MATRIX",
+            "xor": ["oneline", "fourxfour"],
         },
     ),
     (
-        "mask_file",
-        File,
+        "oneline",
+        bool,
+        {
+            "help_string": "indicates that the resulting matrixwill simply be written as 12 numbers on one line.",
+            "argstr": "-ONELINE",
+            "xor": ["matrix", "fourxfour"],
+        },
+    ),
+    (
+        "fourxfour",
+        bool,
         {
-            "help_string": "Mask within which ReHo should be calculated voxelwise",
-            "argstr": "-mask {mask_file}",
+            "help_string": "Output matrix in augmented form (last row is 0 0 0 1)This option does not work with -MATRIX or -ONELINE",
+            "argstr": "-4x4",
+            "xor": ["matrix", "oneline"],
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+CatMatvec_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+CatMatvec_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class CatMatvec(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage_afni import OneD
+    >>> from pydra.tasks.afni.auto.utils.cat_matvec import CatMatvec
+
+    >>> task = CatMatvec()
+    >>> task.inputs.in_file = [("structural.BRIK::WARP_DATA","I")]
+    >>> task.inputs.out_file = OneD.mock(None)
+    >>> task.cmdline
+    'cat_matvec structural.BRIK::WARP_DATA -I > warp.anat.Xat.1D'
+
+
+    """
+
+    input_spec = CatMatvec_input_spec
+    output_spec = CatMatvec_output_spec
+    executable = "cat_matvec"
+
+
+input_fields = [
     (
-        "neighborhood",
-        ty.Any,
+        "in_file",
+        list,
         {
-            "help_string": "\nvoxels in neighborhood. can be:\n``faces`` (for voxel and 6 facewise neighbors, only),\n``edges`` (for voxel and 18 face- and edge-wise neighbors),\n``vertices`` (for voxel and 26 face-, edge-, and node-wise neighbors).",
-            "argstr": "-nneigh {neighborhood}",
-            "xor": ["sphere", "ellipsoid"],
+            "help_string": "list of tuples of mfiles and associated opkeys",
+            "argstr": "{in_file}",
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "sphere",
-        float,
+        "out_file",
+        Path,
         {
-            "help_string": "\\\nFor additional voxelwise neighborhood control, the\nradius R of a desired neighborhood can be put in; R is\na floating point number, and must be >1. Examples of\nthe numbers of voxels in a given radius are as follows\n(you can roughly approximate with the ol' :math:`4\\pi\\,R^3/3`\nthing):\n\n    * R=2.0 -> V=33\n    * R=2.3 -> V=57,\n    * R=2.9 -> V=93,\n    * R=3.1 -> V=123,\n    * R=3.9 -> V=251,\n    * R=4.5 -> V=389,\n    * R=6.1 -> V=949,\n\nbut you can choose most any value.",
-            "argstr": "-neigh_RAD {sphere}",
-            "xor": ["neighborhood", "ellipsoid"],
+            "help_string": "File to write concattenated matvecs to",
+            "argstr": " > {out_file}",
+            "mandatory": True,
+            "position": -1,
+            "output_file_template": "{in_file}_cat.aff12.1D",
         },
     ),
     (
-        "ellipsoid",
-        ty.Any,
+        "matrix",
+        bool,
         {
-            "help_string": "\\\nTuple indicating the x, y, and z radius of an ellipsoid\ndefining the neighbourhood of each voxel.\nThe 'hood is then made according to the following relation:\n:math:`(i/A)^2 + (j/B)^2 + (k/C)^2 \\le 1.`\nwhich will have approx. :math:`V=4 \\pi \\, A B C/3`. The impetus for\nthis freedom was for use with data having anisotropic\nvoxel edge lengths.",
-            "argstr": "-neigh_X {ellipsoid[0]} -neigh_Y {ellipsoid[1]} -neigh_Z {ellipsoid[2]}",
-            "xor": ["sphere", "neighborhood"],
+            "help_string": "indicates that the resulting matrix willbe written to outfile in the 'MATRIX(...)' format (FORM 3).This feature could be used, with clever scripting, to inputa matrix directly on the command line to program 3dWarp.",
+            "argstr": "-MATRIX",
+            "xor": ["oneline", "fourxfour"],
         },
     ),
     (
-        "label_set",
-        File,
+        "oneline",
+        bool,
         {
-            "help_string": "a set of ROIs, each labelled with distinct integers. ReHo will then be calculated per ROI.",
-            "argstr": "-in_rois {label_set}",
+            "help_string": "indicates that the resulting matrixwill simply be written as 12 numbers on one line.",
+            "argstr": "-ONELINE",
+            "xor": ["matrix", "fourxfour"],
         },
     ),
     (
-        "overwrite",
+        "fourxfour",
         bool,
         {
-            "help_string": "overwrite output file if it already exists",
-            "argstr": "-overwrite",
+            "help_string": "Output matrix in augmented form (last row is 0 0 0 1)This option does not work with -MATRIX or -ONELINE",
+            "argstr": "-4x4",
+            "xor": ["matrix", "oneline"],
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-ReHo_input_spec = specs.SpecInfo(
+cat_matvec_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    (
-        "out_vals",
-        File,
-        {"help_string": "Table of labelwise regional homogeneity values"},
-    )
-]
-ReHo_output_spec = specs.SpecInfo(
+output_fields = []
+cat_matvec_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class ReHo(ShellCommandTask):
+class cat_matvec(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.re_ho import ReHo
-
-    >>> task = ReHo()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""reho.nii.gz""
-    >>> task.inputs.mask_file = File.mock()
-    >>> task.inputs.neighborhood = ""vertices""
-    >>> task.inputs.label_set = File.mock()
+    >>> from pydra.tasks.afni.auto.utils.cat_matvec import cat_matvec
+
+    >>> task = cat_matvec()
+    >>> task.inputs.in_file = [("structural.BRIK::WARP_DATA","I")]
+    >>> task.inputs.out_file = None
     >>> task.cmdline
-    '3dReHo -prefix reho.nii.gz -inset functional.nii -nneigh 27'
+    'cat_matvec structural.BRIK::WARP_DATA -I > warp.anat.Xat.1D'
 
 
     """
 
-    input_spec = ReHo_input_spec
-    output_spec = ReHo_output_spec
-    executable = "3dReHo"
+    input_spec = cat_matvec_input_spec
+    output_spec = cat_matvec_output_spec
+    executable = "cat_matvec"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/refit.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/center_mass.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,175 +1,223 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+from fileformats.text import TextFile
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input file to 3drefit",
+            "help_string": "input file to 3dCM",
             "argstr": "{in_file}",
             "copyfile": True,
             "mandatory": True,
-            "position": -1,
+            "position": -2,
         },
     ),
     (
-        "deoblique",
-        bool,
+        "cm_file",
+        TextFile,
         {
-            "help_string": "replace current transformation matrix with cardinal matrix",
-            "argstr": "-deoblique",
+            "help_string": "File to write center of mass to",
+            "argstr": "> {cm_file}",
+            "position": -1,
+            "output_file_template": "{in_file}_cm.out",
         },
     ),
     (
-        "xorigin",
-        str,
+        "mask_file",
+        File,
         {
-            "help_string": "x distance for edge voxel offset",
-            "argstr": "-xorigin {xorigin}",
+            "help_string": "Only voxels with nonzero values in the provided mask will be averaged.",
+            "argstr": "-mask {mask_file}",
         },
     ),
     (
-        "yorigin",
-        str,
-        {
-            "help_string": "y distance for edge voxel offset",
-            "argstr": "-yorigin {yorigin}",
-        },
+        "automask",
+        bool,
+        {"help_string": "Generate the mask automatically", "argstr": "-automask"},
     ),
     (
-        "zorigin",
-        str,
+        "set_cm",
+        ty.Any,
         {
-            "help_string": "z distance for edge voxel offset",
-            "argstr": "-zorigin {zorigin}",
+            "help_string": "After computing the center of mass, set the origin fields in the header so that the center of mass will be at (x,y,z) in DICOM coords.",
+            "argstr": "-set {set_cm[0]} {set_cm[1]} {set_cm[2]}",
         },
     ),
     (
-        "duporigin_file",
-        File,
+        "local_ijk",
+        bool,
         {
-            "help_string": "Copies the xorigin, yorigin, and zorigin values from the header of the given dataset",
-            "argstr": "-duporigin {duporigin_file}",
+            "help_string": "Output values as (i,j,k) in local orientation",
+            "argstr": "-local_ijk",
         },
     ),
     (
-        "xdel",
-        float,
-        {"help_string": "new x voxel dimension in mm", "argstr": "-xdel {xdel}"},
-    ),
-    (
-        "ydel",
-        float,
-        {"help_string": "new y voxel dimension in mm", "argstr": "-ydel {ydel}"},
-    ),
-    (
-        "zdel",
-        float,
-        {"help_string": "new z voxel dimension in mm", "argstr": "-zdel {zdel}"},
+        "roi_vals",
+        list,
+        {
+            "help_string": "Compute center of mass for each blob with voxel value of v0, v1, v2, etc. This option is handy for getting ROI centers of mass.",
+            "argstr": "-roi_vals {roi_vals}",
+        },
     ),
     (
-        "xyzscale",
-        float,
+        "all_rois",
+        bool,
         {
-            "help_string": "Scale the size of the dataset voxels by the given factor",
-            "argstr": "-xyzscale {xyzscale}",
+            "help_string": "Don't bother listing the values of ROIs you want: The program will find all of them and produce a full list",
+            "argstr": "-all_rois",
         },
     ),
+]
+center_mass_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [
+    ("out_file", File, {"help_string": "output file"}),
+    ("cm", list, {"help_string": "center of mass"}),
+]
+center_mass_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class center_mass(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.text import TextFile
+    >>> from pydra.tasks.afni.auto.utils.center_mass import center_mass
+
+    >>> task = center_mass()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.cm_file = TextFile.mock(None)
+    >>> task.inputs.mask_file = File.mock()
+    >>> task.inputs.roi_vals = [2, 10]
+    >>> task.cmdline
+    '3dCM -roi_vals 2 10 structural.nii > cm.txt'
+
+
+    """
+
+    input_spec = center_mass_input_spec
+    output_spec = center_mass_output_spec
+    executable = "3dCM"
+
+
+input_fields = [
     (
-        "space",
-        ty.Any,
+        "in_file",
+        Nifti1,
         {
-            "help_string": "Associates the dataset with a specific template type, e.g. TLRC, MNI, ORIG",
-            "argstr": "-space {space}",
+            "help_string": "input file to 3dCM",
+            "argstr": "{in_file}",
+            "copyfile": True,
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "atrcopy",
-        ty.Any,
+        "cm_file",
+        TextFile,
         {
-            "help_string": "Copy AFNI header attribute from the given file into the header of the dataset(s) being modified. For more information on AFNI header attributes, see documentation file README.attributes. More than one '-atrcopy' option can be used. For AFNI advanced users only. Do NOT use -atrcopy or -atrstring with other modification options. See also -copyaux.",
-            "argstr": "-atrcopy {atrcopy[0]} {atrcopy[1]}",
+            "help_string": "File to write center of mass to",
+            "argstr": "> {cm_file}",
+            "position": -1,
+            "output_file_template": "{in_file}_cm.out",
         },
     ),
     (
-        "atrstring",
-        ty.Any,
+        "mask_file",
+        File,
         {
-            "help_string": "Copy the last given string into the dataset(s) being modified, giving it the attribute name given by the last string.To be safe, the last string should be in quotes.",
-            "argstr": "-atrstring {atrstring[0]} {atrstring[1]}",
+            "help_string": "Only voxels with nonzero values in the provided mask will be averaged.",
+            "argstr": "-mask {mask_file}",
         },
     ),
     (
-        "atrfloat",
+        "automask",
+        bool,
+        {"help_string": "Generate the mask automatically", "argstr": "-automask"},
+    ),
+    (
+        "set_cm",
         ty.Any,
         {
-            "help_string": "Create or modify floating point attributes. The input values may be specified as a single string in quotes or as a 1D filename or string, example '1 0.2 0 0 -0.2 1 0 0 0 0 1 0' or flipZ.1D or '1D:1,0.2,2@0,-0.2,1,2@0,2@0,1,0'",
-            "argstr": "-atrfloat {atrfloat[0]} {atrfloat[1]}",
+            "help_string": "After computing the center of mass, set the origin fields in the header so that the center of mass will be at (x,y,z) in DICOM coords.",
+            "argstr": "-set {set_cm[0]} {set_cm[1]} {set_cm[2]}",
         },
     ),
     (
-        "atrint",
-        ty.Any,
+        "local_ijk",
+        bool,
         {
-            "help_string": "Create or modify integer attributes. The input values may be specified as a single string in quotes or as a 1D filename or string, example '1 0 0 0 0 1 0 0 0 0 1 0' or flipZ.1D or '1D:1,0,2@0,-0,1,2@0,2@0,1,0'",
-            "argstr": "-atrint {atrint[0]} {atrint[1]}",
+            "help_string": "Output values as (i,j,k) in local orientation",
+            "argstr": "-local_ijk",
         },
     ),
     (
-        "saveatr",
-        bool,
+        "roi_vals",
+        list,
         {
-            "help_string": "(default) Copy the attributes that are known to AFNI into the dset->dblk structure thereby forcing changes to known attributes to be present in the output. This option only makes sense with -atrcopy.",
-            "argstr": "-saveatr",
+            "help_string": "Compute center of mass for each blob with voxel value of v0, v1, v2, etc. This option is handy for getting ROI centers of mass.",
+            "argstr": "-roi_vals {roi_vals}",
         },
     ),
     (
-        "nosaveatr",
+        "all_rois",
         bool,
-        {"help_string": "Opposite of -saveatr", "argstr": "-nosaveatr"},
+        {
+            "help_string": "Don't bother listing the values of ROIs you want: The program will find all of them and produce a full list",
+            "argstr": "-all_rois",
+        },
     ),
 ]
-Refit_input_spec = specs.SpecInfo(
+CenterMass_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", File, {"help_string": "output file"})]
-Refit_output_spec = specs.SpecInfo(
+output_fields = [
+    ("out_file", File, {"help_string": "output file"}),
+    ("cm", list, {"help_string": "center of mass"}),
+]
+CenterMass_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Refit(ShellCommandTask):
+class CenterMass(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.refit import Refit
-
-    >>> task = Refit()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.deoblique = "True"
-    >>> task.inputs.duporigin_file = File.mock()
-    >>> task.cmdline
-    '3drefit -deoblique structural.nii'
-
-
-    >>> task = Refit()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.duporigin_file = File.mock()
-    >>> task.inputs.atrfloat = "("IJK_TO_DICOM_REAL", "'1 0.2 0 0 -0.2 1 0 0 0 0 1 0'")"
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.text import TextFile
+    >>> from pydra.tasks.afni.auto.utils.center_mass import CenterMass
+
+    >>> task = CenterMass()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.cm_file = TextFile.mock(None)
+    >>> task.inputs.mask_file = File.mock()
+    >>> task.inputs.roi_vals = [2, 10]
     >>> task.cmdline
-    '3drefit -atrfloat IJK_TO_DICOM_REAL "1 0.2 0 0 -0.2 1 0 0 0 0 1 0" structural.nii'
+    '3dCM -roi_vals 2 10 structural.nii > cm.txt'
 
 
     """
 
-    input_spec = Refit_input_spec
-    output_spec = Refit_output_spec
-    executable = "3drefit"
+    input_spec = CenterMass_input_spec
+    output_spec = CenterMass_output_spec
+    executable = "3dCM"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/remlfit.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/model/remlfit.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
 from fileformats.medimage_afni import OneD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_files",
         ty.List[Nifti1],
         {
             "help_string": "Read time series dataset",
             "argstr": '-input "{in_files}"',
@@ -174,63 +177,63 @@
         {
             "help_string": "read a symbolic GLT from input file and associate it with a label. As in Deconvolve, you can also use the 'SYM:' method to provide the definition of the GLT directly as a string (e.g., with 'SYM: +Label1 -Label2'). Unlike Deconvolve, you MUST specify 'SYM: ' if providing the GLT directly as a string instead of from a file",
             "argstr": '-gltsym "{gltsym[0]}" {gltsym[1]}...',
         },
     ),
     (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.",
             "argstr": "-Rbuck {out_file}",
         },
     ),
     (
         "var_file",
-        Path,
+        File,
         {
             "help_string": "output dataset for REML variance parameters",
             "argstr": "-Rvar {var_file}",
         },
     ),
     (
         "rbeta_file",
-        Path,
+        File,
         {
             "help_string": "output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.",
             "argstr": "-Rbeta {rbeta_file}",
         },
     ),
     (
         "glt_file",
-        Path,
+        File,
         {
             "help_string": "output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym'; GLTs from Deconvolve's command line will NOT be included.",
             "argstr": "-Rglt {glt_file}",
         },
     ),
     (
         "fitts_file",
-        Path,
+        File,
         {
             "help_string": "output dataset for REML fitted model",
             "argstr": "-Rfitts {fitts_file}",
         },
     ),
     (
         "errts_file",
-        Path,
+        File,
         {
             "help_string": "output dataset for REML residuals = data - fitted model",
             "argstr": "-Rerrts {errts_file}",
         },
     ),
     (
         "wherr_file",
-        Path,
+        File,
         {
             "help_string": "dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise",
             "argstr": "-Rwherr {wherr_file}",
         },
     ),
     (
         "quiet",
@@ -251,52 +254,52 @@
         {
             "help_string": "With potential issues flagged in the design matrix, an attempt will nevertheless be made to fit the model",
             "argstr": "-GOFORIT",
         },
     ),
     (
         "ovar",
-        Path,
+        File,
         {
             "help_string": "dataset for OLSQ st.dev. parameter (kind of boring)",
             "argstr": "-Ovar {ovar}",
         },
     ),
     (
         "obeta",
-        Path,
+        File,
         {
             "help_string": "dataset for beta weights from the OLSQ estimation",
             "argstr": "-Obeta {obeta}",
         },
     ),
     (
         "obuck",
-        Path,
+        File,
         {
             "help_string": "dataset for beta + statistics from the OLSQ estimation",
             "argstr": "-Obuck {obuck}",
         },
     ),
     (
         "oglt",
-        Path,
+        File,
         {
             "help_string": "dataset for beta + statistics from 'gltsym' options",
             "argstr": "-Oglt {oglt}",
         },
     ),
     (
         "ofitts",
-        Path,
+        File,
         {"help_string": "dataset for OLSQ fitted model", "argstr": "-Ofitts {ofitts}"},
     ),
     (
         "oerrts",
-        Path,
+        File,
         {
             "help_string": "dataset for OLSQ residuals (data - fitted model)",
             "argstr": "-Oerrts {oerrts}",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
@@ -393,27 +396,39 @@
 
 class Remlfit(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
+    >>> from fileformats.medimage import Nifti1
     >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.remlfit import Remlfit
+    >>> from pydra.tasks.afni.auto.model.remlfit import Remlfit
 
     >>> task = Remlfit()
     >>> task.inputs.in_files = None
-    >>> task.inputs.matrix = OneD.mock()
+    >>> task.inputs.matrix = OneD.mock(None)
     >>> task.inputs.matim = File.mock()
     >>> task.inputs.mask = File.mock()
     >>> task.inputs.STATmask = File.mock()
     >>> task.inputs.dsort = File.mock()
-    >>> task.inputs.gltsym = "[("SYM: +Lab1 -Lab2", "TestSYM"), ("timeseries.txt", "TestFile")]"
-    >>> task.inputs.out_file = ""output.nii""
+    >>> task.inputs.gltsym = [("SYM: +Lab1 -Lab2", "TestSYM"), ("timeseries.txt", "TestFile")]
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.var_file = File.mock()
+    >>> task.inputs.rbeta_file = File.mock()
+    >>> task.inputs.glt_file = File.mock()
+    >>> task.inputs.fitts_file = File.mock()
+    >>> task.inputs.errts_file = File.mock()
+    >>> task.inputs.wherr_file = File.mock()
+    >>> task.inputs.ovar = File.mock()
+    >>> task.inputs.obeta = File.mock()
+    >>> task.inputs.obuck = File.mock()
+    >>> task.inputs.oglt = File.mock()
+    >>> task.inputs.ofitts = File.mock()
+    >>> task.inputs.oerrts = File.mock()
     >>> task.cmdline
     '3dREMLfit -gltsym "SYM: +Lab1 -Lab2" TestSYM -gltsym "timeseries.txt" TestFile -input "functional.nii functional2.nii" -matrix output.1D -Rbuck output.nii'
 
 
     """
 
     input_spec = Remlfit_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/resample.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_corr_1d.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,93 +1,116 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "xset",
         Nifti1,
         {
-            "help_string": "input file to 3dresample",
-            "argstr": "-inset {in_file}",
+            "help_string": "3d+time dataset input",
+            "argstr": " {xset}",
             "copyfile": False,
             "mandatory": True,
+            "position": -2,
+        },
+    ),
+    (
+        "y_1d",
+        OneD,
+        {
+            "help_string": "1D time series file input",
+            "argstr": " {y_1d}",
+            "mandatory": True,
             "position": -1,
         },
     ),
     (
         "out_file",
         Path,
         {
-            "help_string": "output image file name",
+            "help_string": "output filename prefix",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_resample",
+            "output_file_template": "{xset}_correlation.nii.gz",
         },
     ),
     (
-        "orientation",
-        str,
-        {"help_string": "new orientation code", "argstr": "-orient {orientation}"},
+        "pearson",
+        bool,
+        {
+            "help_string": "Correlation is the normal Pearson correlation coefficient",
+            "argstr": " -pearson",
+            "position": 1,
+            "xor": ["spearman", "quadrant", "ktaub"],
+        },
     ),
     (
-        "resample_mode",
-        ty.Any,
+        "spearman",
+        bool,
         {
-            "help_string": 'resampling method from set {"NN", "Li", "Cu", "Bk"}. These are for "Nearest Neighbor", "Linear", "Cubic" and "Blocky"interpolation, respectively. Default is NN.',
-            "argstr": "-rmode {resample_mode}",
+            "help_string": "Correlation is the Spearman (rank) correlation coefficient",
+            "argstr": " -spearman",
+            "position": 1,
+            "xor": ["pearson", "quadrant", "ktaub"],
         },
     ),
     (
-        "voxel_size",
-        ty.Any,
+        "quadrant",
+        bool,
         {
-            "help_string": "resample to new dx, dy and dz",
-            "argstr": "-dxyz {voxel_size[0]} {voxel_size[1]} {voxel_size[2]}",
+            "help_string": "Correlation is the quadrant correlation coefficient",
+            "argstr": " -quadrant",
+            "position": 1,
+            "xor": ["pearson", "spearman", "ktaub"],
         },
     ),
     (
-        "master",
-        File,
+        "ktaub",
+        bool,
         {
-            "help_string": "align dataset grid to a reference file",
-            "argstr": "-master {master}",
+            "help_string": "Correlation is the Kendall's tau_b correlation coefficient",
+            "argstr": " -ktaub",
+            "position": 1,
+            "xor": ["pearson", "spearman", "quadrant"],
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Resample_input_spec = specs.SpecInfo(
+TCorr1D_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-Resample_output_spec = specs.SpecInfo(
+TCorr1D_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Resample(ShellCommandTask):
+class TCorr1D(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.resample import Resample
-
-    >>> task = Resample()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.orientation = ""RPI""
-    >>> task.inputs.master = File.mock()
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.medimage_afni import OneD
+    >>> from pydra.tasks.afni.auto.preprocess.t_corr_1d import TCorr1D
+
+    >>> task = TCorr1D()
+    >>> task.inputs.xset = Nifti1.mock(None)
+    >>> task.inputs.y_1d = OneD.mock(None)
     >>> task.cmdline
-    '3dresample -orient RPI -prefix functional_resample.nii -inset functional.nii'
+    '3dTcorr1D -prefix u_rc1s1_Template_correlation.nii.gz u_rc1s1_Template.nii seed.1D'
 
 
     """
 
-    input_spec = Resample_input_spec
-    output_spec = Resample_output_spec
-    executable = "3dresample"
+    input_spec = TCorr1D_input_spec
+    output_spec = TCorr1D_output_spec
+    executable = "3dTcorr1D"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/retroicor.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/convert_dset.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,123 +1,144 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Gifti
+from fileformats.medimage_afni import Dset
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
-        Nifti1,
+        Gifti,
         {
-            "help_string": "input file to 3dretroicor",
-            "argstr": "{in_file}",
-            "copyfile": False,
+            "help_string": "input file to ConvertDset",
+            "argstr": "-input {in_file}",
             "mandatory": True,
-            "position": -1,
+            "position": -2,
         },
     ),
     (
         "out_file",
-        Path,
+        Dset,
         {
-            "help_string": "output image file name",
+            "help_string": "output file for ConvertDset",
             "argstr": "-prefix {out_file}",
-            "position": 1,
-            "output_file_template": "{in_file}_retroicor",
-        },
-    ),
-    (
-        "card",
-        OneD,
-        {
-            "help_string": "1D cardiac data file for cardiac correction",
-            "argstr": "-card {card}",
-            "position": -2,
-        },
-    ),
-    (
-        "resp",
-        OneD,
-        {
-            "help_string": "1D respiratory waveform data for correction",
-            "argstr": "-resp {resp}",
-            "position": -3,
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "threshold",
-        int,
+        "out_type",
+        ty.Any,
         {
-            "help_string": "Threshold for detection of R-wave peaks in input (Make sure it is above the background noise level, Try 3/4 or 4/5 times range plus minimum)",
-            "argstr": "-threshold {threshold}",
-            "position": -4,
+            "help_string": "output type",
+            "argstr": "-o_{out_type}",
+            "mandatory": True,
+            "position": 0,
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+ConvertDset_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [("out_file", Dset, {"help_string": "output file"})]
+ConvertDset_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class ConvertDset(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Gifti
+    >>> from fileformats.medimage_afni import Dset
+    >>> from pydra.tasks.afni.auto.utils.convert_dset import ConvertDset
+
+    >>> task = ConvertDset()
+    >>> task.inputs.in_file = Gifti.mock(None)
+    >>> task.inputs.out_file = Dset.mock(None)
+    >>> task.inputs.out_type = "niml_asc"
+    >>> task.cmdline
+    'ConvertDset -o_niml_asc -input lh.pial_converted.gii -prefix lh.pial_converted.niml.dset'
+
+
+    """
+
+    input_spec = ConvertDset_input_spec
+    output_spec = ConvertDset_output_spec
+    executable = "ConvertDset"
+
+
+input_fields = [
     (
-        "order",
-        int,
+        "in_file",
+        File,
         {
-            "help_string": "The order of the correction (2 is typical)",
-            "argstr": "-order {order}",
-            "position": -5,
+            "help_string": "input file to ConvertDset",
+            "argstr": "-input {in_file}",
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "cardphase",
+        "out_file",
         File,
         {
-            "help_string": "Filename for 1D cardiac phase output",
-            "argstr": "-cardphase {cardphase}",
-            "position": -6,
+            "help_string": "output file for ConvertDset",
+            "argstr": "-prefix {out_file}",
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "respphase",
-        File,
+        "out_type",
+        ty.Any,
         {
-            "help_string": "Filename for 1D resp phase output",
-            "argstr": "-respphase {respphase}",
-            "position": -7,
+            "help_string": "output type",
+            "argstr": "-o_{out_type}",
+            "mandatory": True,
+            "position": 0,
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Retroicor_input_spec = specs.SpecInfo(
+convert_dset_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-Retroicor_output_spec = specs.SpecInfo(
+output_fields = [("out_file", File, {"help_string": "output file"})]
+convert_dset_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Retroicor(ShellCommandTask):
+class convert_dset(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.retroicor import Retroicor
-
-    >>> task = Retroicor()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.card = OneD.mock()
-    >>> task.inputs.resp = OneD.mock()
-    >>> task.inputs.cardphase = File.mock()
-    >>> task.inputs.respphase = File.mock()
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> from pydra.tasks.afni.auto.utils.convert_dset import convert_dset
+
+    >>> task = convert_dset()
+    >>> task.inputs.in_file = File.mock(None)
+    >>> task.inputs.out_file = File.mock(None)
+    >>> task.inputs.out_type = "niml_asc"
     >>> task.cmdline
-    '3dretroicor -prefix functional_retroicor.nii -resp resp.1D -card mask.1D functional.nii'
+    'ConvertDset -o_niml_asc -input lh.pial_converted.gii -prefix lh.pial_converted.niml.dset'
 
 
     """
 
-    input_spec = Retroicor_input_spec
-    output_spec = Retroicor_output_spec
-    executable = "3dretroicor"
+    input_spec = convert_dset_input_spec
+    output_spec = convert_dset_output_spec
+    executable = "ConvertDset"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/roi_stats.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/roi_stats.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,17 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
-from pydra.engine.specs import MultiInputObj
+from pydra.engine import ShellCommandTask, specs
+import typing as ty
+
+
+logger = logging.getLogger(__name__)
+
 
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input dataset",
@@ -94,15 +97,15 @@
             "help_string": "Output results in a 1D format that includes uncommented labels. May not work optimally with typical 1D functions, but is useful for R functions.",
             "argstr": "-1DRformat",
             "xor": ["format1D"],
         },
     ),
     (
         "stat",
-        MultiInputObj,
+        ty.List[File],
         {
             "help_string": "Statistics to compute. Options include:\n\n * mean       =   Compute the mean using only non_zero voxels.\n                  Implies the opposite for the mean computed\n                  by default.\n * median     =   Compute the median of nonzero voxels\n * mode       =   Compute the mode of nonzero voxels.\n                  (integral valued sets only)\n * minmax     =   Compute the min/max of nonzero voxels\n * sum        =   Compute the sum using only nonzero voxels.\n * voxels     =   Compute the number of nonzero voxels\n * sigma      =   Compute the standard deviation of nonzero\n                  voxels\n\nStatistics that include zero-valued voxels:\n\n * zerominmax =   Compute the min/max of all voxels.\n * zerosigma  =   Compute the standard deviation of all\n                  voxels.\n * zeromedian =   Compute the median of all voxels.\n * zeromode   =   Compute the mode of all voxels.\n * summary    =   Only output a summary line with the grand\n                  mean across all briks in the input dataset.\n                  This option cannot be used with nomeanout.\n\nMore that one option can be specified.",
             "argstr": "{stat}...",
         },
     ),
     (
         "out_file",
@@ -127,26 +130,24 @@
 
 class ROIStats(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.medimage.nifti import NiftiGz
-    >>> from pydra.engine.specs import MultiInputObj
-    >>> from pydra.tasks.afni.auto.roi_stats import ROIStats
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.preprocess.roi_stats import ROIStats
 
     >>> task = ROIStats()
-    >>> task.inputs.in_file = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
     >>> task.inputs.mask = File.mock()
-    >>> task.inputs.mask_file = NiftiGz.mock()
+    >>> task.inputs.mask_file = NiftiGz.mock(None)
     >>> task.inputs.roisel = File.mock()
-    >>> task.inputs.nomeanout = "True"
-    >>> task.inputs.stat = "["mean", "median", "voxels"]"
+    >>> task.inputs.nomeanout = True
+    >>> task.inputs.stat = None
     >>> task.cmdline
     '3dROIstats -mask skeleton_mask.nii.gz -nomeanout -nzmean -nzmedian -nzvoxels functional.nii > functional_roistat.1D'
 
 
     """
 
     input_spec = ROIStats_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/seg.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/warp.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,132 +1,162 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "ANAT is the volume to segment",
-            "argstr": "-anat {in_file}",
-            "copyfile": True,
+            "help_string": "input file to 3dWarp",
+            "argstr": "{in_file}",
+            "copyfile": False,
             "mandatory": True,
             "position": -1,
         },
     ),
     (
-        "mask",
-        ty.Any,
+        "out_file",
+        NiftiGz,
         {
-            "help_string": 'only non-zero voxels in mask are analyzed. mask can either be a dataset or the string "AUTO" which would use AFNI\'s automask function to create the mask.',
-            "argstr": "-mask {mask}",
-            "mandatory": True,
-            "position": -2,
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_warp",
         },
     ),
     (
-        "blur_meth",
-        ty.Any,
+        "tta2mni",
+        bool,
         {
-            "help_string": "set the blurring method for bias field estimation",
-            "argstr": "-blur_meth {blur_meth}",
+            "help_string": "transform dataset from Talairach to MNI152",
+            "argstr": "-tta2mni",
         },
     ),
     (
-        "bias_fwhm",
-        float,
+        "mni2tta",
+        bool,
         {
-            "help_string": "The amount of blurring used when estimating the field bias with the Wells method",
-            "argstr": "-bias_fwhm {bias_fwhm}",
+            "help_string": "transform dataset from MNI152 to Talaraich",
+            "argstr": "-mni2tta",
         },
     ),
     (
-        "classes",
-        str,
+        "matparent",
+        File,
         {
-            "help_string": "CLASS_STRING is a semicolon delimited string of class labels",
-            "argstr": "-classes {classes}",
+            "help_string": "apply transformation from 3dWarpDrive",
+            "argstr": "-matparent {matparent}",
         },
     ),
     (
-        "bmrf",
-        float,
+        "oblique_parent",
+        File,
         {
-            "help_string": "Weighting factor controlling spatial homogeneity of the classifications",
-            "argstr": "-bmrf {bmrf}",
+            "help_string": "Read in the oblique transformation matrix from an oblique dataset and make cardinal dataset oblique to match",
+            "argstr": "-oblique_parent {oblique_parent}",
         },
     ),
     (
-        "bias_classes",
-        str,
+        "deoblique",
+        bool,
         {
-            "help_string": "A semicolon delimited string of classes that contribute to the estimation of the bias field",
-            "argstr": "-bias_classes {bias_classes}",
+            "help_string": "transform dataset from oblique to cardinal",
+            "argstr": "-deoblique",
         },
     ),
     (
-        "prefix",
-        str,
+        "interp",
+        ty.Any,
         {
-            "help_string": "the prefix for the output folder containing all output volumes",
-            "argstr": "-prefix {prefix}",
+            "help_string": "spatial interpolation methods [default = linear]",
+            "argstr": "-{interp}",
         },
     ),
     (
-        "mixfrac",
-        str,
+        "gridset",
+        File,
         {
-            "help_string": "MIXFRAC sets up the volume-wide (within mask) tissue fractions while initializing the segmentation (see IGNORE for exception)",
-            "argstr": "-mixfrac {mixfrac}",
+            "help_string": "copy grid of specified dataset",
+            "argstr": "-gridset {gridset}",
         },
     ),
     (
-        "mixfloor",
+        "newgrid",
         float,
         {
-            "help_string": "Set the minimum value for any class's mixing fraction",
-            "argstr": "-mixfloor {mixfloor}",
+            "help_string": "specify grid of this size (mm)",
+            "argstr": "-newgrid {newgrid}",
         },
     ),
     (
-        "main_N",
+        "zpad",
         int,
         {
-            "help_string": "Number of iterations to perform.",
-            "argstr": "-main_N {main_N}",
+            "help_string": "pad input dataset with N planes of zero on all sides.",
+            "argstr": "-zpad {zpad}",
         },
     ),
+    (
+        "verbose",
+        bool,
+        {"help_string": "Print out some information along the way.", "argstr": "-verb"},
+    ),
+    (
+        "save_warp",
+        bool,
+        {"help_string": "save warp as .mat file", "requires": ["verbose"]},
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Seg_input_spec = specs.SpecInfo(
+Warp_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", File, {"help_string": "output file"})]
-Seg_output_spec = specs.SpecInfo(
+output_fields = [("warp_file", File, {"help_string": "warp transform .mat file"})]
+Warp_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Seg(ShellCommandTask):
+class Warp(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.seg import Seg
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.preprocess.warp import Warp
+
+    >>> task = Warp()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = NiftiGz.mock(None)
+    >>> task.inputs.matparent = File.mock()
+    >>> task.inputs.oblique_parent = File.mock()
+    >>> task.inputs.deoblique = True
+    >>> task.inputs.gridset = File.mock()
+    >>> task.cmdline
+    '3dWarp -deoblique -prefix trans.nii.gz structural.nii'
+
 
-    >>> task = Seg()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.mask = ""AUTO""
+    >>> task = Warp()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = NiftiGz.mock(None)
+    >>> task.inputs.matparent = File.mock()
+    >>> task.inputs.oblique_parent = File.mock()
+    >>> task.inputs.gridset = File.mock()
+    >>> task.inputs.newgrid = 1.0
     >>> task.cmdline
-    '3dSeg -mask AUTO -anat structural.nii'
+    '3dWarp -newgrid 1.000000 -prefix trans.nii.gz structural.nii'
 
 
     """
 
-    input_spec = Seg_input_spec
-    output_spec = Seg_output_spec
-    executable = "3dSeg"
+    input_spec = Warp_input_spec
+    output_spec = Warp_output_spec
+    executable = "3dWarp"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/svm_test.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/s_v_m_train.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,105 +1,146 @@
 from fileformats.generic import File
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "model",
+        "ttype",
         str,
         {
-            "help_string": "modname is the basename for the brik containing the SVM model",
-            "argstr": "-model {model}",
+            "help_string": "tname: classification or regression",
+            "argstr": "-type {ttype}",
             "mandatory": True,
         },
     ),
     (
         "in_file",
         File,
         {
-            "help_string": "A 3D or 3D+t AFNI brik dataset to be used for testing.",
-            "argstr": "-testvol {in_file}",
+            "help_string": "A 3D+t AFNI brik dataset to be used for training.",
+            "argstr": "-trainvol {in_file}",
+            "copyfile": False,
             "mandatory": True,
         },
     ),
     (
         "out_file",
         Path,
         {
-            "help_string": "filename for .1D prediction file(s).",
-            "argstr": "-predictions {out_file}",
-            "output_file_template": "%s_predictions",
+            "help_string": "output sum of weighted linear support vectors file name",
+            "argstr": "-bucket {out_file}",
+            "output_file_template": "{in_file}_vectors",
+        },
+    ),
+    (
+        "model",
+        Path,
+        {
+            "help_string": "basename for the brik containing the SVM model",
+            "argstr": "-model {model}",
+            "output_file_template": "{in_file}_model",
+        },
+    ),
+    (
+        "alphas",
+        Path,
+        {
+            "help_string": "output alphas file name",
+            "argstr": "-alpha {alphas}",
+            "output_file_template": "{in_file}_alphas",
         },
     ),
     (
-        "testlabels",
+        "mask",
         File,
         {
-            "help_string": "*true* class category .1D labels for the test dataset. It is used to calculate the prediction accuracy performance",
-            "argstr": "-testlabels {testlabels}",
+            "help_string": "byte-format brik file used to mask voxels in the analysis",
+            "argstr": "-mask {mask}",
+            "copyfile": False,
+            "position": -1,
         },
     ),
     (
-        "classout",
+        "nomodelmask",
         bool,
         {
-            "help_string": "Flag to specify that pname files should be integer-valued, corresponding to class category decisions.",
-            "argstr": "-classout",
+            "help_string": "Flag to enable the omission of a mask file",
+            "argstr": "-nomodelmask",
         },
     ),
     (
-        "nopredcensord",
-        bool,
+        "trainlabels",
+        File,
         {
-            "help_string": "Flag to prevent writing predicted values for censored time-points",
-            "argstr": "-nopredcensord",
+            "help_string": ".1D labels corresponding to the stimulus paradigm for the training data.",
+            "argstr": "-trainlabels {trainlabels}",
         },
     ),
     (
-        "nodetrend",
-        bool,
+        "censor",
+        File,
+        {
+            "help_string": ".1D censor file that allows the user to ignore certain samples in the training data.",
+            "argstr": "-censor {censor}",
+        },
+    ),
+    (
+        "kernel",
+        str,
+        {
+            "help_string": "string specifying type of kernel function:linear, polynomial, rbf, sigmoid",
+            "argstr": "-kernel {kernel}",
+        },
+    ),
+    (
+        "max_iterations",
+        int,
         {
-            "help_string": "Flag to specify that pname files should not be linearly detrended",
-            "argstr": "-nodetrend",
+            "help_string": "Specify the maximum number of iterations for the optimization.",
+            "argstr": "-max_iterations {max_iterations}",
         },
     ),
     (
-        "multiclass",
+        "w_out",
         bool,
         {
-            "help_string": "Specifies multiclass algorithm for classification",
-            "argstr": "-multiclass {multiclass}",
+            "help_string": "output sum of weighted linear support vectors",
+            "argstr": "-wout",
         },
     ),
     (
         "options",
         str,
         {"help_string": "additional options for SVM-light", "argstr": "{options}"},
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-SVMTest_input_spec = specs.SpecInfo(
+s_v_m_train_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-SVMTest_output_spec = specs.SpecInfo(
+s_v_m_train_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class SVMTest(ShellCommandTask):
+class s_v_m_train(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from pydra.tasks.afni.auto.svm_test import SVMTest
+    >>> from pydra.tasks.afni.auto.svm.s_v_m_train import s_v_m_train
 
     """
 
-    input_spec = SVMTest_input_spec
-    output_spec = SVMTest_output_spec
+    input_spec = s_v_m_train_input_spec
+    output_spec = s_v_m_train_output_spec
     executable = "3dsvm"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/svm_train.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/clip_level.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,142 +1,155 @@
 from fileformats.generic import File
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
-import typing as ty
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
+
+
+logger = logging.getLogger(__name__)
+
 
 input_fields = [
     (
-        "ttype",
-        str,
-        {
-            "help_string": "tname: classification or regression",
-            "argstr": "-type {ttype}",
-            "mandatory": True,
-        },
-    ),
-    (
         "in_file",
-        File,
+        Nifti1,
         {
-            "help_string": "A 3D+t AFNI brik dataset to be used for training.",
-            "argstr": "-trainvol {in_file}",
-            "copyfile": False,
+            "help_string": "input file to 3dClipLevel",
+            "argstr": "{in_file}",
             "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "out_file",
-        Path,
-        {
-            "help_string": "output sum of weighted linear support vectors file name",
-            "argstr": "-bucket {out_file}",
-            "output_file_template": "{in_file}_vectors",
-        },
-    ),
-    (
-        "model",
-        Path,
-        {
-            "help_string": "basename for the brik containing the SVM model",
-            "argstr": "-model {model}",
-            "output_file_template": "{in_file}_model",
-        },
-    ),
-    (
-        "alphas",
-        Path,
-        {
-            "help_string": "output alphas file name",
-            "argstr": "-alpha {alphas}",
-            "output_file_template": "{in_file}_alphas",
-        },
-    ),
-    (
-        "mask",
-        File,
+        "mfrac",
+        float,
         {
-            "help_string": "byte-format brik file used to mask voxels in the analysis",
-            "argstr": "-mask {mask}",
-            "copyfile": False,
-            "position": -1,
+            "help_string": "Use the number ff instead of 0.50 in the algorithm",
+            "argstr": "-mfrac {mfrac}",
+            "position": 2,
         },
     ),
     (
-        "nomodelmask",
+        "doall",
         bool,
         {
-            "help_string": "Flag to enable the omission of a mask file",
-            "argstr": "-nomodelmask",
+            "help_string": "Apply the algorithm to each sub-brick separately.",
+            "argstr": "-doall",
+            "position": 3,
+            "xor": "grad",
         },
     ),
     (
-        "trainlabels",
+        "grad",
         File,
         {
-            "help_string": ".1D labels corresponding to the stimulus paradigm for the training data.",
-            "argstr": "-trainlabels {trainlabels}",
+            "help_string": "Also compute a 'gradual' clip level as a function of voxel position, and output that to a dataset.",
+            "argstr": "-grad {grad}",
+            "position": 3,
+            "xor": "doall",
         },
     ),
+]
+ClipLevel_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [("clip_val", float, {"help_string": "output"})]
+ClipLevel_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class ClipLevel(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.clip_level import ClipLevel
+
+    >>> task = ClipLevel()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.grad = File.mock()
+    >>> task.cmdline
+    '3dClipLevel anatomical.nii'
+
+
+    """
+
+    input_spec = ClipLevel_input_spec
+    output_spec = ClipLevel_output_spec
+    executable = "3dClipLevel"
+
+
+input_fields = [
     (
-        "censor",
-        File,
+        "in_file",
+        Nifti1,
         {
-            "help_string": ".1D censor file that allows the user to ignore certain samples in the training data.",
-            "argstr": "-censor {censor}",
+            "help_string": "input file to 3dClipLevel",
+            "argstr": "{in_file}",
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "kernel",
-        str,
+        "mfrac",
+        float,
         {
-            "help_string": "string specifying type of kernel function:linear, polynomial, rbf, sigmoid",
-            "argstr": "-kernel {kernel}",
+            "help_string": "Use the number ff instead of 0.50 in the algorithm",
+            "argstr": "-mfrac {mfrac}",
+            "position": 2,
         },
     ),
     (
-        "max_iterations",
-        int,
+        "doall",
+        bool,
         {
-            "help_string": "Specify the maximum number of iterations for the optimization.",
-            "argstr": "-max_iterations {max_iterations}",
+            "help_string": "Apply the algorithm to each sub-brick separately.",
+            "argstr": "-doall",
+            "position": 3,
+            "xor": "grad",
         },
     ),
     (
-        "w_out",
-        bool,
+        "grad",
+        File,
         {
-            "help_string": "output sum of weighted linear support vectors",
-            "argstr": "-wout",
+            "help_string": "Also compute a 'gradual' clip level as a function of voxel position, and output that to a dataset.",
+            "argstr": "-grad {grad}",
+            "position": 3,
+            "xor": "doall",
         },
     ),
-    (
-        "options",
-        str,
-        {"help_string": "additional options for SVM-light", "argstr": "{options}"},
-    ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-SVMTrain_input_spec = specs.SpecInfo(
+clip_level_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-SVMTrain_output_spec = specs.SpecInfo(
+output_fields = [("clip_val", float, {"help_string": "output"})]
+clip_level_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class SVMTrain(ShellCommandTask):
+class clip_level(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from pydra.tasks.afni.auto.svm_train import SVMTrain
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.clip_level import clip_level
+
+    >>> task = clip_level()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.grad = File.mock()
+    >>> task.cmdline
+    '3dClipLevel anatomical.nii'
+
 
     """
 
-    input_spec = SVMTrain_input_spec
-    output_spec = SVMTrain_output_spec
-    executable = "3dsvm"
+    input_spec = clip_level_input_spec
+    output_spec = clip_level_output_spec
+    executable = "3dClipLevel"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/synthesize.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/undump.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,105 +1,123 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "cbucket",
+        "in_file",
         Nifti1,
         {
-            "help_string": "Read the dataset output from 3dDeconvolve via the '-cbucket' option.",
-            "argstr": "-cbucket {cbucket}",
+            "help_string": "input file to 3dUndump, whose geometry will determinethe geometry of the output",
+            "argstr": "-master {in_file}",
             "copyfile": False,
             "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "matrix",
-        OneD,
+        "out_file",
+        Nifti1,
+        {"help_string": "output image file name", "argstr": "-prefix {out_file}"},
+    ),
+    (
+        "mask_file",
+        File,
         {
-            "help_string": "Read the matrix output from 3dDeconvolve via the '-x1D' option.",
-            "argstr": "-matrix {matrix}",
-            "copyfile": False,
-            "mandatory": True,
+            "help_string": "mask image file name. Only voxels that are nonzero in the mask can be set.",
+            "argstr": "-mask {mask_file}",
         },
     ),
     (
-        "select",
-        list,
+        "datatype",
+        ty.Any,
+        {"help_string": "set output file datatype", "argstr": "-datum {datatype}"},
+    ),
+    (
+        "default_value",
+        float,
         {
-            "help_string": "A list of selected columns from the matrix (and the corresponding coefficient sub-bricks from the cbucket). Valid types include 'baseline',  'polort', 'allfunc', 'allstim', 'all', Can also provide 'something' where something matches a stim_label from 3dDeconvolve, and 'digits' where digits are the numbers of the select matrix columns by numbers (starting at 0), or number ranges of the form '3..7' and '3-7'.",
-            "argstr": "-select {select}",
-            "mandatory": True,
+            "help_string": "default value stored in each input voxel that does not have a value supplied in the input file",
+            "argstr": "-dval {default_value}",
         },
     ),
     (
-        "out_file",
-        Path,
+        "fill_value",
+        float,
         {
-            "help_string": "output dataset prefix name (default 'syn')",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "syn",
+            "help_string": "value, used for each voxel in the output dataset that is NOT listed in the input file",
+            "argstr": "-fval {fill_value}",
         },
     ),
     (
-        "dry_run",
-        bool,
+        "coordinates_specification",
+        ty.Any,
         {
-            "help_string": "Don't compute the output, just check the inputs.",
-            "argstr": "-dry",
+            "help_string": "Coordinates in the input file as index triples (i, j, k) or spatial coordinates (x, y, z) in mm",
+            "argstr": "-{coordinates_specification}",
         },
     ),
     (
-        "TR",
+        "srad",
         float,
         {
-            "help_string": "TR to set in the output.  The default value of TR is read from the header of the matrix file.",
-            "argstr": "-TR {TR}",
+            "help_string": "radius in mm of the sphere that will be filled about each input (x,y,z) or (i,j,k) voxel. If the radius is not given, or is 0, then each input data line sets the value in only one voxel.",
+            "argstr": "-srad {srad}",
         },
     ),
     (
-        "cenfill",
+        "orient",
         ty.Any,
         {
-            "help_string": "Determines how censored time points from the 3dDeconvolve run will be filled. Valid types are 'zero', 'nbhr' and 'none'.",
-            "argstr": "-cenfill {cenfill}",
+            "help_string": "Specifies the coordinate order used by -xyz. The code must be 3 letters, one each from the pairs {R,L} {A,P} {I,S}.  The first letter gives the orientation of the x-axis, the second the orientation of the y-axis, the third the z-axis: R = right-to-left         L = left-to-right A = anterior-to-posterior P = posterior-to-anterior I = inferior-to-superior  S = superior-to-inferior If -orient isn't used, then the coordinate order of the -master (in_file) dataset is used to interpret (x,y,z) inputs.",
+            "argstr": "-orient {orient}",
+        },
+    ),
+    (
+        "head_only",
+        bool,
+        {
+            "help_string": "create only the .HEAD file which gets exploited by the AFNI matlab library function New_HEAD.m",
+            "argstr": "-head_only",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Synthesize_input_spec = specs.SpecInfo(
+Undump_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-Synthesize_output_spec = specs.SpecInfo(
+output_fields = [("out_file", Nifti1, {"help_string": "assembled file"})]
+Undump_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Synthesize(ShellCommandTask):
+class Undump(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from fileformats.medimage_afni import OneD
-    >>> from pydra.tasks.afni.auto.synthesize import Synthesize
-
-    >>> task = Synthesize()
-    >>> task.inputs.cbucket = Nifti1.mock()
-    >>> task.inputs.matrix = OneD.mock()
-    >>> task.inputs.select = "["baseline"]"
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.undump import Undump
+
+    >>> task = Undump()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.mask_file = File.mock()
     >>> task.cmdline
-    '3dSynthesize -cbucket functional.nii -matrix output.1D -select baseline'
+    '3dUndump -prefix structural_undumped.nii -master structural.nii'
 
 
     """
 
-    input_spec = Synthesize_input_spec
-    output_spec = Synthesize_output_spec
-    executable = "3dSynthesize"
+    input_spec = Undump_input_spec
+    output_spec = Undump_output_spec
+    executable = "3dUndump"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_cat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/to_3_d.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,78 +1,95 @@
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_files",
-        ty.List[Nifti1],
-        {
-            "help_string": "input file to 3dTcat",
-            "argstr": " {in_files}",
-            "copyfile": False,
-            "mandatory": True,
-            "position": -1,
-        },
-    ),
-    (
         "out_file",
-        Path,
+        Nifti1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_files}_tcat",
+            "output_file_template": "{in_folder}",
         },
     ),
     (
-        "rlt",
+        "in_folder",
         ty.Any,
         {
-            "help_string": "Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.",
-            "argstr": "-rlt{rlt}",
-            "position": 1,
+            "help_string": "folder with DICOM images to convert",
+            "argstr": "{in_folder}/*.dcm",
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "verbose",
+        "filetype",
+        ty.Any,
+        {"help_string": "type of datafile being converted", "argstr": "-{filetype}"},
+    ),
+    (
+        "skipoutliers",
+        bool,
+        {"help_string": "skip the outliers check", "argstr": "-skip_outliers"},
+    ),
+    (
+        "assumemosaic",
         bool,
         {
-            "help_string": "Print out some verbose output as the program",
-            "argstr": "-verb",
+            "help_string": "assume that Siemens image is mosaic",
+            "argstr": "-assume_dicom_mosaic",
+        },
+    ),
+    (
+        "datatype",
+        ty.Any,
+        {"help_string": "set output file datatype", "argstr": "-datum {datatype}"},
+    ),
+    (
+        "funcparams",
+        str,
+        {
+            "help_string": "parameters for functional data",
+            "argstr": "-time:zt {funcparams} alt+z2",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-TCat_input_spec = specs.SpecInfo(
+to3_d_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
 output_fields = []
-TCat_output_spec = specs.SpecInfo(
+to3_d_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class TCat(ShellCommandTask):
+class to3_d(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.t_cat import TCat
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.to_3_d import to3_d
 
-    >>> task = TCat()
-    >>> task.inputs.in_files = None
-    >>> task.inputs.out_file = ""functional_tcat.nii""
-    >>> task.inputs.rlt = ""+""
+    >>> task = to3_d()
+    >>> task.inputs.out_file = Nifti1.mock(None)
+    >>> task.inputs.in_folder = "."
+    >>> task.inputs.filetype = "anat"
+    >>> task.inputs.datatype = "float"
     >>> task.cmdline
-    '3dTcat -rlt+ -prefix functional_tcat.nii functional.nii functional2.nii'
+    'to3d -datum float -anat -prefix dicomdir.nii ./*.dcm'
 
 
     """
 
-    input_spec = TCat_input_spec
-    output_spec = TCat_output_spec
-    executable = "3dTcat"
+    input_spec = to3_d_input_spec
+    output_spec = to3_d_output_spec
+    executable = "to3d"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_cat_sub_brick.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/t_cat_sub_brick.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,16 @@
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_files",
         list,
         {
             "help_string": "List of tuples of file names and subbrick selectors as strings.Don't forget to protect the single quotes in the subbrick selectorso the contents are protected from the command line interpreter.",
             "argstr": "{in_files[0]}{in_files[1]} ...",
@@ -47,22 +51,87 @@
 
 
 class TCatSubBrick(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from pydra.tasks.afni.auto.t_cat_sub_brick import TCatSubBrick
+    >>> from pydra.tasks.afni.auto.utils.t_cat_sub_brick import TCatSubBrick
 
     >>> task = TCatSubBrick()
-    >>> task.inputs.in_files = "[('functional.nii', "'{2..$}'"), ('functional2.nii', "'{2..$}'")]"
-    >>> task.inputs.out_file = ""functional_tcat.nii""
-    >>> task.inputs.rlt = ""+""
+    >>> task.inputs.in_files = [('functional.nii', "'{2..$}'"), ('functional2.nii', "'{2..$}'")]
+    >>> task.inputs.out_file = "functional_tcat.nii"
+    >>> task.inputs.rlt = "+"
     >>> task.cmdline
     '3dTcat -rlt+ -prefix functional_tcat.nii functional.nii"{2..$}" functional2.nii"{2..$}" '
 
 
     """
 
     input_spec = TCatSubBrick_input_spec
     output_spec = TCatSubBrick_output_spec
     executable = "3dTcat"
+
+
+input_fields = [
+    (
+        "in_files",
+        list,
+        {
+            "help_string": "List of tuples of file names and subbrick selectors as strings.Don't forget to protect the single quotes in the subbrick selectorso the contents are protected from the command line interpreter.",
+            "argstr": "{in_files[0]}{in_files[1]} ...",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -1,
+        },
+    ),
+    (
+        "out_file",
+        Path,
+        {
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": '"functional_tcat.nii"',
+        },
+    ),
+    (
+        "rlt",
+        ty.Any,
+        {
+            "help_string": "Remove linear trends in each voxel time series loaded from each input dataset, SEPARATELY. Option -rlt removes the least squares fit of 'a+b*t' to each voxel time series. Option -rlt+ adds dataset mean back in. Option -rlt++ adds overall mean of all dataset timeseries back in.",
+            "argstr": "-rlt{rlt}",
+            "position": 1,
+        },
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+t_cat_sub_brick_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+t_cat_sub_brick_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class t_cat_sub_brick(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from pydra.tasks.afni.auto.utils.t_cat_sub_brick import t_cat_sub_brick
+
+    >>> task = t_cat_sub_brick()
+    >>> task.inputs.in_files = [('functional.nii', "'{2..$}'"), ('functional2.nii', "'{2..$}'")]
+    >>> task.inputs.out_file = "functional_tcat.nii"
+    >>> task.inputs.rlt = "+"
+    >>> task.cmdline
+    '3dTcat -rlt+ -prefix functional_tcat.nii functional.nii"{2..$}" functional2.nii"{2..$}" '
+
+
+    """
+
+    input_spec = t_cat_sub_brick_input_spec
+    output_spec = t_cat_sub_brick_output_spec
+    executable = "3dTcat"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_corr_map.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/quality_index.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,185 +1,232 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
-import typing as ty
+from pydra.engine import ShellCommandTask, specs
+
+
+logger = logging.getLogger(__name__)
+
 
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "",
-            "argstr": "-input {in_file}",
-            "copyfile": False,
+            "help_string": "input dataset",
+            "argstr": "{in_file}",
             "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "seeds",
+        "mask",
         File,
-        {"help_string": "", "argstr": "-seed {seeds}", "xor": "seeds_width"},
+        {
+            "help_string": "compute correlation only across masked voxels",
+            "argstr": "-mask {mask}",
+            "xor": ["autoclip", "automask"],
+        },
     ),
-    ("mask", Nifti1, {"help_string": "", "argstr": "-mask {mask}"}),
-    ("automask", bool, {"help_string": "", "argstr": "-automask"}),
-    ("polort", int, {"help_string": "", "argstr": "-polort {polort}"}),
     (
-        "bandpass",
-        ty.Any,
-        {"help_string": "", "argstr": "-bpass {bandpass[0]} {bandpass[1]}"},
+        "spearman",
+        bool,
+        False,
+        {
+            "help_string": "Quality index is 1 minus the Spearman (rank) correlation coefficient of each sub-brick with the median sub-brick. (default).",
+            "argstr": "-spearman",
+        },
     ),
     (
-        "regress_out_timeseries",
-        File,
-        {"help_string": "", "argstr": "-ort {regress_out_timeseries}"},
+        "quadrant",
+        bool,
+        False,
+        {
+            "help_string": "Similar to -spearman, but using 1 minus the quadrant correlation coefficient as the quality index.",
+            "argstr": "-quadrant",
+        },
     ),
-    ("blur_fwhm", float, {"help_string": "", "argstr": "-Gblur {blur_fwhm}"}),
     (
-        "seeds_width",
-        float,
-        {"help_string": "", "argstr": "-Mseed {seeds_width}", "xor": "seeds"},
+        "autoclip",
+        bool,
+        False,
+        {
+            "help_string": "clip off small voxels",
+            "argstr": "-autoclip",
+            "xor": ["mask"],
+        },
     ),
-    ("mean_file", Path, {"help_string": "", "argstr": "-Mean {mean_file}"}),
-    ("zmean", Path, {"help_string": "", "argstr": "-Zmean {zmean}"}),
-    ("qmean", Path, {"help_string": "", "argstr": "-Qmean {qmean}"}),
-    ("pmean", Path, {"help_string": "", "argstr": "-Pmean {pmean}"}),
-    ("thresholds", list, {"help_string": ""}),
     (
-        "absolute_threshold",
-        Path,
+        "automask",
+        bool,
+        False,
         {
-            "help_string": "",
-            "argstr": "-Thresh {absolute_threshold[0]} {absolute_threshold[1]}",
-            "xor": (
-                "absolute_threshold",
-                "var_absolute_threshold",
-                "var_absolute_threshold_normalize",
-            ),
+            "help_string": "clip off small voxels",
+            "argstr": "-automask",
+            "xor": ["mask"],
         },
     ),
+    ("clip", float, {"help_string": "clip off values below", "argstr": "-clip {clip}"}),
     (
-        "var_absolute_threshold",
-        Path,
+        "interval",
+        bool,
+        False,
         {
-            "help_string": "",
-            "argstr": "-VarThresh {var_absolute_threshold[0]} {var_absolute_threshold[1]} {var_absolute_threshold[2]} {var_absolute_threshold[3]}",
-            "xor": (
-                "absolute_threshold",
-                "var_absolute_threshold",
-                "var_absolute_threshold_normalize",
-            ),
+            "help_string": "write out the median + 3.5 MAD of outlier count with each timepoint",
+            "argstr": "-range",
         },
     ),
     (
-        "var_absolute_threshold_normalize",
+        "out_file",
         Path,
         {
-            "help_string": "",
-            "argstr": "-VarThreshN {var_absolute_threshold_normalize[0]} {var_absolute_threshold_normalize[1]} {var_absolute_threshold_normalize[2]} {var_absolute_threshold_normalize[3]}",
-            "xor": (
-                "absolute_threshold",
-                "var_absolute_threshold",
-                "var_absolute_threshold_normalize",
-            ),
+            "help_string": "capture standard output",
+            "argstr": "> {out_file}",
+            "position": -1,
+            "output_file_template": "{in_file}_tqual",
+        },
+    ),
+]
+quality_index_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+quality_index_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class quality_index(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.quality_index import quality_index
+
+    >>> task = quality_index()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = File.mock()
+    >>> task.cmdline
+    '3dTqual functional.nii > functional_tqual'
+
+
+    """
+
+    input_spec = quality_index_input_spec
+    output_spec = quality_index_output_spec
+    executable = "3dTqual"
+
+
+input_fields = [
+    (
+        "in_file",
+        Nifti1,
+        {
+            "help_string": "input dataset",
+            "argstr": "{in_file}",
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "correlation_maps",
-        Path,
-        {"help_string": "", "argstr": "-CorrMap {correlation_maps}"},
+        "mask",
+        File,
+        {
+            "help_string": "compute correlation only across masked voxels",
+            "argstr": "-mask {mask}",
+            "xor": ["autoclip", "automask"],
+        },
     ),
     (
-        "correlation_maps_masked",
-        Path,
-        {"help_string": "", "argstr": "-CorrMask {correlation_maps_masked}"},
+        "spearman",
+        bool,
+        False,
+        {
+            "help_string": "Quality index is 1 minus the Spearman (rank) correlation coefficient of each sub-brick with the median sub-brick. (default).",
+            "argstr": "-spearman",
+        },
     ),
-    ("expr", str, {"help_string": ""}),
     (
-        "average_expr",
-        Path,
+        "quadrant",
+        bool,
+        False,
         {
-            "help_string": "",
-            "argstr": "-Aexpr {average_expr[0]} {average_expr[1]}",
-            "xor": ("average_expr", "average_expr_nonzero", "sum_expr"),
+            "help_string": "Similar to -spearman, but using 1 minus the quadrant correlation coefficient as the quality index.",
+            "argstr": "-quadrant",
         },
     ),
     (
-        "average_expr_nonzero",
-        Path,
+        "autoclip",
+        bool,
+        False,
         {
-            "help_string": "",
-            "argstr": "-Cexpr {average_expr_nonzero[0]} {average_expr_nonzero[1]}",
-            "xor": ("average_expr", "average_expr_nonzero", "sum_expr"),
+            "help_string": "clip off small voxels",
+            "argstr": "-autoclip",
+            "xor": ["mask"],
         },
     ),
     (
-        "sum_expr",
-        Path,
+        "automask",
+        bool,
+        False,
         {
-            "help_string": "",
-            "argstr": "-Sexpr {sum_expr[0]} {sum_expr[1]}",
-            "xor": ("average_expr", "average_expr_nonzero", "sum_expr"),
+            "help_string": "clip off small voxels",
+            "argstr": "-automask",
+            "xor": ["mask"],
         },
     ),
-    ("histogram_bin_numbers", int, {"help_string": ""}),
+    ("clip", float, {"help_string": "clip off values below", "argstr": "-clip {clip}"}),
     (
-        "histogram",
-        Path,
-        {"help_string": "", "argstr": "-Hist {histogram[0]} {histogram[1]}"},
+        "interval",
+        bool,
+        False,
+        {
+            "help_string": "write out the median + 3.5 MAD of outlier count with each timepoint",
+            "argstr": "-range",
+        },
     ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
     (
         "out_file",
         Path,
-        {"help_string": "output image file name", "argstr": "-prefix {out_file}"},
+        {
+            "help_string": "capture standard output",
+            "argstr": "> {out_file}",
+            "position": -1,
+            "output_file_template": "{in_file}_tqual",
+        },
     ),
 ]
-TCorrMap_input_spec = specs.SpecInfo(
+QualityIndex_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    ("mean_file", File, {}),
-    ("zmean", File, {}),
-    ("qmean", File, {}),
-    ("pmean", File, {}),
-    ("absolute_threshold", File, {}),
-    ("var_absolute_threshold", File, {}),
-    ("var_absolute_threshold_normalize", File, {}),
-    ("correlation_maps", File, {}),
-    ("correlation_maps_masked", File, {}),
-    ("average_expr", File, {}),
-    ("average_expr_nonzero", File, {}),
-    ("sum_expr", File, {}),
-    ("histogram", File, {}),
-]
-TCorrMap_output_spec = specs.SpecInfo(
+output_fields = []
+QualityIndex_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class TCorrMap(ShellCommandTask):
+class QualityIndex(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.t_corr_map import TCorrMap
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.quality_index import QualityIndex
 
-    >>> task = TCorrMap()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.seeds = File.mock()
-    >>> task.inputs.mask = Nifti1.mock()
-    >>> task.inputs.regress_out_timeseries = File.mock()
+    >>> task = QualityIndex()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = File.mock()
     >>> task.cmdline
-    '3dTcorrMap -input functional.nii -mask mask.nii -Mean functional_meancorr.nii'
+    '3dTqual functional.nii > functional_tqual'
 
 
     """
 
-    input_spec = TCorrMap_input_spec
-    output_spec = TCorrMap_output_spec
-    executable = "3dTcorrMap"
+    input_spec = QualityIndex_input_spec
+    output_spec = QualityIndex_output_spec
+    executable = "3dTqual"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_norm.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_norm.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,13 +1,17 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dTNorm",
             "argstr": "{in_file}",
@@ -87,23 +91,128 @@
 
 
 class TNorm(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.t_norm import TNorm
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.t_norm import TNorm
 
     >>> task = TNorm()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""rm.errts.unit errts+tlrc""
-    >>> task.inputs.norm2 = "True"
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = None
+    >>> task.inputs.norm2 = True
     >>> task.cmdline
     '3dTnorm -norm2 -prefix rm.errts.unit errts+tlrc functional.nii'
 
 
     """
 
     input_spec = TNorm_input_spec
     output_spec = TNorm_output_spec
     executable = "3dTnorm"
+
+
+input_fields = [
+    (
+        "in_file",
+        Nifti1,
+        {
+            "help_string": "input file to 3dTNorm",
+            "argstr": "{in_file}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -1,
+        },
+    ),
+    (
+        "out_file",
+        Path,
+        {
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_tnorm",
+        },
+    ),
+    (
+        "norm2",
+        bool,
+        {
+            "help_string": "L2 normalize (sum of squares = 1) [DEFAULT]",
+            "argstr": "-norm2",
+        },
+    ),
+    (
+        "normR",
+        bool,
+        {
+            "help_string": "normalize so sum of squares = number of time points \\* e.g., so RMS = 1.",
+            "argstr": "-normR",
+        },
+    ),
+    (
+        "norm1",
+        bool,
+        {
+            "help_string": "L1 normalize (sum of absolute values = 1)",
+            "argstr": "-norm1",
+        },
+    ),
+    (
+        "normx",
+        bool,
+        {
+            "help_string": "Scale so max absolute value = 1 (L_infinity norm)",
+            "argstr": "-normx",
+        },
+    ),
+    (
+        "polort",
+        int,
+        {
+            "help_string": "Detrend with polynomials of order p before normalizing [DEFAULT = don't do this].\nUse '-polort 0' to remove the mean, for example",
+            "argstr": "-polort {polort}",
+        },
+    ),
+    (
+        "L1fit",
+        bool,
+        {
+            "help_string": "Detrend with L1 regression (L2 is the default)\nThis option is here just for the hell of it",
+            "argstr": "-L1fit",
+        },
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+t_norm_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+t_norm_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class t_norm(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.preprocess.t_norm import t_norm
+
+    >>> task = t_norm()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = None
+    >>> task.inputs.norm2 = True
+    >>> task.cmdline
+    '3dTnorm -norm2 -prefix rm.errts.unit errts+tlrc functional.nii'
+
+
+    """
+
+    input_spec = t_norm_input_spec
+    output_spec = t_norm_output_spec
+    executable = "3dTnorm"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_project.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/t_project.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,29 +1,218 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
+input_fields = [
+    (
+        "in_file",
+        Nifti1,
+        {
+            "help_string": "input file to 3dTproject",
+            "argstr": "-input {in_file}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": 1,
+        },
+    ),
+    (
+        "out_file",
+        NiftiGz,
+        {
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "position": -1,
+            "output_file_template": "{in_file}_tproject",
+        },
+    ),
+    (
+        "censor",
+        File,
+        {
+            "help_string": "Filename of censor .1D time series.\nThis is a file of 1s and 0s, indicating which\ntime points are to be included (1) and which are\nto be excluded (0).",
+            "argstr": "-censor {censor}",
+        },
+    ),
+    (
+        "censortr",
+        list,
+        {
+            "help_string": "List of strings that specify time indexes\nto be removed from the analysis.  Each string is\nof one of the following forms:\n\n* ``37`` => remove global time index #37\n* ``2:37`` => remove time index #37 in run #2\n* ``37..47`` => remove global time indexes #37-47\n* ``37-47`` => same as above\n* ``2:37..47`` => remove time indexes #37-47 in run #2\n* ``*:0-2`` => remove time indexes #0-2 in all runs\n\n  * Time indexes within each run start at 0.\n  * Run indexes start at 1 (just be to confusing).\n  * N.B.: 2:37,47 means index #37 in run #2 and\n    global time index 47; it does NOT mean\n    index #37 in run #2 AND index #47 in run #2.\n\n",
+            "argstr": "-CENSORTR {censortr}",
+        },
+    ),
+    (
+        "cenmode",
+        ty.Any,
+        {
+            "help_string": "Specifies how censored time points are treated in\nthe output dataset:\n\n* mode = ZERO -- put zero values in their place;\n  output dataset is same length as input\n* mode = KILL -- remove those time points;\n  output dataset is shorter than input\n* mode = NTRP -- censored values are replaced by interpolated\n  neighboring (in time) non-censored values,\n  BEFORE any projections, and then the\n  analysis proceeds without actual removal\n  of any time points -- this feature is to\n  keep the Spanish Inquisition happy.\n* The default mode is KILL !!!\n\n",
+            "argstr": "-cenmode {cenmode}",
+        },
+    ),
+    (
+        "concat",
+        File,
+        {
+            "help_string": "The catenation file, as in 3dDeconvolve, containing the\nTR indexes of the start points for each contiguous run\nwithin the input dataset (the first entry should be 0).\n\n* Also as in 3dDeconvolve, if the input dataset is\n  automatically catenated from a collection of datasets,\n  then the run start indexes are determined directly,\n  and '-concat' is not needed (and will be ignored).\n* Each run must have at least 9 time points AFTER\n  censoring, or the program will not work!\n* The only use made of this input is in setting up\n  the bandpass/stopband regressors.\n* '-ort' and '-dsort' regressors run through all time\n  points, as read in.  If you want separate projections\n  in each run, then you must either break these ort files\n  into appropriate components, OR you must run 3dTproject\n  for each run separately, using the appropriate pieces\n  from the ort files via the ``{...}`` selector for the\n  1D files and the ``[...]`` selector for the datasets.\n\n",
+            "argstr": "-concat {concat}",
+        },
+    ),
+    (
+        "noblock",
+        bool,
+        {
+            "help_string": "Also as in 3dDeconvolve, if you want the program to treat\nan auto-catenated dataset as one long run, use this option.\nHowever, '-noblock' will not affect catenation if you use\nthe '-concat' option.",
+            "argstr": "-noblock",
+        },
+    ),
+    (
+        "ort",
+        File,
+        {
+            "help_string": "Remove each column in file.\nEach column will have its mean removed.",
+            "argstr": "-ort {ort}",
+        },
+    ),
+    (
+        "polort",
+        int,
+        {
+            "help_string": "Remove polynomials up to and including degree pp.\n\n* Default value is 2.\n* It makes no sense to use a value of pp greater than\n  2, if you are bandpassing out the lower frequencies!\n* For catenated datasets, each run gets a separate set\n  set of pp+1 Legendre polynomial regressors.\n* Use of -polort -1 is not advised (if data mean != 0),\n  even if -ort contains constant terms, as all means are\n  removed.\n\n",
+            "argstr": "-polort {polort}",
+        },
+    ),
+    (
+        "dsort",
+        ty.List[File],
+        {
+            "help_string": "Remove the 3D+time time series in dataset fset.\n\n* That is, 'fset' contains a different nuisance time\n  series for each voxel (e.g., from AnatICOR).\n* Multiple -dsort options are allowed.\n\n",
+            "argstr": "-dsort {dsort}...",
+        },
+    ),
+    (
+        "bandpass",
+        ty.Any,
+        {
+            "help_string": "Remove all frequencies EXCEPT those in the range",
+            "argstr": "-bandpass {bandpass[0]} {bandpass[1]}",
+        },
+    ),
+    (
+        "stopband",
+        ty.Any,
+        {
+            "help_string": "Remove all frequencies in the range",
+            "argstr": "-stopband {stopband[0]} {stopband[1]}",
+        },
+    ),
+    (
+        "TR",
+        float,
+        {
+            "help_string": "Use time step dd for the frequency calculations,\nrather than the value stored in the dataset header.",
+            "argstr": "-TR {TR}",
+        },
+    ),
+    (
+        "mask",
+        File,
+        {
+            "help_string": "Only operate on voxels nonzero in the mset dataset.\n\n* Voxels outside the mask will be filled with zeros.\n* If no masking option is given, then all voxels\n  will be processed.\n\n",
+            "argstr": "-mask {mask}",
+        },
+    ),
+    (
+        "automask",
+        bool,
+        {
+            "help_string": "Generate a mask automatically",
+            "argstr": "-automask",
+            "xor": ["mask"],
+        },
+    ),
+    (
+        "blur",
+        float,
+        {
+            "help_string": "Blur (inside the mask only) with a filter that has\nwidth (FWHM) of fff millimeters.\nSpatial blurring (if done) is after the time\nseries filtering.",
+            "argstr": "-blur {blur}",
+        },
+    ),
+    (
+        "norm",
+        bool,
+        {
+            "help_string": "\nNormalize each output time series to have sum of\nsquares = 1. This is the LAST operation.",
+            "argstr": "-norm",
+        },
+    ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+t_project_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+t_project_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class t_project(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.preprocess.t_project import t_project
+
+    >>> task = t_project()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = NiftiGz.mock(None)
+    >>> task.inputs.censor = File.mock()
+    >>> task.inputs.concat = File.mock()
+    >>> task.inputs.ort = File.mock()
+    >>> task.inputs.polort = 3
+    >>> task.inputs.bandpass = (0.00667, 99999)
+    >>> task.inputs.mask = File.mock()
+    >>> task.inputs.automask = True
+    >>> task.cmdline
+    '3dTproject -input functional.nii -automask -bandpass 0.00667 99999 -polort 3 -prefix projected.nii.gz'
+
+
+    """
+
+    input_spec = t_project_input_spec
+    output_spec = t_project_output_spec
+    executable = "3dTproject"
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dTproject",
             "argstr": "-input {in_file}",
             "copyfile": False,
             "mandatory": True,
             "position": 1,
         },
     ),
     (
         "out_file",
-        Path,
+        NiftiGz,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "position": -1,
             "output_file_template": "{in_file}_tproject",
         },
     ),
@@ -163,27 +352,27 @@
 
 class TProject(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.t_project import TProject
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.preprocess.t_project import TProject
 
     >>> task = TProject()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""projected.nii.gz""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = NiftiGz.mock(None)
     >>> task.inputs.censor = File.mock()
     >>> task.inputs.concat = File.mock()
     >>> task.inputs.ort = File.mock()
-    >>> task.inputs.polort = "3"
-    >>> task.inputs.bandpass = "(0.00667, 99999)"
+    >>> task.inputs.polort = 3
+    >>> task.inputs.bandpass = (0.00667, 99999)
     >>> task.inputs.mask = File.mock()
-    >>> task.inputs.automask = "True"
+    >>> task.inputs.automask = True
     >>> task.cmdline
     '3dTproject -input functional.nii -automask -bandpass 0.00667 99999 -polort 3 -prefix projected.nii.gz'
 
 
     """
 
     input_spec = TProject_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_shift.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/nwarp_apply.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,188 +1,234 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
-        Nifti1,
+        ty.Any,
+        {
+            "help_string": "the name of the dataset to be warped can be multiple datasets",
+            "argstr": "-source {in_file}",
+            "mandatory": True,
+        },
+    ),
+    (
+        "warp",
+        ty.Any,
         {
-            "help_string": "input file to 3dTshift",
-            "argstr": "{in_file}",
-            "copyfile": False,
+            "help_string": "the name of the warp dataset. multiple warps can be concatenated (make sure they exist)",
+            "argstr": "-nwarp {warp}",
             "mandatory": True,
-            "position": -1,
+        },
+    ),
+    (
+        "inv_warp",
+        bool,
+        {
+            "help_string": "After the warp specified in '-nwarp' is computed, invert it",
+            "argstr": "-iwarp",
+        },
+    ),
+    (
+        "master",
+        File,
+        {
+            "help_string": "the name of the master dataset, which defines the output grid",
+            "argstr": "-master {master}",
+        },
+    ),
+    (
+        "interp",
+        ty.Any,
+        "wsinc5",
+        {
+            "help_string": "defines interpolation method to use during warp",
+            "argstr": "-interp {interp}",
+        },
+    ),
+    (
+        "ainterp",
+        ty.Any,
+        {
+            "help_string": "specify a different interpolation method than might be used for the warp",
+            "argstr": "-ainterp {ainterp}",
         },
     ),
     (
         "out_file",
         Path,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_tshift",
+            "output_file_template": "{in_file}_Nwarp",
         },
     ),
     (
-        "tr",
-        str,
+        "short",
+        bool,
         {
-            "help_string": 'manually set the TR. You can attach suffix "s" for seconds or "ms" for milliseconds.',
-            "argstr": "-TR {tr}",
+            "help_string": "Write output dataset using 16-bit short integers, rather than the usual 32-bit floats.",
+            "argstr": "-short",
         },
     ),
     (
-        "tzero",
-        float,
+        "quiet",
+        bool,
+        {"help_string": "don't be verbose :(", "argstr": "-quiet", "xor": ["verb"]},
+    ),
+    (
+        "verb",
+        bool,
+        {"help_string": "be extra verbose :)", "argstr": "-verb", "xor": ["quiet"]},
+    ),
+]
+nwarp_apply_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+nwarp_apply_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class nwarp_apply(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from pydra.tasks.afni.auto.utils.nwarp_apply import nwarp_apply
+
+    >>> task = nwarp_apply()
+    >>> task.inputs.in_file = "Fred+orig"
+    >>> task.inputs.warp = "'Fred_WARP+tlrc Fred.Xaff12.1D'"
+    >>> task.inputs.master = File.mock(None)
+    >>> task.cmdline
+    '3dNwarpApply -source Fred+orig -interp wsinc5 -master NWARP -prefix Fred+orig_Nwarp -nwarp "Fred_WARP+tlrc Fred.Xaff12.1D"'
+
+
+    """
+
+    input_spec = nwarp_apply_input_spec
+    output_spec = nwarp_apply_output_spec
+    executable = "3dNwarpApply"
+
+
+input_fields = [
+    (
+        "in_file",
+        ty.Any,
         {
-            "help_string": "align each slice to given time offset",
-            "argstr": "-tzero {tzero}",
-            "xor": ["tslice"],
+            "help_string": "the name of the dataset to be warped can be multiple datasets",
+            "argstr": "-source {in_file}",
+            "mandatory": True,
         },
     ),
     (
-        "tslice",
-        int,
+        "warp",
+        ty.Any,
         {
-            "help_string": "align each slice to time offset of given slice",
-            "argstr": "-slice {tslice}",
-            "xor": ["tzero"],
+            "help_string": "the name of the warp dataset. multiple warps can be concatenated (make sure they exist)",
+            "argstr": "-nwarp {warp}",
+            "mandatory": True,
         },
     ),
     (
-        "ignore",
-        int,
+        "inv_warp",
+        bool,
         {
-            "help_string": "ignore the first set of points specified",
-            "argstr": "-ignore {ignore}",
+            "help_string": "After the warp specified in '-nwarp' is computed, invert it",
+            "argstr": "-iwarp",
         },
     ),
     (
-        "interp",
-        ty.Any,
+        "master",
+        File,
         {
-            "help_string": "different interpolation methods (see 3dTshift for details) default = Fourier",
-            "argstr": "-{interp}",
+            "help_string": "the name of the master dataset, which defines the output grid",
+            "argstr": "-master {master}",
         },
     ),
     (
-        "tpattern",
+        "interp",
         ty.Any,
+        "wsinc5",
         {
-            "help_string": "use specified slice time pattern rather than one in header",
-            "argstr": "-tpattern {tpattern}",
-            "xor": ["slice_timing"],
+            "help_string": "defines interpolation method to use during warp",
+            "argstr": "-interp {interp}",
         },
     ),
     (
-        "slice_timing",
+        "ainterp",
         ty.Any,
         {
-            "help_string": "time offsets from the volume acquisition onset for each slice",
-            "argstr": "-tpattern @{slice_timing}",
-            "xor": ["tpattern"],
+            "help_string": "specify a different interpolation method than might be used for the warp",
+            "argstr": "-ainterp {ainterp}",
         },
     ),
     (
-        "slice_encoding_direction",
-        ty.Any,
-        "k",
+        "out_file",
+        Path,
         {
-            "help_string": "Direction in which slice_timing is specified (default: k). If negative,slice_timing is defined in reverse order, that is, the first entry corresponds to the slice with the largest index, and the final entry corresponds to slice index zero. Only in effect when slice_timing is passed as list, not when it is passed as file."
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_file}_Nwarp",
         },
     ),
     (
-        "rlt",
+        "short",
         bool,
         {
-            "help_string": "Before shifting, remove the mean and linear trend",
-            "argstr": "-rlt",
+            "help_string": "Write output dataset using 16-bit short integers, rather than the usual 32-bit floats.",
+            "argstr": "-short",
         },
     ),
     (
-        "rltplus",
+        "quiet",
         bool,
-        {
-            "help_string": "Before shifting, remove the mean and linear trend and later put back the mean",
-            "argstr": "-rlt+",
-        },
+        {"help_string": "don't be verbose :(", "argstr": "-quiet", "xor": ["verb"]},
+    ),
+    (
+        "verb",
+        bool,
+        {"help_string": "be extra verbose :)", "argstr": "-verb", "xor": ["quiet"]},
     ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-TShift_input_spec = specs.SpecInfo(
+NwarpApply_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [
-    (
-        "timing_file",
-        File,
-        {"help_string": "AFNI formatted timing file, if ``slice_timing`` is a list"},
-    )
-]
-TShift_output_spec = specs.SpecInfo(
+output_fields = []
+NwarpApply_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class TShift(ShellCommandTask):
+class NwarpApply(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.t_shift import TShift
-
-    >>> task = TShift()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.tr = ""%.1fs" % TR"
-    >>> task.inputs.tzero = "0.0"
-    >>> task.inputs.slice_timing = "list(np.arange(40) / TR)"
-    >>> task.cmdline
-    '3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii'
-
-
-    >>> task = TShift()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.slice_encoding_direction = ""k-""
-    >>> task.cmdline
-    '3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii" >>> np.loadtxt(tshift._list_outputs()["timing_file'
-
-
-    >>> task = TShift()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.tr = ""%.1fs" % TR"
-    >>> task.inputs.tzero = "0.0"
-    >>> task.inputs.slice_timing = ""slice_timing.1D""
-    >>> task.cmdline
-    '3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii'
-
-
-    >>> task = TShift()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.tr = ""%.1fs" % TR"
-    >>> task.inputs.tzero = "0.0"
-    >>> task.inputs.tpattern = ""alt+z""
-    >>> task.cmdline
-    '3dTshift -prefix functional_tshift -tpattern alt+z -TR 2.5s -tzero 0.0 functional.nii'
-
+    >>> from pydra.tasks.afni.auto.utils.nwarp_apply import NwarpApply
 
-    >>> task = TShift()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.tr = ""%.1fs" % TR"
-    >>> task.inputs.tzero = "0.0"
-    >>> task.inputs.tpattern = ""@slice_timing.1D""
+    >>> task = NwarpApply()
+    >>> task.inputs.in_file = "Fred+orig"
+    >>> task.inputs.warp = "'Fred_WARP+tlrc Fred.Xaff12.1D'"
+    >>> task.inputs.master = File.mock(None)
     >>> task.cmdline
-    '3dTshift -prefix functional_tshift -tpattern @slice_timing.1D -TR 2.5s -tzero 0.0 functional.nii'
+    '3dNwarpApply -source Fred+orig -interp wsinc5 -master NWARP -prefix Fred+orig_Nwarp -nwarp "Fred_WARP+tlrc Fred.Xaff12.1D"'
 
 
     """
 
-    input_spec = TShift_input_spec
-    output_spec = TShift_output_spec
-    executable = "3dTshift"
+    input_spec = NwarpApply_input_spec
+    output_spec = NwarpApply_output_spec
+    executable = "3dNwarpApply"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/t_smooth.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/a_boverlap.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,132 +1,188 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1
+from fileformats.text import TextFile
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
+        "in_file_a",
         Nifti1,
         {
-            "help_string": "input file to 3dTSmooth",
-            "argstr": "{in_file}",
+            "help_string": "input file A",
+            "argstr": "{in_file_a}",
             "copyfile": False,
             "mandatory": True,
-            "position": -1,
+            "position": -3,
         },
     ),
     (
-        "out_file",
-        Path,
+        "in_file_b",
+        Nifti1,
         {
-            "help_string": "output file from 3dTSmooth",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_smooth",
+            "help_string": "input file B",
+            "argstr": "{in_file_b}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "datum",
-        str,
+        "out_file",
+        TextFile,
         {
-            "help_string": "Sets the data type of the output dataset",
-            "argstr": "-datum {datum}",
+            "help_string": "collect output to a file",
+            "argstr": " |& tee {out_file}",
+            "position": -1,
         },
     ),
     (
-        "lin",
+        "no_automask",
         bool,
-        {
-            "help_string": "3 point linear filter: :math:`0.15\\,a + 0.70\\,b + 0.15\\,c` [This is the default smoother]",
-            "argstr": "-lin",
-        },
+        {"help_string": "consider input datasets as masks", "argstr": "-no_automask"},
     ),
     (
-        "med",
+        "quiet",
         bool,
-        {"help_string": "3 point median filter: median(a,b,c)", "argstr": "-med"},
+        {
+            "help_string": "be as quiet as possible (without being entirely mute)",
+            "argstr": "-quiet",
+        },
     ),
     (
-        "osf",
+        "verb",
         bool,
         {
-            "help_string": "3 point order statistics filter::math:`0.15\\,min(a,b,c) + 0.70\\,median(a,b,c) + 0.15\\,max(a,b,c)`",
-            "argstr": "-osf",
+            "help_string": "print out some progress reports (to stderr)",
+            "argstr": "-verb",
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+a_boverlap_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [("out_file", TextFile, {"help_string": "output file"})]
+a_boverlap_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class a_boverlap(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.text import TextFile
+    >>> from pydra.tasks.afni.auto.utils.a_boverlap import a_boverlap
+
+    >>> task = a_boverlap()
+    >>> task.inputs.in_file_a = Nifti1.mock(None)
+    >>> task.inputs.in_file_b = Nifti1.mock(None)
+    >>> task.inputs.out_file = TextFile.mock(None)
+    >>> task.cmdline
+    '3dABoverlap functional.nii structural.nii |& tee out.mask_ae_overlap.txt'
+
+
+    """
+
+    input_spec = a_boverlap_input_spec
+    output_spec = a_boverlap_output_spec
+    executable = "3dABoverlap"
+
+
+input_fields = [
     (
-        "lin3",
-        int,
+        "in_file_a",
+        Nifti1,
         {
-            "help_string": "3 point linear filter: :math:`0.5\\,(1-m)\\,a + m\\,b + 0.5\\,(1-m)\\,c`. Here, 'm' is a number strictly between 0 and 1.",
-            "argstr": "-3lin {lin3}",
+            "help_string": "input file A",
+            "argstr": "{in_file_a}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -3,
         },
     ),
     (
-        "hamming",
-        int,
+        "in_file_b",
+        Nifti1,
         {
-            "help_string": "Use N point Hamming windows. (N must be odd and bigger than 1.)",
-            "argstr": "-hamming {hamming}",
+            "help_string": "input file B",
+            "argstr": "{in_file_b}",
+            "copyfile": False,
+            "mandatory": True,
+            "position": -2,
         },
     ),
     (
-        "blackman",
-        int,
+        "out_file",
+        TextFile,
         {
-            "help_string": "Use N point Blackman windows. (N must be odd and bigger than 1.)",
-            "argstr": "-blackman {blackman}",
+            "help_string": "collect output to a file",
+            "argstr": " |& tee {out_file}",
+            "position": -1,
         },
     ),
     (
-        "custom",
-        File,
+        "no_automask",
+        bool,
+        {"help_string": "consider input datasets as masks", "argstr": "-no_automask"},
+    ),
+    (
+        "quiet",
+        bool,
         {
-            "help_string": "odd # of coefficients must be in a single column in ASCII file",
-            "argstr": "-custom {custom}",
+            "help_string": "be as quiet as possible (without being entirely mute)",
+            "argstr": "-quiet",
         },
     ),
     (
-        "adaptive",
-        int,
+        "verb",
+        bool,
         {
-            "help_string": "use adaptive mean filtering of width N (where N must be odd and bigger than 3).",
-            "argstr": "-adaptive {adaptive}",
+            "help_string": "print out some progress reports (to stderr)",
+            "argstr": "-verb",
         },
     ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-TSmooth_input_spec = specs.SpecInfo(
+ABoverlap_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-TSmooth_output_spec = specs.SpecInfo(
+output_fields = [("out_file", TextFile, {"help_string": "output file"})]
+ABoverlap_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class TSmooth(ShellCommandTask):
+class ABoverlap(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.t_smooth import TSmooth
-
-    >>> task = TSmooth()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.custom = File.mock()
-    >>> task.inputs.adaptive = "5"
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.text import TextFile
+    >>> from pydra.tasks.afni.auto.utils.a_boverlap import ABoverlap
+
+    >>> task = ABoverlap()
+    >>> task.inputs.in_file_a = Nifti1.mock(None)
+    >>> task.inputs.in_file_b = Nifti1.mock(None)
+    >>> task.inputs.out_file = TextFile.mock(None)
     >>> task.cmdline
-    '3dTsmooth -adaptive 5 -prefix functional_smooth functional.nii'
+    '3dABoverlap functional.nii structural.nii |& tee out.mask_ae_overlap.txt'
 
 
     """
 
-    input_spec = TSmooth_input_spec
-    output_spec = TSmooth_output_spec
-    executable = "3dTsmooth"
+    input_spec = ABoverlap_input_spec
+    output_spec = ABoverlap_output_spec
+    executable = "3dABoverlap"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/undump.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/fwh_mx.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,120 +1,166 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
-            "help_string": "input file to 3dUndump, whose geometry will determinethe geometry of the output",
-            "argstr": "-master {in_file}",
-            "copyfile": False,
+            "help_string": "input dataset",
+            "argstr": "-input {in_file}",
             "mandatory": True,
-            "position": -1,
         },
     ),
     (
         "out_file",
         Path,
-        {"help_string": "output image file name", "argstr": "-prefix {out_file}"},
+        {
+            "help_string": "output file",
+            "argstr": "> {out_file}",
+            "position": -1,
+            "output_file_template": "{in_file}_fwhmx.out",
+        },
     ),
     (
-        "mask_file",
+        "out_subbricks",
+        Path,
+        {
+            "help_string": "output file listing the subbricks FWHM",
+            "argstr": "-out {out_subbricks}",
+            "output_file_template": "{in_file}_subbricks.out",
+        },
+    ),
+    (
+        "mask",
         File,
         {
-            "help_string": "mask image file name. Only voxels that are nonzero in the mask can be set.",
-            "argstr": "-mask {mask_file}",
+            "help_string": "use only voxels that are nonzero in mask",
+            "argstr": "-mask {mask}",
+        },
+    ),
+    (
+        "automask",
+        bool,
+        False,
+        {
+            "help_string": "compute a mask from THIS dataset, a la 3dAutomask",
+            "argstr": "-automask",
         },
     ),
     (
-        "datatype",
+        "detrend",
         ty.Any,
-        {"help_string": "set output file datatype", "argstr": "-datum {datatype}"},
+        False,
+        {
+            "help_string": "instead of demed (0th order detrending), detrend to the specified order.  If order is not given, the program picks q=NT/30. -detrend disables -demed, and includes -unif.",
+            "argstr": "-detrend",
+            "xor": ["demed"],
+        },
     ),
     (
-        "default_value",
-        float,
+        "demed",
+        bool,
         {
-            "help_string": "default value stored in each input voxel that does not have a value supplied in the input file",
-            "argstr": "-dval {default_value}",
+            "help_string": "If the input dataset has more than one sub-brick (e.g., has a time axis), then subtract the median of each voxel's time series before processing FWHM. This will tend to remove intrinsic spatial structure and leave behind the noise.",
+            "argstr": "-demed",
+            "xor": ["detrend"],
         },
     ),
     (
-        "fill_value",
-        float,
+        "unif",
+        bool,
         {
-            "help_string": "value, used for each voxel in the output dataset that is NOT listed in the input file",
-            "argstr": "-fval {fill_value}",
+            "help_string": "If the input dataset has more than one sub-brick, then normalize each voxel's time series to have the same MAD before processing FWHM.",
+            "argstr": "-unif",
         },
     ),
     (
-        "coordinates_specification",
-        ty.Any,
+        "out_detrend",
+        Path,
         {
-            "help_string": "Coordinates in the input file as index triples (i, j, k) or spatial coordinates (x, y, z) in mm",
-            "argstr": "-{coordinates_specification}",
+            "help_string": "Save the detrended file into a dataset",
+            "argstr": "-detprefix {out_detrend}",
+            "output_file_template": "{in_file}_detrend",
         },
     ),
     (
-        "srad",
-        float,
+        "geom",
+        bool,
         {
-            "help_string": "radius in mm of the sphere that will be filled about each input (x,y,z) or (i,j,k) voxel. If the radius is not given, or is 0, then each input data line sets the value in only one voxel.",
-            "argstr": "-srad {srad}",
+            "help_string": "if in_file has more than one sub-brick, compute the final estimate as the geometric mean of the individual sub-brick FWHM estimates",
+            "argstr": "-geom",
+            "xor": ["arith"],
         },
     ),
     (
-        "orient",
-        ty.Any,
+        "arith",
+        bool,
         {
-            "help_string": "Specifies the coordinate order used by -xyz. The code must be 3 letters, one each from the pairs {R,L} {A,P} {I,S}.  The first letter gives the orientation of the x-axis, the second the orientation of the y-axis, the third the z-axis: R = right-to-left         L = left-to-right A = anterior-to-posterior P = posterior-to-anterior I = inferior-to-superior  S = superior-to-inferior If -orient isn't used, then the coordinate order of the -master (in_file) dataset is used to interpret (x,y,z) inputs.",
-            "argstr": "-orient {orient}",
+            "help_string": "if in_file has more than one sub-brick, compute the final estimate as the arithmetic mean of the individual sub-brick FWHM estimates",
+            "argstr": "-arith",
+            "xor": ["geom"],
         },
     ),
     (
-        "head_only",
+        "combine",
         bool,
         {
-            "help_string": "create only the .HEAD file which gets exploited by the AFNI matlab library function New_HEAD.m",
-            "argstr": "-head_only",
+            "help_string": "combine the final measurements along each axis",
+            "argstr": "-combine",
         },
     ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+    (
+        "compat",
+        bool,
+        {"help_string": "be compatible with the older 3dFWHM", "argstr": "-compat"},
+    ),
+    (
+        "acf",
+        ty.Any,
+        False,
+        {"help_string": "computes the spatial autocorrelation", "argstr": "-acf"},
+    ),
 ]
-Undump_input_spec = specs.SpecInfo(
+FWHMx_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("out_file", Nifti1, {"help_string": "assembled file"})]
-Undump_output_spec = specs.SpecInfo(
+output_fields = [
+    ("fwhm", ty.Any, {"help_string": "FWHM along each axis"}),
+    ("acf_param", ty.Any, {"help_string": "fitted ACF model parameters"}),
+    ("out_acf", File, {"help_string": "output acf file"}),
+]
+FWHMx_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Undump(ShellCommandTask):
+class FWHMx(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.undump import Undump
+    >>> from fileformats.medimage import Nifti1
+    >>> from pydra.tasks.afni.auto.utils.fwh_mx import FWHMx
 
-    >>> task = Undump()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""structural_undumped.nii""
-    >>> task.inputs.mask_file = File.mock()
+    >>> task = FWHMx()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = File.mock()
     >>> task.cmdline
-    '3dUndump -prefix structural_undumped.nii -master structural.nii'
+    '3dFWHMx -input functional.nii -out functional_subbricks.out > functional_fwhmx.out'
 
 
     """
 
-    input_spec = Undump_input_spec
-    output_spec = Undump_output_spec
-    executable = "3dUndump"
+    input_spec = FWHMx_input_spec
+    output_spec = FWHMx_output_spec
+    executable = "3dFWHMx"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/unifize.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/nwarp_cat.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,141 +1,177 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
-        Nifti1,
+        "in_files",
+        list,
         {
-            "help_string": "input file to 3dUnifize",
-            "argstr": "-input {in_file}",
-            "copyfile": False,
+            "help_string": "list of tuples of 3D warps and associated functions",
+            "argstr": "{in_files}",
             "mandatory": True,
             "position": -1,
         },
     ),
     (
-        "out_file",
-        Path,
+        "space",
+        ty.Any,
         {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_unifized",
+            "help_string": "string to attach to the output dataset as its atlas space marker.",
+            "argstr": "-space {space}",
         },
     ),
     (
-        "t2",
+        "inv_warp",
         bool,
-        {
-            "help_string": "Treat the input as if it were T2-weighted, rather than T1-weighted. This processing is done simply by inverting the image contrast, processing it as if that result were T1-weighted, and then re-inverting the results counts of voxel overlap, i.e., each voxel will contain the number of masks that it is set in.",
-            "argstr": "-T2",
-        },
+        {"help_string": "invert the final warp before output", "argstr": "-iwarp"},
     ),
     (
-        "gm",
-        bool,
+        "interp",
+        ty.Any,
+        "wsinc5",
         {
-            "help_string": "Also scale to unifize 'gray matter' = lower intensity voxels (to aid in registering images from different scanners).",
-            "argstr": "-GM",
+            "help_string": "specify a different interpolation method than might be used for the warp",
+            "argstr": "-interp {interp}",
         },
     ),
     (
-        "urad",
-        float,
+        "expad",
+        int,
         {
-            "help_string": "Sets the radius (in voxels) of the ball used for the sneaky trick. Default value is 18.3, and should be changed proportionally if the dataset voxel size differs significantly from 1 mm.",
-            "argstr": "-Urad {urad}",
+            "help_string": "Pad the nonlinear warps by the given number of voxels in all directions. The warp displacements are extended by linear extrapolation from the faces of the input grid..",
+            "argstr": "-expad {expad}",
         },
     ),
     (
-        "scale_file",
+        "out_file",
         Path,
         {
-            "help_string": "output file name to save the scale factor used at each voxel ",
-            "argstr": "-ssave {scale_file}",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_files}_NwarpCat",
         },
     ),
+    ("verb", bool, {"help_string": "be verbose", "argstr": "-verb"}),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+nwarp_cat_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+nwarp_cat_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class nwarp_cat(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from pydra.tasks.afni.auto.utils.nwarp_cat import nwarp_cat
+
+    >>> task = nwarp_cat()
+    >>> task.inputs.in_files = ["Q25_warp+tlrc.HEAD", ("IDENT", "structural.nii")]
+    >>> task.inputs.out_file = None
+    >>> task.cmdline
+    '3dNwarpCat -interp wsinc5 -prefix Fred_total_WARP Q25_warp+tlrc.HEAD "IDENT(structural.nii)"'
+
+
+    """
+
+    input_spec = nwarp_cat_input_spec
+    output_spec = nwarp_cat_output_spec
+    executable = "3dNwarpCat"
+
+
+input_fields = [
     (
-        "no_duplo",
-        bool,
+        "in_files",
+        list,
         {
-            "help_string": "Do NOT use the 'duplo down' step; this can be useful for lower resolution datasets.",
-            "argstr": "-noduplo",
+            "help_string": "list of tuples of 3D warps and associated functions",
+            "argstr": "{in_files}",
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "epi",
-        bool,
+        "space",
+        ty.Any,
         {
-            "help_string": "Assume the input dataset is a T2 (or T2\\*) weighted EPI time series. After computing the scaling, apply it to ALL volumes (TRs) in the input dataset. That is, a given voxel will be scaled by the same factor at each TR. This option also implies '-noduplo' and '-T2'.This option turns off '-GM' if you turned it on.",
-            "argstr": "-EPI",
-            "requires": ["no_duplo", "t2"],
-            "xor": ["gm"],
+            "help_string": "string to attach to the output dataset as its atlas space marker.",
+            "argstr": "-space {space}",
         },
     ),
     (
-        "rbt",
+        "inv_warp",
+        bool,
+        {"help_string": "invert the final warp before output", "argstr": "-iwarp"},
+    ),
+    (
+        "interp",
         ty.Any,
+        "wsinc5",
         {
-            "help_string": "Option for AFNI experts only.Specify the 3 parameters for the algorithm:\nR = radius; same as given by option '-Urad', [default=18.3]\nb = bottom percentile of normalizing data range, [default=70.0]\nr = top percentile of normalizing data range, [default=80.0]\n",
-            "argstr": "-rbt {rbt[0]} {rbt[1]} {rbt[2]}",
+            "help_string": "specify a different interpolation method than might be used for the warp",
+            "argstr": "-interp {interp}",
         },
     ),
     (
-        "t2_up",
-        float,
+        "expad",
+        int,
         {
-            "help_string": "Option for AFNI experts only.Set the upper percentile point used for T2-T1 inversion. Allowed to be anything between 90 and 100 (inclusive), with default to 98.5  (for no good reason).",
-            "argstr": "-T2up {t2_up}",
+            "help_string": "Pad the nonlinear warps by the given number of voxels in all directions. The warp displacements are extended by linear extrapolation from the faces of the input grid..",
+            "argstr": "-expad {expad}",
         },
     ),
     (
-        "cl_frac",
-        float,
+        "out_file",
+        Path,
         {
-            "help_string": "Option for AFNI experts only.Set the automask 'clip level fraction'. Must be between 0.1 and 0.9. A small fraction means to make the initial threshold for clipping (a la 3dClipLevel) smaller, which will tend to make the mask larger.  [default=0.1]",
-            "argstr": "-clfrac {cl_frac}",
+            "help_string": "output image file name",
+            "argstr": "-prefix {out_file}",
+            "output_file_template": "{in_files}_NwarpCat",
         },
     ),
-    (
-        "quiet",
-        bool,
-        {"help_string": "Don't print the progress messages.", "argstr": "-quiet"},
-    ),
+    ("verb", bool, {"help_string": "be verbose", "argstr": "-verb"}),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Unifize_input_spec = specs.SpecInfo(
+NwarpCat_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("scale_file", File, {"help_string": "scale factor file"})]
-Unifize_output_spec = specs.SpecInfo(
+output_fields = []
+NwarpCat_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Unifize(ShellCommandTask):
+class NwarpCat(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.unifize import Unifize
-
-    >>> task = Unifize()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""structural_unifized.nii""
+    >>> from pydra.tasks.afni.auto.utils.nwarp_cat import NwarpCat
+
+    >>> task = NwarpCat()
+    >>> task.inputs.in_files = ["Q25_warp+tlrc.HEAD", ("IDENT", "structural.nii")]
+    >>> task.inputs.out_file = None
     >>> task.cmdline
-    '3dUnifize -prefix structural_unifized.nii -input structural.nii'
+    '3dNwarpCat -interp wsinc5 -prefix Fred_total_WARP Q25_warp+tlrc.HEAD "IDENT(structural.nii)"'
 
 
     """
 
-    input_spec = Unifize_input_spec
-    output_spec = Unifize_output_spec
-    executable = "3dUnifize"
+    input_spec = NwarpCat_input_spec
+    output_spec = NwarpCat_output_spec
+    executable = "3dNwarpCat"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/volreg.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/volreg.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,18 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD, R1
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
         "in_file",
         Nifti1,
         {
             "help_string": "input file to 3dvolreg",
             "argstr": "{in_file}",
@@ -22,15 +27,15 @@
         {
             "help_string": "weights for each voxel specified by a file with an optional volume number (defaults to 0)",
             "argstr": "-weight '{in_weight_volume[0]}[{in_weight_volume[1]}]'",
         },
     ),
     (
         "out_file",
-        Path,
+        R1,
         {
             "help_string": "output image file name",
             "argstr": "-prefix {out_file}",
             "output_file_template": "{in_file}_volreg",
         },
     ),
     (
@@ -59,15 +64,15 @@
             "argstr": "-maxdisp1D {md1d_file}",
             "position": -4,
             "output_file_template": "{in_file}_md.1D",
         },
     ),
     (
         "oned_file",
-        Path,
+        OneD,
         {
             "help_string": "1D movement parameters output file",
             "argstr": "-1Dfile {oned_file}",
             "output_file_template": "{in_file}.1D",
         },
     ),
     (
@@ -86,15 +91,15 @@
     (
         "copyorigin",
         bool,
         {"help_string": "copy base file origin coords to output", "argstr": "-twodup"},
     ),
     (
         "oned_matrix_save",
-        Path,
+        OneD,
         {
             "help_string": "Save the matrix transformation",
             "argstr": "-1Dmatrix_save {oned_matrix_save}",
             "output_file_template": "{in_file}.aff12.1D",
         },
     ),
     (
@@ -119,35 +124,39 @@
 
 
 class Volreg(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.volreg import Volreg
+    >>> from fileformats.medimage import Nifti1
+    >>> from fileformats.medimage_afni import OneD, R1
+    >>> from pydra.tasks.afni.auto.preprocess.volreg import Volreg
 
     >>> task = Volreg()
-    >>> task.inputs.in_file = Nifti1.mock()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = R1.mock()
     >>> task.inputs.basefile = Nifti1.mock()
-    >>> task.inputs.zpad = "4"
-    >>> task.inputs.outputtype = ""NIFTI""
+    >>> task.inputs.zpad = 4
+    >>> task.inputs.oned_file = OneD.mock()
+    >>> task.inputs.oned_matrix_save = OneD.mock()
+    >>> task.inputs.outputtype = "NIFTI"
     >>> task.cmdline
     '3dvolreg -Fourier -twopass -1Dfile functional.1D -1Dmatrix_save functional.aff12.1D -prefix functional_volreg.nii -zpad 4 -maxdisp1D functional_md.1D functional.nii'
 
 
     >>> task = Volreg()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""rm.epi.volreg.r1""
-    >>> task.inputs.basefile = Nifti1.mock()
-    >>> task.inputs.zpad = "1"
-    >>> task.inputs.oned_file = ""dfile.r1.1D""
-    >>> task.inputs.verbose = "True"
-    >>> task.inputs.oned_matrix_save = ""mat.r1.tshift+orig.1D""
-    >>> task.inputs.interp = ""cubic""
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.out_file = R1.mock(None)
+    >>> task.inputs.basefile = Nifti1.mock(None)
+    >>> task.inputs.zpad = 1
+    >>> task.inputs.oned_file = OneD.mock(None)
+    >>> task.inputs.verbose = True
+    >>> task.inputs.oned_matrix_save = OneD.mock(None)
+    >>> task.inputs.interp = "cubic"
     >>> task.cmdline
     '3dvolreg -cubic -1Dfile dfile.r1.1D -1Dmatrix_save mat.r1.tshift+orig.1D -prefix rm.epi.volreg.r1 -verbose -base functional.nii -zpad 1 -maxdisp1D functional_md.1D functional.nii'
 
 
     """
 
     input_spec = Volreg_input_spec
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/warp.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/nwarp_adjust.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,159 +1,135 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import NiftiGz
+import logging
 from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_file",
-        Nifti1,
+        "warps",
+        ty.List[NiftiGz],
         {
-            "help_string": "input file to 3dWarp",
-            "argstr": "{in_file}",
-            "copyfile": False,
+            "help_string": "List of input 3D warp datasets",
+            "argstr": "-nwarp {warps}",
             "mandatory": True,
-            "position": -1,
-        },
-    ),
-    (
-        "out_file",
-        Path,
-        {
-            "help_string": "output image file name",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "{in_file}_warp",
-        },
-    ),
-    (
-        "tta2mni",
-        bool,
-        {
-            "help_string": "transform dataset from Talairach to MNI152",
-            "argstr": "-tta2mni",
-        },
-    ),
-    (
-        "mni2tta",
-        bool,
-        {
-            "help_string": "transform dataset from MNI152 to Talaraich",
-            "argstr": "-mni2tta",
-        },
-    ),
-    (
-        "matparent",
-        File,
-        {
-            "help_string": "apply transformation from 3dWarpDrive",
-            "argstr": "-matparent {matparent}",
-        },
-    ),
-    (
-        "oblique_parent",
-        File,
-        {
-            "help_string": "Read in the oblique transformation matrix from an oblique dataset and make cardinal dataset oblique to match",
-            "argstr": "-oblique_parent {oblique_parent}",
         },
     ),
     (
-        "deoblique",
-        bool,
+        "in_files",
+        ty.List[File],
         {
-            "help_string": "transform dataset from oblique to cardinal",
-            "argstr": "-deoblique",
+            "help_string": "List of input 3D datasets to be warped by the adjusted warp datasets.  There must be exactly as many of these datasets as there are input warps.",
+            "argstr": "-source {in_files}",
         },
     ),
     (
-        "interp",
-        ty.Any,
+        "out_file",
+        Path,
         {
-            "help_string": "spatial interpolation methods [default = linear]",
-            "argstr": "-{interp}",
+            "help_string": "Output mean dataset, only needed if in_files are also given. The output dataset will be on the common grid shared by the source datasets.",
+            "argstr": "-prefix {out_file}",
+            "requires": ["in_files"],
+            "output_file_template": "{in_files}_NwarpAdjust",
         },
     ),
+    ("num_threads", int, 1, {"help_string": "set number of threads"}),
+    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
+]
+nwarp_adjust_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = []
+nwarp_adjust_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class nwarp_adjust(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.generic import File
+    >>> from fileformats.medimage import NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.nwarp_adjust import nwarp_adjust
+
+    >>> task = nwarp_adjust()
+    >>> task.inputs.warps = None
+    >>> task.cmdline
+    '3dNwarpAdjust -nwarp func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz'
+
+
+    """
+
+    input_spec = nwarp_adjust_input_spec
+    output_spec = nwarp_adjust_output_spec
+    executable = "3dNwarpAdjust"
+
+
+input_fields = [
     (
-        "gridset",
-        File,
+        "warps",
+        ty.List[NiftiGz],
         {
-            "help_string": "copy grid of specified dataset",
-            "argstr": "-gridset {gridset}",
+            "help_string": "List of input 3D warp datasets",
+            "argstr": "-nwarp {warps}",
+            "mandatory": True,
         },
     ),
     (
-        "newgrid",
-        float,
+        "in_files",
+        ty.List[File],
         {
-            "help_string": "specify grid of this size (mm)",
-            "argstr": "-newgrid {newgrid}",
+            "help_string": "List of input 3D datasets to be warped by the adjusted warp datasets.  There must be exactly as many of these datasets as there are input warps.",
+            "argstr": "-source {in_files}",
         },
     ),
     (
-        "zpad",
-        int,
+        "out_file",
+        Path,
         {
-            "help_string": "pad input dataset with N planes of zero on all sides.",
-            "argstr": "-zpad {zpad}",
+            "help_string": "Output mean dataset, only needed if in_files are also given. The output dataset will be on the common grid shared by the source datasets.",
+            "argstr": "-prefix {out_file}",
+            "requires": ["in_files"],
+            "output_file_template": "{in_files}_NwarpAdjust",
         },
     ),
-    (
-        "verbose",
-        bool,
-        {"help_string": "Print out some information along the way.", "argstr": "-verb"},
-    ),
-    (
-        "save_warp",
-        bool,
-        {"help_string": "save warp as .mat file", "requires": ["verbose"]},
-    ),
     ("num_threads", int, 1, {"help_string": "set number of threads"}),
     ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Warp_input_spec = specs.SpecInfo(
+NwarpAdjust_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = [("warp_file", File, {"help_string": "warp transform .mat file"})]
-Warp_output_spec = specs.SpecInfo(
+output_fields = []
+NwarpAdjust_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Warp(ShellCommandTask):
+class NwarpAdjust(ShellCommandTask):
     """
     Examples
     -------
 
     >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.warp import Warp
-
-    >>> task = Warp()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""trans.nii.gz""
-    >>> task.inputs.matparent = File.mock()
-    >>> task.inputs.oblique_parent = File.mock()
-    >>> task.inputs.deoblique = "True"
-    >>> task.inputs.gridset = File.mock()
-    >>> task.cmdline
-    '3dWarp -deoblique -prefix trans.nii.gz structural.nii'
-
+    >>> from fileformats.medimage import NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.nwarp_adjust import NwarpAdjust
 
-    >>> task = Warp()
-    >>> task.inputs.in_file = Nifti1.mock()
-    >>> task.inputs.out_file = ""trans.nii.gz""
-    >>> task.inputs.matparent = File.mock()
-    >>> task.inputs.oblique_parent = File.mock()
-    >>> task.inputs.gridset = File.mock()
-    >>> task.inputs.newgrid = "1.0"
+    >>> task = NwarpAdjust()
+    >>> task.inputs.warps = None
     >>> task.cmdline
-    '3dWarp -newgrid 1.000000 -prefix trans.nii.gz structural.nii'
+    '3dNwarpAdjust -nwarp func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz func2anat_InverseWarp.nii.gz'
 
 
     """
 
-    input_spec = Warp_input_spec
-    output_spec = Warp_output_spec
-    executable = "3dWarp"
+    input_spec = NwarpAdjust_input_spec
+    output_spec = NwarpAdjust_output_spec
+    executable = "3dNwarpAdjust"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/zeropad.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/brick_stat.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,177 +1,205 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from pathlib import Path
-from pydra.engine import ShellCommandTask
-from pydra.engine import specs
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
+from pydra.engine import ShellCommandTask, specs
 import typing as ty
 
+
+logger = logging.getLogger(__name__)
+
+
 input_fields = [
     (
-        "in_files",
+        "in_file",
         Nifti1,
         {
-            "help_string": "input dataset",
-            "argstr": "{in_files}",
-            "copyfile": False,
+            "help_string": "input file to 3dmaskave",
+            "argstr": "{in_file}",
             "mandatory": True,
             "position": -1,
         },
     ),
     (
-        "out_file",
-        Path,
+        "mask",
+        NiftiGz,
         {
-            "help_string": "output dataset prefix name (default 'zeropad')",
-            "argstr": "-prefix {out_file}",
-            "output_file_template": "zeropad",
+            "help_string": "-mask dset = use dset as mask to include/exclude voxels",
+            "argstr": "-mask {mask}",
+            "position": 2,
         },
     ),
     (
-        "I",
-        int,
+        "min",
+        bool,
         {
-            "help_string": "adds 'n' planes of zero at the Inferior edge",
-            "argstr": "-I {I}",
-            "xor": ["master"],
+            "help_string": "print the minimum value in dataset",
+            "argstr": "-min",
+            "position": 1,
         },
     ),
     (
-        "S",
-        int,
+        "slow",
+        bool,
         {
-            "help_string": "adds 'n' planes of zero at the Superior edge",
-            "argstr": "-S {S}",
-            "xor": ["master"],
+            "help_string": "read the whole dataset to find the min and max values",
+            "argstr": "-slow",
         },
     ),
     (
-        "A",
-        int,
-        {
-            "help_string": "adds 'n' planes of zero at the Anterior edge",
-            "argstr": "-A {A}",
-            "xor": ["master"],
-        },
+        "max",
+        bool,
+        {"help_string": "print the maximum value in the dataset", "argstr": "-max"},
     ),
     (
-        "P",
-        int,
-        {
-            "help_string": "adds 'n' planes of zero at the Posterior edge",
-            "argstr": "-P {P}",
-            "xor": ["master"],
-        },
+        "mean",
+        bool,
+        {"help_string": "print the mean value in the dataset", "argstr": "-mean"},
     ),
     (
-        "L",
-        int,
-        {
-            "help_string": "adds 'n' planes of zero at the Left edge",
-            "argstr": "-L {L}",
-            "xor": ["master"],
-        },
+        "sum",
+        bool,
+        {"help_string": "print the sum of values in the dataset", "argstr": "-sum"},
     ),
     (
-        "R",
-        int,
-        {
-            "help_string": "adds 'n' planes of zero at the Right edge",
-            "argstr": "-R {R}",
-            "xor": ["master"],
-        },
+        "var",
+        bool,
+        {"help_string": "print the variance in the dataset", "argstr": "-var"},
     ),
     (
-        "z",
-        int,
+        "percentile",
+        ty.Any,
         {
-            "help_string": "adds 'n' planes of zero on EACH of the dataset z-axis (slice-direction) faces",
-            "argstr": "-z {z}",
-            "xor": ["master"],
+            "help_string": "p0 ps p1 write the percentile values starting at p0% and ending at p1% at a step of ps%. only one sub-brick is accepted.",
+            "argstr": "-percentile {percentile[0]:.3} {percentile[1]:.3} {percentile[2]:.3}",
         },
     ),
+]
+BrickStat_input_spec = specs.SpecInfo(
+    name="Input", fields=input_fields, bases=(specs.ShellSpec,)
+)
+
+output_fields = [("min_val", float, {"help_string": "output"})]
+BrickStat_output_spec = specs.SpecInfo(
+    name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
+)
+
+
+class BrickStat(ShellCommandTask):
+    """
+    Examples
+    -------
+
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.brick_stat import BrickStat
+
+    >>> task = BrickStat()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = NiftiGz.mock(None)
+    >>> task.inputs.min = True
+    >>> task.cmdline
+    '3dBrickStat -min -mask skeleton_mask.nii.gz functional.nii'
+
+
+    """
+
+    input_spec = BrickStat_input_spec
+    output_spec = BrickStat_output_spec
+    executable = "3dBrickStat"
+
+
+input_fields = [
     (
-        "RL",
-        int,
+        "in_file",
+        Nifti1,
         {
-            "help_string": "specify that planes should be added or cut symmetrically to make the resulting volume haveN slices in the right-left direction",
-            "argstr": "-RL {RL}",
-            "xor": ["master"],
+            "help_string": "input file to 3dmaskave",
+            "argstr": "{in_file}",
+            "mandatory": True,
+            "position": -1,
         },
     ),
     (
-        "AP",
-        int,
+        "mask",
+        NiftiGz,
         {
-            "help_string": "specify that planes should be added or cut symmetrically to make the resulting volume haveN slices in the anterior-posterior direction",
-            "argstr": "-AP {AP}",
-            "xor": ["master"],
+            "help_string": "-mask dset = use dset as mask to include/exclude voxels",
+            "argstr": "-mask {mask}",
+            "position": 2,
         },
     ),
     (
-        "IS",
-        int,
+        "min",
+        bool,
         {
-            "help_string": "specify that planes should be added or cut symmetrically to make the resulting volume haveN slices in the inferior-superior direction",
-            "argstr": "-IS {IS}",
-            "xor": ["master"],
+            "help_string": "print the minimum value in dataset",
+            "argstr": "-min",
+            "position": 1,
         },
     ),
     (
-        "mm",
+        "slow",
         bool,
         {
-            "help_string": "pad counts 'n' are in mm instead of slices, where each 'n' is an integer and at least 'n' mm of slices will be added/removed; e.g., n =  3 and slice thickness = 2.5 mm ==> 2 slices added",
-            "argstr": "-mm",
-            "xor": ["master"],
+            "help_string": "read the whole dataset to find the min and max values",
+            "argstr": "-slow",
         },
     ),
     (
-        "master",
-        File,
+        "max",
+        bool,
+        {"help_string": "print the maximum value in the dataset", "argstr": "-max"},
+    ),
+    (
+        "mean",
+        bool,
+        {"help_string": "print the mean value in the dataset", "argstr": "-mean"},
+    ),
+    (
+        "sum",
+        bool,
+        {"help_string": "print the sum of values in the dataset", "argstr": "-sum"},
+    ),
+    (
+        "var",
+        bool,
+        {"help_string": "print the variance in the dataset", "argstr": "-var"},
+    ),
+    (
+        "percentile",
+        ty.Any,
         {
-            "help_string": "match the volume described in dataset 'mset', where mset must have the same orientation and grid spacing as dataset to be padded. the goal of -master is to make the output dataset from 3dZeropad match the spatial 'extents' of mset by adding or subtracting slices as needed. You can't use -I,-S,..., or -mm with -master",
-            "argstr": "-master {master}",
-            "xor": ["I", "S", "A", "P", "L", "R", "z", "RL", "AP", "IS", "mm"],
+            "help_string": "p0 ps p1 write the percentile values starting at p0% and ending at p1% at a step of ps%. only one sub-brick is accepted.",
+            "argstr": "-percentile {percentile[0]:.3} {percentile[1]:.3} {percentile[2]:.3}",
         },
     ),
-    ("num_threads", int, 1, {"help_string": "set number of threads"}),
-    ("outputtype", ty.Any, {"help_string": "AFNI output filetype"}),
 ]
-Zeropad_input_spec = specs.SpecInfo(
+brick_stat_input_spec = specs.SpecInfo(
     name="Input", fields=input_fields, bases=(specs.ShellSpec,)
 )
 
-output_fields = []
-Zeropad_output_spec = specs.SpecInfo(
+output_fields = [("min_val", float, {"help_string": "output"})]
+brick_stat_output_spec = specs.SpecInfo(
     name="Output", fields=output_fields, bases=(specs.ShellOutSpec,)
 )
 
 
-class Zeropad(ShellCommandTask):
+class brick_stat(ShellCommandTask):
     """
     Examples
     -------
 
-    >>> from fileformats.generic import File
-    >>> from fileformats.medimage.nifti import Nifti1
-    >>> from pydra.tasks.afni.auto.zeropad import Zeropad
-
-    >>> task = Zeropad()
-    >>> task.inputs.in_files = Nifti1.mock()
-    >>> task.inputs.out_file = ""pad_functional.nii""
-    >>> task.inputs.I = "10"
-    >>> task.inputs.S = "10"
-    >>> task.inputs.A = "10"
-    >>> task.inputs.P = "10"
-    >>> task.inputs.L = "10"
-    >>> task.inputs.R = "10"
-    >>> task.inputs.master = File.mock()
+    >>> from fileformats.medimage import Nifti1, NiftiGz
+    >>> from pydra.tasks.afni.auto.utils.brick_stat import brick_stat
+
+    >>> task = brick_stat()
+    >>> task.inputs.in_file = Nifti1.mock(None)
+    >>> task.inputs.mask = NiftiGz.mock(None)
+    >>> task.inputs.min = True
     >>> task.cmdline
-    '3dZeropad -A 10 -I 10 -L 10 -P 10 -R 10 -S 10 -prefix pad_functional.nii functional.nii'
+    '3dBrickStat -min -mask skeleton_mask.nii.gz functional.nii'
 
 
     """
 
-    input_spec = Zeropad_input_spec
-    output_spec = Zeropad_output_spec
-    executable = "3dZeropad"
+    input_spec = brick_stat_input_spec
+    output_spec = brick_stat_output_spec
+    executable = "3dBrickStat"
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/conftest.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/conftest.py`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_aboverlap.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_lfcd.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,29 +1,32 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.text import TextFile
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.a_boverlap import ABoverlap
+from pydra.tasks.afni.auto.preprocess.lfcd import LFCD
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_aboverlap_1():
-    task = ABoverlap()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.in_file_b = Nifti1.sample(seed=1)
-    task.inputs.no_automask = False
-    task.inputs.quiet = False
-    task.inputs.verb = False
+def test_lfcd_1():
+    task = LFCD()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask = Nifti1.sample(seed=1)
     task.inputs.num_threads = 1
+    task.inputs.out_file = Nifti1.sample(seed=8)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_aboverlap_2():
-    task = ABoverlap()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.in_file_b = Nifti1.sample(seed=1)
+def test_lfcd_2():
+    task = LFCD()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask = Nifti1.sample(seed=1)
+    task.inputs.thresh = 0.8  # keep all connections with corr >= 0.8
+    task.inputs.out_file = Nifti1.sample(seed=8)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_afnitonifti.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_fim.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,28 +1,34 @@
-from fileformats.medimage_afni import ThreeD
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.afn_ito_nifti import AFNItoNIFTI
+from pydra.tasks.afni.auto.preprocess.fim import Fim
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_afnitonifti_1():
-    task = AFNItoNIFTI()
-    task.inputs.in_file = ThreeD.sample(seed=0)
-    task.inputs.pure = False
-    task.inputs.denote = False
-    task.inputs.oldid = False
-    task.inputs.newid = False
+def test_fim_1():
+    task = Fim()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.ideal_file = OneD.sample(seed=2)
     task.inputs.num_threads = 1
-    task.inputs.outputtype = "NIFTI"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_afnitonifti_2():
-    task = AFNItoNIFTI()
-    task.inputs.in_file = ThreeD.sample(seed=0)
+def test_fim_2():
+    task = Fim()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.ideal_file = OneD.sample(seed=2)
+    task.inputs.fim_thr = 0.0009
+    task.inputs.out = "Correlation"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_alignepianatpy.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_edge3.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,37 +1,41 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.align_epi_anat_py import AlignEpiAnatPy
+from pydra.tasks.afni.auto.utils.edge_3 import Edge3, edge3
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
+@pytest.mark.xfail
+def test_edge3_1():
+    task = edge3()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.datum = "byte"
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
 @pytest.mark.xfail
-def test_alignepianatpy_1():
-    task = AlignEpiAnatPy()
+def test_edge3_1():
+    task = Edge3()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.anat = Nifti1.sample(seed=1)
-    task.inputs.anat2epi = False
-    task.inputs.epi2anat = False
-    task.inputs.suffix = "_al"
-    task.inputs.epi_strip = "3dSkullStrip"
-    task.inputs.volreg = "on"
-    task.inputs.tshift = "on"
-    task.inputs.outputtype = "AFNI"
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_alignepianatpy_2():
-    task = AlignEpiAnatPy()
+def test_edge3_2():
+    task = Edge3()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.anat = Nifti1.sample(seed=1)
-    task.inputs.epi_base = 0
-    task.inputs.save_skullstrip = True
-    task.inputs.epi_strip = "3dAutomask"
-    task.inputs.volreg = "off"
-    task.inputs.tshift = "off"
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.datum = "byte"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_allineate.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_warp.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,56 +1,45 @@
-from fileformats.datascience.data import TextMatrix
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.text import TextFile
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.allineate import Allineate
+from pydra.tasks.afni.auto.preprocess.warp import Warp
 import pytest
 
 
-@pytest.mark.xfail
-def test_allineate_1():
-    task = Allineate()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.reference = Nifti1.sample(seed=1)
-    task.inputs.in_param_file = File.sample(seed=4)
-    task.inputs.in_matrix = TextMatrix.sample(seed=6)
-    task.inputs.weight_file = File.sample(seed=29)
-    task.inputs.source_mask = File.sample(seed=32)
-    task.inputs.master = File.sample(seed=43)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_allineate_2():
-    task = Allineate()
+def test_warp_1():
+    task = Warp()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "functional_allineate.nii"
-    task.inputs.in_matrix = TextMatrix.sample(seed=6)
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.matparent = File.sample(seed=4)
+    task.inputs.oblique_parent = File.sample(seed=5)
+    task.inputs.gridset = File.sample(seed=8)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_allineate_3():
-    task = Allineate()
+def test_warp_2():
+    task = Warp()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.reference = Nifti1.sample(seed=1)
-    task.inputs.allcostx = "out.allcostX.txt"
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.deoblique = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_allineate_4():
-    task = Allineate()
+def test_warp_3():
+    task = Warp()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.reference = Nifti1.sample(seed=1)
-    task.inputs.nwarp_fixmot = ["X", "Y"]
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.newgrid = 1.0
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_autobox.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tproject.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,24 +1,38 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.autobox import Autobox
+from pydra.tasks.afni.auto.preprocess.t_project import TProject
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_autobox_1():
-    task = Autobox()
+def test_tproject_1():
+    task = TProject()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.censor = File.sample(seed=2)
+    task.inputs.concat = File.sample(seed=5)
+    task.inputs.ort = File.sample(seed=7)
+    task.inputs.dsort = [File.sample(seed=9)]
+    task.inputs.mask = File.sample(seed=13)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_autobox_2():
-    task = Autobox()
+def test_tproject_2():
+    task = TProject()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.padding = 5
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.polort = 3
+    task.inputs.bandpass = (0.00667, 99999)
+    task.inputs.automask = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_automask.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_undump.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,31 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.automask import Automask
+from pydra.tasks.afni.auto.utils.undump import Undump
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_automask_1():
-    task = Automask()
+def test_undump_1():
+    task = Undump()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.mask_file = File.sample(seed=2)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_automask_2():
-    task = Automask()
+def test_undump_2():
+    task = Undump()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.dilate = 1
-    task.inputs.outputtype = "NIFTI"
+    task.inputs.out_file = Nifti1.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_autotcorrelate.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_autotcorrelate.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.auto_tcorrelate import AutoTcorrelate
+from pydra.tasks.afni.auto.preprocess.auto_tcorrelate import AutoTcorrelate
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_autotcorrelate_1():
     task = AutoTcorrelate()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.mask = Nifti1.sample(seed=3)
     task.inputs.mask_source = File.sample(seed=5)
     task.inputs.num_threads = 1
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_autotlrc.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_autobox.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,28 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.auto_tlrc import AutoTLRC
+from pydra.tasks.afni.auto.utils.autobox import Autobox
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_autotlrc_1():
-    task = AutoTLRC()
-    task.inputs.in_file = Nifti1.sample(seed=1)
+def test_autobox_1():
+    task = Autobox()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_autotlrc_2():
-    task = AutoTLRC()
-    task.inputs.in_file = Nifti1.sample(seed=1)
-    task.inputs.base = "TT_N27+tlrc"
-    task.inputs.no_ss = True
+def test_autobox_2():
+    task = Autobox()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.padding = 5
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_axialize.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_ecm.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,32 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.axialize import Axialize
+from pydra.tasks.afni.auto.preprocess.ecm import ECM
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_axialize_1():
-    task = Axialize()
+def test_ecm_1():
+    task = ECM()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask = Nifti1.sample(seed=9)
     task.inputs.num_threads = 1
+    task.inputs.out_file = Nifti1.sample(seed=16)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_axialize_2():
-    task = Axialize()
+def test_ecm_2():
+    task = ECM()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "axialized.nii"
+    task.inputs.sparsity = 0.1  # keep top 0.1% of connections
+    task.inputs.mask = Nifti1.sample(seed=9)
+    task.inputs.out_file = Nifti1.sample(seed=16)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_bandpass.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_bandpass.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.bandpass import Bandpass
+from pydra.tasks.afni.auto.preprocess.bandpass import Bandpass
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_bandpass_1():
     task = Bandpass()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.mask = File.sample(seed=4)
     task.inputs.orthogonalize_file = [File.sample(seed=6)]
     task.inputs.orthogonalize_dset = File.sample(seed=7)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_blurinmask.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_axialize.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,28 +1,29 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.blur_in_mask import BlurInMask
+from pydra.tasks.afni.auto.utils.axialize import Axialize
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_blurinmask_1():
-    task = BlurInMask()
+def test_axialize_1():
+    task = Axialize()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.multimask = File.sample(seed=3)
+    task.inputs.out_file = Nifti1.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_blurinmask_2():
-    task = BlurInMask()
+def test_axialize_2():
+    task = Axialize()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.fwhm = 5.0
+    task.inputs.out_file = Nifti1.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_blurtofwhm.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_onedtoolpy.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,27 +1,33 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.blur_to_fwhm import BlurToFWHM
+from pydra.tasks.afni.auto.utils.one_d_tool_py import OneDToolPy
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_blurtofwhm_1():
-    task = BlurToFWHM()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.blurmaster = File.sample(seed=4)
-    task.inputs.mask = File.sample(seed=5)
-    task.inputs.num_threads = 1
+def test_onedtoolpy_1():
+    task = OneDToolPy()
+    task.inputs.in_file = OneD.sample(seed=0)
+    task.inputs.out_file = OneD.sample(seed=4)
+    task.inputs.show_cormat_warnings = File.sample(seed=9)
+    task.inputs.py27_path = "python2"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_blurtofwhm_2():
-    task = BlurToFWHM()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.fwhm = 2.5
+def test_onedtoolpy_2():
+    task = OneDToolPy()
+    task.inputs.in_file = OneD.sample(seed=0)
+    task.inputs.set_nruns = 3
+    task.inputs.demean = True
+    task.inputs.out_file = OneD.sample(seed=4)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_brickstat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_unifize.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,31 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.brick_stat import BrickStat
+from pydra.tasks.afni.auto.utils.unifize import Unifize
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_brickstat_1():
-    task = BrickStat()
+def test_unifize_1():
+    task = Unifize()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = NiftiGz.sample(seed=1)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.scale_file = File.sample(seed=5)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_brickstat_2():
-    task = BrickStat()
+def test_unifize_2():
+    task = Unifize()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = NiftiGz.sample(seed=1)
-    task.inputs.min = True
+    task.inputs.out_file = Nifti1.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_bucket.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_t_cat_sub_brick.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,22 +1,21 @@
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.bucket import Bucket
+from pydra.tasks.afni.auto.utils.t_cat_sub_brick import t_cat_sub_brick
 import pytest
 
 
-@pytest.mark.xfail
-def test_bucket_1():
-    task = Bucket()
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_bucket_2():
-    task = Bucket()
-    task.inputs.in_file = [("functional.nii", "{2..$}"), ("functional.nii", "{1}")]
-    task.inputs.out_file = "vr_base"
+def test_t_cat_sub_brick_1():
+    task = t_cat_sub_brick()
+    task.inputs.in_files = [
+        ("functional.nii", "'{2..$}'"),
+        ("functional2.nii", "'{2..$}'"),
+    ]
+    task.inputs.out_file = "functional_tcat.nii"
+    task.inputs.rlt = "+"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_calc.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_volreg.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,43 +1,50 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD, R1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.calc import Calc
+from pydra.tasks.afni.auto.preprocess.volreg import Volreg
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_calc_1():
-    task = Calc()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.in_file_b = Nifti1.sample(seed=1)
-    task.inputs.in_file_c = File.sample(seed=2)
-    task.inputs.other = File.sample(seed=9)
+def test_volreg_1():
+    task = Volreg()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = R1.sample(seed=2)
+    task.inputs.basefile = Nifti1.sample(seed=3)
+    task.inputs.oned_file = OneD.sample(seed=6)
+    task.inputs.oned_matrix_save = OneD.sample(seed=10)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_calc_2():
-    task = Calc()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.in_file_b = Nifti1.sample(seed=1)
-    task.inputs.out_file = "functional_calc.nii.gz"
-    task.inputs.expr = "a*b"
+def test_volreg_2():
+    task = Volreg()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.zpad = 4
     task.inputs.outputtype = "NIFTI"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_calc_3():
-    task = Calc()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.out_file = "rm.epi.all1"
-    task.inputs.expr = "1"
-    task.inputs.overwrite = True
+def test_volreg_3():
+    task = Volreg()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = R1.sample(seed=2)
+    task.inputs.basefile = Nifti1.sample(seed=3)
+    task.inputs.zpad = 1
+    task.inputs.oned_file = OneD.sample(seed=6)
+    task.inputs.verbose = True
+    task.inputs.oned_matrix_save = OneD.sample(seed=10)
+    task.inputs.interp = "cubic"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_cat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_dot.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,25 +1,33 @@
-from fileformats.medimage_afni import OneD
+from fileformats.generic import File
+from fileformats.medimage import Nifti
+from fileformats.text import TextFile
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.cat import Cat
+from pydra.tasks.afni.auto.utils.dot import Dot
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_cat_1():
-    task = Cat()
-    task.inputs.in_files = [OneD.sample(seed=0)]
+def test_dot_1():
+    task = Dot()
+    task.inputs.in_files = [Nifti.sample(seed=0)]
+    task.inputs.out_file = TextFile.sample(seed=1)
+    task.inputs.mask = File.sample(seed=2)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_cat_2():
-    task = Cat()
-    task.inputs.in_files = [OneD.sample(seed=0)]
-    task.inputs.out_file = "catout.1d"
-    task.inputs.sel = "'[0,2]'"
+def test_dot_2():
+    task = Dot()
+    task.inputs.in_files = [Nifti.sample(seed=0)]
+    task.inputs.out_file = TextFile.sample(seed=1)
+    task.inputs.dodice = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_catmatvec.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_catmatvec.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,22 +1,28 @@
+from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.cat_matvec import CatMatvec
+from pydra.tasks.afni.auto.utils.cat_matvec import CatMatvec
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_catmatvec_1():
     task = CatMatvec()
+    task.inputs.out_file = OneD.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_catmatvec_2():
     task = CatMatvec()
     task.inputs.in_file = [("structural.BRIK::WARP_DATA", "I")]
-    task.inputs.out_file = "warp.anat.Xat.1D"
+    task.inputs.out_file = OneD.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_centermass.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_outliercount.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,26 +1,35 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.center_mass import CenterMass
+from pydra.tasks.afni.auto.preprocess.outlier_count import OutlierCount
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_centermass_1():
-    task = CenterMass()
+def test_outliercount_1():
+    task = OutlierCount()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask_file = File.sample(seed=2)
+    task.inputs.mask = File.sample(seed=1)
+    task.inputs.qthr = 0.001
+    task.inputs.autoclip = False
+    task.inputs.automask = False
+    task.inputs.fraction = False
+    task.inputs.interval = False
+    task.inputs.save_outliers = False
+    task.inputs.legendre = False
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_centermass_2():
-    task = CenterMass()
+def test_outliercount_2():
+    task = OutlierCount()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.cm_file = "cm.txt"
-    task.inputs.roi_vals = [2, 10]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_cliplevel.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_seg.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,24 +1,27 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.clip_level import ClipLevel
+from pydra.tasks.afni.auto.preprocess.seg import Seg
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_cliplevel_1():
-    task = ClipLevel()
+def test_seg_1():
+    task = Seg()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.grad = File.sample(seed=3)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_cliplevel_2():
-    task = ClipLevel()
+def test_seg_2():
+    task = Seg()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask = "AUTO"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_convertdset.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_masktool.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,26 +1,28 @@
-from fileformats.medimage.surface import Gifti
-from fileformats.medimage_afni import Dset
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.convert_dset import ConvertDset
+from pydra.tasks.afni.auto.utils.mask_tool import MaskTool
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_convertdset_1():
-    task = ConvertDset()
-    task.inputs.in_file = Gifti.sample(seed=0)
+def test_masktool_1():
+    task = MaskTool()
+    task.inputs.in_file = [Nifti1.sample(seed=0)]
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_convertdset_2():
-    task = ConvertDset()
-    task.inputs.in_file = Gifti.sample(seed=0)
-    task.inputs.out_file = "lh.pial_converted.niml.dset"
-    task.inputs.out_type = "niml_asc"
+def test_masktool_2():
+    task = MaskTool()
+    task.inputs.in_file = [Nifti1.sample(seed=0)]
+    task.inputs.outputtype = "NIFTI"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_copy.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_copy.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,22 @@
-from copy import deepcopy
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.copy import Copy
+from pydra.tasks.afni.auto.utils.copy import Copy
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_copy_1():
     task = Copy()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
@@ -41,11 +45,11 @@
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_copy_5():
     task = Copy()
-    task.inputs.out_file = "new_func.nii"
+    task.inputs.out_file = Nifti1.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_deconvolve.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_alignepianatpy.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,34 +1,37 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.deconvolve import Deconvolve
+from pydra.tasks.afni.auto.preprocess.align_epi_anat_py import AlignEpiAnatPy
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_deconvolve_1():
-    task = Deconvolve()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.input1D = File.sample(seed=5)
-    task.inputs.mask = File.sample(seed=19)
-    task.inputs.STATmask = File.sample(seed=21)
-    task.inputs.censor = File.sample(seed=22)
+def test_alignepianatpy_1():
+    task = AlignEpiAnatPy()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.anat = Nifti1.sample(seed=1)
+    task.inputs.suffix = "_al"
+    task.inputs.volreg = "on"
+    task.inputs.tshift = "on"
+    task.inputs.py27_path = "python2"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_deconvolve_2():
-    task = Deconvolve()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.x1D = "output.1D"
-    task.inputs.out_file = "output.nii"
-    task.inputs.stim_times = stim_times
-    task.inputs.stim_label = [(1, "Houses")]
-    task.inputs.gltsym = ["SYM: +Houses"]
-    task.inputs.glt_label = [(1, "Houses")]
+def test_alignepianatpy_2():
+    task = AlignEpiAnatPy()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.anat = Nifti1.sample(seed=1)
+    task.inputs.epi_base = 0
+    task.inputs.save_skullstrip = True
+    task.inputs.epi_strip = "3dAutomask"
+    task.inputs.volreg = "off"
+    task.inputs.tshift = "off"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_degreecentrality.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_degreecentrality.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,28 +1,32 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.degree_centrality import DegreeCentrality
+from pydra.tasks.afni.auto.preprocess.degree_centrality import DegreeCentrality
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_degreecentrality_1():
     task = DegreeCentrality()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.mask = Nifti1.sample(seed=3)
     task.inputs.num_threads = 1
+    task.inputs.out_file = Nifti1.sample(seed=10)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_degreecentrality_2():
     task = DegreeCentrality()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.sparsity = 1  # keep the top one percent of connections
     task.inputs.mask = Nifti1.sample(seed=3)
-    task.inputs.out_file = "out.nii"
+    task.inputs.out_file = Nifti1.sample(seed=10)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_despike.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_skullstrip.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.despike import Despike
+from pydra.tasks.afni.auto.preprocess.skull_strip import SkullStrip
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_despike_1():
-    task = Despike()
+def test_skullstrip_1():
+    task = SkullStrip()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_despike_2():
-    task = Despike()
+def test_skullstrip_2():
+    task = SkullStrip()
     task.inputs.in_file = Nifti1.sample(seed=0)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_detrend.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_zcutup.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,30 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.detrend import Detrend
+from pydra.tasks.afni.auto.utils.z_cut_up import ZCutUp
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_detrend_1():
-    task = Detrend()
+def test_zcutup_1():
+    task = ZCutUp()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_detrend_2():
-    task = Detrend()
+def test_zcutup_2():
+    task = ZCutUp()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.outputtype = "AFNI"
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.keep = "0 10"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_dot.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarpadjust.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,28 +1,29 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.text import TextFile
+from fileformats.medimage import NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.dot import Dot
+from pydra.tasks.afni.auto.utils.nwarp_adjust import NwarpAdjust
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_dot_1():
-    task = Dot()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.mask = File.sample(seed=2)
+def test_nwarpadjust_1():
+    task = NwarpAdjust()
+    task.inputs.warps = [NiftiGz.sample(seed=0)]
+    task.inputs.in_files = [File.sample(seed=1)]
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_dot_2():
-    task = Dot()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.out_file = "out.mask_ae_dice.txt"
-    task.inputs.dodice = True
+def test_nwarpadjust_2():
+    task = NwarpAdjust()
+    task.inputs.warps = [NiftiGz.sample(seed=0)]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_ecm.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tcorrelate.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,27 +1,33 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.ecm import ECM
+from pydra.tasks.afni.auto.preprocess.t_correlate import TCorrelate
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_ecm_1():
-    task = ECM()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=9)
+def test_tcorrelate_1():
+    task = TCorrelate()
+    task.inputs.xset = Nifti1.sample(seed=0)
+    task.inputs.yset = Nifti1.sample(seed=1)
+    task.inputs.out_file = NiftiGz.sample(seed=2)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_ecm_2():
-    task = ECM()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.sparsity = 0.1  # keep top 0.1% of connections
-    task.inputs.mask = Nifti1.sample(seed=9)
-    task.inputs.out_file = "out.nii"
+def test_tcorrelate_2():
+    task = TCorrelate()
+    task.inputs.xset = Nifti1.sample(seed=0)
+    task.inputs.yset = Nifti1.sample(seed=1)
+    task.inputs.out_file = NiftiGz.sample(seed=2)
+    task.inputs.pearson = True
+    task.inputs.polort = -1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_edge3.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_merge.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,31 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.edge_3 import Edge3
+from pydra.tasks.afni.auto.utils.merge import Merge
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_edge3_1():
-    task = Edge3()
-    task.inputs.in_file = Nifti1.sample(seed=0)
+def test_merge_1():
+    task = Merge()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_edge3_2():
-    task = Edge3()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "edges.nii"
-    task.inputs.datum = "byte"
+def test_merge_2():
+    task = Merge()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.doall = True
+    task.inputs.blurfwhm = 4
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_eval.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_eval.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,31 +1,36 @@
 from fileformats.generic import File
 from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.eval import Eval
+from pydra.tasks.afni.auto.utils.eval import Eval
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_eval_1():
     task = Eval()
     task.inputs.in_file_a = OneD.sample(seed=0)
     task.inputs.in_file_b = OneD.sample(seed=1)
     task.inputs.in_file_c = File.sample(seed=2)
+    task.inputs.out_file = OneD.sample(seed=3)
     task.inputs.other = File.sample(seed=9)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_eval_2():
     task = Eval()
     task.inputs.in_file_a = OneD.sample(seed=0)
     task.inputs.in_file_b = OneD.sample(seed=1)
-    task.inputs.out_file = "data_calc.1D"
+    task.inputs.out_file = OneD.sample(seed=3)
     task.inputs.out1D = True
     task.inputs.expr = "a*b"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_fim.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_netcorr.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,29 +1,39 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import NCorr
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.fim import Fim
+from pydra.tasks.afni.auto.preprocess.net_corr import NetCorr
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_fim_1():
-    task = Fim()
+def test_netcorr_1():
+    task = NetCorr()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.ideal_file = OneD.sample(seed=2)
+    task.inputs.in_rois = Nifti1.sample(seed=1)
+    task.inputs.mask = Nifti1.sample(seed=2)
+    task.inputs.weight_ts = File.sample(seed=3)
+    task.inputs.out_file = NCorr.sample(seed=16)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_fim_2():
-    task = Fim()
+def test_netcorr_2():
+    task = NetCorr()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "functional_corr.nii"
-    task.inputs.ideal_file = OneD.sample(seed=2)
-    task.inputs.fim_thr = 0.0009
-    task.inputs.out = "Correlation"
+    task.inputs.in_rois = Nifti1.sample(seed=1)
+    task.inputs.mask = Nifti1.sample(seed=2)
+    task.inputs.fish_z = True
+    task.inputs.ts_wb_corr = True
+    task.inputs.ts_wb_Z = True
+    task.inputs.out_file = NCorr.sample(seed=16)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_fourier.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_correlate.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,21 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.fourier import Fourier
+from pydra.tasks.afni.auto.preprocess.t_correlate import t_correlate
 import pytest
 
 
-@pytest.mark.xfail
-def test_fourier_1():
-    task = Fourier()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_fourier_2():
-    task = Fourier()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.lowpass = 0.1
-    task.inputs.highpass = 0.005
-    task.inputs.retrend = True
+def test_t_correlate_1():
+    task = t_correlate()
+    task.inputs.xset = Nifti1.sample(seed=0)
+    task.inputs.yset = Nifti1.sample(seed=1)
+    task.inputs.out_file = NiftiGz.sample(seed=2)
+    task.inputs.pearson = True
+    task.inputs.polort = -1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_fwhmx.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_roistats.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,27 +1,34 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.fwh_mx import FWHMx
+from pydra.tasks.afni.auto.preprocess.roi_stats import ROIStats
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_fwhmx_1():
-    task = FWHMx()
+def test_roistats_1():
+    task = ROIStats()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = File.sample(seed=3)
-    task.inputs.automask = False
-    task.inputs.detrend = False
-    task.inputs.acf = False
+    task.inputs.mask = File.sample(seed=1)
+    task.inputs.mask_file = NiftiGz.sample(seed=2)
+    task.inputs.roisel = File.sample(seed=6)
+    task.inputs.stat = [File.sample(seed=13)]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_fwhmx_2():
-    task = FWHMx()
+def test_roistats_2():
+    task = ROIStats()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask_file = NiftiGz.sample(seed=2)
+    task.inputs.nomeanout = True
+    task.inputs.stat = [File.sample(seed=13)]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_gcor.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_fwhmx.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,31 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.gcor import GCOR
+from pydra.tasks.afni.auto.utils.fwh_mx import FWHMx
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_gcor_1():
-    task = GCOR()
+def test_fwhmx_1():
+    task = FWHMx()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = File.sample(seed=1)
+    task.inputs.mask = File.sample(seed=3)
+    task.inputs.automask = False
+    task.inputs.detrend = False
+    task.inputs.acf = False
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_gcor_2():
-    task = GCOR()
+def test_fwhmx_2():
+    task = FWHMx()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.nfirst = 4
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_hist.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_autotlrc.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,25 +1,28 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.hist import Hist
+from pydra.tasks.afni.auto.preprocess.auto_tlrc import AutoTLRC
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_hist_1():
-    task = Hist()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.showhist = False
-    task.inputs.mask = File.sample(seed=4)
+def test_autotlrc_1():
+    task = AutoTLRC()
+    task.inputs.in_file = Nifti1.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_hist_2():
-    task = Hist()
-    task.inputs.in_file = Nifti1.sample(seed=0)
+def test_autotlrc_2():
+    task = AutoTLRC()
+    task.inputs.in_file = Nifti1.sample(seed=1)
+    task.inputs.base = "TT_N27+tlrc"
+    task.inputs.no_ss = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_lfcd.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_project.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,27 +1,21 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.lfcd import LFCD
+from pydra.tasks.afni.auto.preprocess.t_project import t_project
 import pytest
 
 
-@pytest.mark.xfail
-def test_lfcd_1():
-    task = LFCD()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=1)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_lfcd_2():
-    task = LFCD()
+def test_t_project_1():
+    task = t_project()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=1)
-    task.inputs.thresh = 0.8  # keep all connections with corr >= 0.8
-    task.inputs.out_file = "out.nii"
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.polort = 3
+    task.inputs.bandpass = (0.00667, 99999)
+    task.inputs.automask = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_localbistat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_localbistat.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,32 +1,36 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.engine.specs import MultiInputObj
-from pydra.tasks.afni.auto.local_bistat import LocalBistat
+from pydra.tasks.afni.auto.utils.local_bistat import LocalBistat
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_localbistat_1():
     task = LocalBistat()
     task.inputs.in_file1 = Nifti1.sample(seed=0)
     task.inputs.in_file2 = Nifti1.sample(seed=1)
+    task.inputs.stat = [File.sample(seed=3)]
     task.inputs.mask_file = File.sample(seed=4)
     task.inputs.weight_file = File.sample(seed=6)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_localbistat_2():
     task = LocalBistat()
     task.inputs.in_file1 = Nifti1.sample(seed=0)
     task.inputs.in_file2 = Nifti1.sample(seed=1)
     task.inputs.neighborhood = ("SPHERE", 1.2)
-    task.inputs.stat = "pearson"
+    task.inputs.stat = [File.sample(seed=3)]
     task.inputs.outputtype = "NIFTI"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_localstat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_localstat.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,31 +1,35 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.generic import File
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.engine.specs import MultiInputObj
-from pydra.tasks.afni.auto.localstat import Localstat
+from pydra.tasks.afni.auto.utils.localstat import Localstat
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_localstat_1():
     task = Localstat()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.stat = [File.sample(seed=2)]
     task.inputs.mask_file = NiftiGz.sample(seed=3)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_localstat_2():
     task = Localstat()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.neighborhood = ("SPHERE", 45)
-    task.inputs.stat = "mean"
+    task.inputs.stat = [File.sample(seed=2)]
     task.inputs.mask_file = NiftiGz.sample(seed=3)
     task.inputs.nonmask = True
     task.inputs.outputtype = "NIFTI_GZ"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_maskave.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_hist.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,26 +1,29 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.maskave import Maskave
+from pydra.tasks.afni.auto.preprocess.hist import Hist
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_maskave_1():
-    task = Maskave()
+def test_hist_1():
+    task = Hist()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.num_threads = 1
+    task.inputs.showhist = False
+    task.inputs.mask = File.sample(seed=4)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_maskave_2():
-    task = Maskave()
+def test_hist_2():
+    task = Hist()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.quiet = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_masktool.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_re_ho.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,24 +1,19 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.mask_tool import MaskTool
+from pydra.tasks.afni.auto.utils.re_ho import re_ho
 import pytest
 
 
-@pytest.mark.xfail
-def test_masktool_1():
-    task = MaskTool()
-    task.inputs.in_file = [Nifti1.sample(seed=0)]
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_masktool_2():
-    task = MaskTool()
-    task.inputs.in_file = [Nifti1.sample(seed=0)]
-    task.inputs.outputtype = "NIFTI"
+def test_re_ho_1():
+    task = re_ho()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = NiftiGz.sample(seed=1)
+    task.inputs.neighborhood = "vertices"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_means.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_resample.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,37 +1,31 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.means import Means
+from pydra.tasks.afni.auto.utils.resample import Resample
 import pytest
 
 
-@pytest.mark.xfail
-def test_means_1():
-    task = Means()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.in_file_b = Nifti1.sample(seed=1)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_means_2():
-    task = Means()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.in_file_b = Nifti1.sample(seed=1)
-    task.inputs.out_file = "output.nii"
+def test_resample_1():
+    task = Resample()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.master = File.sample(seed=5)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_means_3():
-    task = Means()
-    task.inputs.in_file_a = Nifti1.sample(seed=0)
-    task.inputs.datum = "short"
-    task.inputs.out_file = "output.nii"
+def test_resample_2():
+    task = Resample()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.orientation = "RPI"
+    task.inputs.outputtype = "NIFTI"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_merge.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_fourier.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,26 +1,30 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.merge import Merge
+from pydra.tasks.afni.auto.preprocess.fourier import Fourier
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_merge_1():
-    task = Merge()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
+def test_fourier_1():
+    task = Fourier()
+    task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_merge_2():
-    task = Merge()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.out_file = "e7.nii"
-    task.inputs.doall = True
-    task.inputs.blurfwhm = 4
+def test_fourier_2():
+    task = Fourier()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.lowpass = 0.1
+    task.inputs.highpass = 0.005
+    task.inputs.retrend = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_netcorr.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_zeropad.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,33 +1,37 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.net_corr import NetCorr
+from pydra.tasks.afni.auto.utils.zeropad import Zeropad
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_netcorr_1():
-    task = NetCorr()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.in_rois = Nifti1.sample(seed=1)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.weight_ts = File.sample(seed=3)
+def test_zeropad_1():
+    task = Zeropad()
+    task.inputs.in_files = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.master = File.sample(seed=13)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_netcorr_2():
-    task = NetCorr()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.in_rois = Nifti1.sample(seed=1)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.fish_z = True
-    task.inputs.ts_wb_corr = True
-    task.inputs.ts_wb_Z = True
-    task.inputs.out_file = "sub0.tp1.ncorr"
+def test_zeropad_2():
+    task = Zeropad()
+    task.inputs.in_files = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.I = 10
+    task.inputs.S = 10
+    task.inputs.A = 10
+    task.inputs.P = 10
+    task.inputs.L = 10
+    task.inputs.R = 10
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_notes.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_notes.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,23 @@
 from fileformats.generic import File
 from fileformats.medimage_afni import Head
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.notes import Notes
+from pydra.tasks.afni.auto.utils.notes import Notes
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_notes_1():
     task = Notes()
     task.inputs.in_file = Head.sample(seed=0)
+    task.inputs.out_file = File.sample(seed=6)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_nwarpadjust.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_to3d.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,25 +1,30 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.nwarp_adjust import NwarpAdjust
+from pydra.tasks.afni.auto.utils.to_3d import To3D
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_nwarpadjust_1():
-    task = NwarpAdjust()
-    task.inputs.warps = [NiftiGz.sample(seed=0)]
-    task.inputs.in_files = [File.sample(seed=1)]
+def test_to3d_1():
+    task = To3D()
+    task.inputs.out_file = Nifti1.sample(seed=0)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_nwarpadjust_2():
-    task = NwarpAdjust()
-    task.inputs.warps = [NiftiGz.sample(seed=0)]
+def test_to3d_2():
+    task = To3D()
+    task.inputs.out_file = Nifti1.sample(seed=0)
+    task.inputs.in_folder = "."
+    task.inputs.filetype = "anat"
+    task.inputs.datatype = "float"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_nwarpapply.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarpapply.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,13 +1,17 @@
 from fileformats.generic import File
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.nwarp_apply import NwarpApply
+from pydra.tasks.afni.auto.utils.nwarp_apply import NwarpApply
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_nwarpapply_1():
     task = NwarpApply()
     task.inputs.master = File.sample(seed=3)
     task.inputs.interp = "wsinc5"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_nwarpcat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_nwarpcat.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,26 @@
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.nwarp_cat import NwarpCat
+from pydra.tasks.afni.auto.utils.nwarp_cat import NwarpCat
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_nwarpcat_1():
     task = NwarpCat()
     task.inputs.interp = "wsinc5"
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_nwarpcat_2():
     task = NwarpCat()
     task.inputs.in_files = ["Q25_warp+tlrc.HEAD", ("IDENT", "structural.nii")]
-    task.inputs.out_file = "Fred_total_WARP"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_onedtoolpy.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_means.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,28 +1,42 @@
-from fileformats.generic import File
-from fileformats.medimage_afni import OneD
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.one_d_tool_py import OneDToolPy
+from pydra.tasks.afni.auto.preprocess.means import Means
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
+@pytest.mark.xfail
+def test_means_1():
+    task = Means()
+    task.inputs.in_file_a = Nifti1.sample(seed=0)
+    task.inputs.in_file_b = Nifti1.sample(seed=1)
+    task.inputs.out_file = Nifti1.sample(seed=3)
+    task.inputs.num_threads = 1
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
 @pytest.mark.xfail
-def test_onedtoolpy_1():
-    task = OneDToolPy()
-    task.inputs.in_file = OneD.sample(seed=0)
-    task.inputs.show_cormat_warnings = File.sample(seed=9)
-    task.inputs.py27_path = "python2"
+def test_means_2():
+    task = Means()
+    task.inputs.in_file_a = Nifti1.sample(seed=0)
+    task.inputs.in_file_b = Nifti1.sample(seed=1)
+    task.inputs.out_file = Nifti1.sample(seed=3)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_onedtoolpy_2():
-    task = OneDToolPy()
-    task.inputs.in_file = OneD.sample(seed=0)
-    task.inputs.set_nruns = 3
-    task.inputs.demean = True
-    task.inputs.out_file = "motion_dmean.1D"
+def test_means_3():
+    task = Means()
+    task.inputs.in_file_a = Nifti1.sample(seed=0)
+    task.inputs.datum = "short"
+    task.inputs.out_file = Nifti1.sample(seed=3)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_qualityindex.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qualityindex.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.quality_index import QualityIndex
+from pydra.tasks.afni.auto.preprocess.quality_index import QualityIndex
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_qualityindex_1():
     task = QualityIndex()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.mask = File.sample(seed=1)
     task.inputs.spearman = False
     task.inputs.quadrant = False
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_qwarp.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qwarp.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,22 +1,27 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1, NiftiGz
 from fileformats.medimage_afni import Head
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.qwarp import Qwarp
+from pydra.tasks.afni.auto.preprocess.qwarp import Qwarp
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_qwarp_1():
     task = Qwarp()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.base_file = Nifti1.sample(seed=1)
+    task.inputs.out_file = NiftiGz.sample(seed=2)
     task.inputs.weight = File.sample(seed=13)
+    task.inputs.out_weight_file = File.sample(seed=16)
     task.inputs.emask = File.sample(seed=19)
     task.inputs.iniwarp = [Head.sample(seed=23)]
     task.inputs.gridlist = File.sample(seed=27)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
@@ -46,15 +51,15 @@
 
 
 @pytest.mark.xfail
 def test_qwarp_4():
     task = Qwarp()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.base_file = Nifti1.sample(seed=1)
-    task.inputs.out_file = "anatSSQ.nii.gz"
+    task.inputs.out_file = NiftiGz.sample(seed=2)
     task.inputs.resample = True
     task.inputs.iwarp = True
     task.inputs.blur = [0, 3]
     task.inputs.verb = True
     task.inputs.lpc = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
@@ -74,29 +79,29 @@
 
 
 @pytest.mark.xfail
 def test_qwarp_6():
     task = Qwarp()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.base_file = Nifti1.sample(seed=1)
-    task.inputs.out_file = "Q25"
+    task.inputs.out_file = NiftiGz.sample(seed=2)
     task.inputs.blur = [0, 3]
     task.inputs.minpatch = 25
     task.inputs.duplo = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_qwarp_7():
     task = Qwarp()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.base_file = Nifti1.sample(seed=1)
-    task.inputs.out_file = "Q11"
+    task.inputs.out_file = NiftiGz.sample(seed=2)
     task.inputs.blur = [0, 2]
     task.inputs.iniwarp = [Head.sample(seed=23)]
     task.inputs.inilev = 7
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_qwarpplusminus.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/test_deconvolve.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,34 +1,40 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.qwarp_plus_minus import QwarpPlusMinus
+from pydra.tasks.afni.auto.model.deconvolve import Deconvolve
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_qwarpplusminus_1():
-    task = QwarpPlusMinus()
-    task.inputs.source_file = File.sample(seed=0)
-    task.inputs.out_file = "Qwarp.nii.gz"
-    task.inputs.plusminus = True
-    task.inputs.in_file = NiftiGz.sample(seed=3)
-    task.inputs.base_file = NiftiGz.sample(seed=4)
-    task.inputs.weight = File.sample(seed=15)
-    task.inputs.emask = File.sample(seed=21)
-    task.inputs.iniwarp = [File.sample(seed=25)]
-    task.inputs.gridlist = File.sample(seed=29)
-    task.inputs.num_threads = 1
+def test_deconvolve_1():
+    task = Deconvolve()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.input1D = File.sample(seed=5)
+    task.inputs.mask = File.sample(seed=19)
+    task.inputs.STATmask = File.sample(seed=21)
+    task.inputs.censor = File.sample(seed=22)
+    task.inputs.x1D = OneD.sample(seed=25)
+    task.inputs.out_file = Nifti1.sample(seed=28)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_qwarpplusminus_2():
-    task = QwarpPlusMinus()
-    task.inputs.in_file = NiftiGz.sample(seed=3)
-    task.inputs.base_file = NiftiGz.sample(seed=4)
-    task.inputs.nopadWARP = True
+def test_deconvolve_2():
+    task = Deconvolve()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.x1D = OneD.sample(seed=25)
+    task.inputs.out_file = Nifti1.sample(seed=28)
+    task.inputs.stim_times = stim_times
+    task.inputs.stim_label = [(1, "Houses")]
+    task.inputs.gltsym = ["SYM: +Houses"]
+    task.inputs.glt_label = [(1, "Houses")]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_refit.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_refit.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.refit import Refit
+from pydra.tasks.afni.auto.utils.refit import Refit
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_refit_1():
     task = Refit()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.duporigin_file = File.sample(seed=5)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_reho.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_reho.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,27 +1,32 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1, NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.re_ho import ReHo
+from pydra.tasks.afni.auto.utils.re_ho import ReHo
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_reho_1():
     task = ReHo()
     task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = NiftiGz.sample(seed=1)
     task.inputs.mask_file = File.sample(seed=3)
     task.inputs.label_set = File.sample(seed=7)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
 def test_reho_2():
     task = ReHo()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "reho.nii.gz"
+    task.inputs.out_file = NiftiGz.sample(seed=1)
     task.inputs.neighborhood = "vertices"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_remlfit.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_qwarpplusminus.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,40 +1,39 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
+from fileformats.medimage import NiftiGz
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.remlfit import Remlfit
+from pydra.tasks.afni.auto.preprocess.qwarp_plus_minus import QwarpPlusMinus
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_remlfit_1():
-    task = Remlfit()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.matrix = OneD.sample(seed=1)
-    task.inputs.matim = File.sample(seed=3)
-    task.inputs.mask = File.sample(seed=4)
-    task.inputs.automask = False
-    task.inputs.STATmask = File.sample(seed=6)
-    task.inputs.addbase = [File.sample(seed=7)]
-    task.inputs.slibase = [File.sample(seed=8)]
-    task.inputs.slibase_sm = [File.sample(seed=9)]
-    task.inputs.dsort = File.sample(seed=12)
+def test_qwarpplusminus_1():
+    task = QwarpPlusMinus()
+    task.inputs.source_file = File.sample(seed=0)
+    task.inputs.out_file = File.sample(seed=1)
+    task.inputs.plusminus = True
+    task.inputs.in_file = NiftiGz.sample(seed=3)
+    task.inputs.base_file = NiftiGz.sample(seed=4)
+    task.inputs.weight = File.sample(seed=15)
+    task.inputs.out_weight_file = File.sample(seed=18)
+    task.inputs.emask = File.sample(seed=21)
+    task.inputs.iniwarp = [File.sample(seed=25)]
+    task.inputs.gridlist = File.sample(seed=29)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_remlfit_2():
-    task = Remlfit()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
-    task.inputs.matrix = OneD.sample(seed=1)
-    task.inputs.gltsym = [
-        ("SYM: +Lab1 -Lab2", "TestSYM"),
-        ("timeseries.txt", "TestFile"),
-    ]
-    task.inputs.out_file = "output.nii"
+def test_qwarpplusminus_2():
+    task = QwarpPlusMinus()
+    task.inputs.in_file = NiftiGz.sample(seed=3)
+    task.inputs.base_file = NiftiGz.sample(seed=4)
+    task.inputs.nopadWARP = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_resample.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_centermass.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,27 +1,32 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+from fileformats.text import TextFile
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.resample import Resample
+from pydra.tasks.afni.auto.utils.center_mass import CenterMass
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_resample_1():
-    task = Resample()
+def test_centermass_1():
+    task = CenterMass()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.master = File.sample(seed=5)
-    task.inputs.num_threads = 1
+    task.inputs.cm_file = TextFile.sample(seed=1)
+    task.inputs.mask_file = File.sample(seed=2)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_resample_2():
-    task = Resample()
+def test_centermass_2():
+    task = CenterMass()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.orientation = "RPI"
-    task.inputs.outputtype = "NIFTI"
+    task.inputs.cm_file = TextFile.sample(seed=1)
+    task.inputs.roi_vals = [2, 10]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_retroicor.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_retroicor.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,19 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
 from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.retroicor import Retroicor
+from pydra.tasks.afni.auto.preprocess.retroicor import Retroicor
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_retroicor_1():
     task = Retroicor()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.card = OneD.sample(seed=2)
     task.inputs.resp = OneD.sample(seed=3)
     task.inputs.cardphase = File.sample(seed=6)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_roistats.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_tstat.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,31 +1,29 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage.nifti import NiftiGz
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.engine.specs import MultiInputObj
-from pydra.tasks.afni.auto.roi_stats import ROIStats
+from pydra.tasks.afni.auto.utils.t_stat import TStat
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_roistats_1():
-    task = ROIStats()
+def test_tstat_1():
+    task = TStat()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = File.sample(seed=1)
-    task.inputs.mask_file = NiftiGz.sample(seed=2)
-    task.inputs.roisel = File.sample(seed=6)
+    task.inputs.mask = File.sample(seed=2)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_roistats_2():
-    task = ROIStats()
+def test_tstat_2():
+    task = TStat()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask_file = NiftiGz.sample(seed=2)
-    task.inputs.nomeanout = True
-    task.inputs.stat = ["mean", "median", "voxels"]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_seg.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_zcat.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,24 +1,29 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.seg import Seg
+from pydra.tasks.afni.auto.utils.zcat import Zcat
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_seg_1():
-    task = Seg()
-    task.inputs.in_file = Nifti1.sample(seed=0)
+def test_zcat_1():
+    task = Zcat()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_seg_2():
-    task = Seg()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = "AUTO"
+def test_zcat_2():
+    task = Zcat()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_skullstrip.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_t_cat.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,23 +1,19 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.skull_strip import SkullStrip
+from pydra.tasks.afni.auto.utils.t_cat import t_cat
 import pytest
 
 
-@pytest.mark.xfail
-def test_skullstrip_1():
-    task = SkullStrip()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_skullstrip_2():
-    task = SkullStrip()
-    task.inputs.in_file = Nifti1.sample(seed=0)
+def test_t_cat_1():
+    task = t_cat()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.rlt = "+"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_svmtrain.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/svm/tests/test_svmtrain.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,13 +1,17 @@
 from fileformats.generic import File
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.svm_train import SVMTrain
+from pydra.tasks.afni.auto.svm.svm_train import SVMTrain
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_svmtrain_1():
     task = SVMTrain()
     task.inputs.in_file = File.sample(seed=1)
     task.inputs.mask = File.sample(seed=5)
     task.inputs.trainlabels = File.sample(seed=7)
     task.inputs.censor = File.sample(seed=8)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_synthesize.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_blurinmask.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,27 +1,32 @@
-from fileformats.medimage.nifti import Nifti1
-from fileformats.medimage_afni import OneD
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.synthesize import Synthesize
+from pydra.tasks.afni.auto.preprocess.blur_in_mask import BlurInMask
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_synthesize_1():
-    task = Synthesize()
-    task.inputs.cbucket = Nifti1.sample(seed=0)
-    task.inputs.matrix = OneD.sample(seed=1)
+def test_blurinmask_1():
+    task = BlurInMask()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask = Nifti1.sample(seed=2)
+    task.inputs.multimask = File.sample(seed=3)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_synthesize_2():
-    task = Synthesize()
-    task.inputs.cbucket = Nifti1.sample(seed=0)
-    task.inputs.matrix = OneD.sample(seed=1)
-    task.inputs.select = ["baseline"]
+def test_blurinmask_2():
+    task = BlurInMask()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.mask = Nifti1.sample(seed=2)
+    task.inputs.fwhm = 5.0
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_tcatsubbrick.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,25 +1,30 @@
-from fileformats.medimage.nifti import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_cat import TCat
+from pydra.tasks.afni.auto.utils.t_cat_sub_brick import TCatSubBrick
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_tcat_1():
-    task = TCat()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
+def test_tcatsubbrick_1():
+    task = TCatSubBrick()
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_tcat_2():
-    task = TCat()
-    task.inputs.in_files = [Nifti1.sample(seed=0)]
+def test_tcatsubbrick_2():
+    task = TCatSubBrick()
+    task.inputs.in_files = [
+        ("functional.nii", "'{2..$}'"),
+        ("functional2.nii", "'{2..$}'"),
+    ]
     task.inputs.out_file = "functional_tcat.nii"
     task.inputs.rlt = "+"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcorr1d.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tcorr1d.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,14 +1,18 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
 from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_corr_1d import TCorr1D
+from pydra.tasks.afni.auto.preprocess.t_corr_1d import TCorr1D
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_tcorr1d_1():
     task = TCorr1D()
     task.inputs.xset = Nifti1.sample(seed=0)
     task.inputs.y_1d = OneD.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcorrelate.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_automask.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,28 +1,29 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_correlate import TCorrelate
+from pydra.tasks.afni.auto.preprocess.automask import Automask
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_tcorrelate_1():
-    task = TCorrelate()
-    task.inputs.xset = Nifti1.sample(seed=0)
-    task.inputs.yset = Nifti1.sample(seed=1)
+def test_automask_1():
+    task = Automask()
+    task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_tcorrelate_2():
-    task = TCorrelate()
-    task.inputs.xset = Nifti1.sample(seed=0)
-    task.inputs.yset = Nifti1.sample(seed=1)
-    task.inputs.out_file = "functional_tcorrelate.nii.gz"
-    task.inputs.pearson = True
-    task.inputs.polort = -1
+def test_automask_2():
+    task = Automask()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.dilate = 1
+    task.inputs.outputtype = "NIFTI"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tcorrmap.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tnorm.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,28 +1,28 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_corr_map import TCorrMap
+from pydra.tasks.afni.auto.preprocess.t_norm import TNorm
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_tcorrmap_1():
-    task = TCorrMap()
+def test_tnorm_1():
+    task = TNorm()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.seeds = File.sample(seed=1)
-    task.inputs.mask = Nifti1.sample(seed=2)
-    task.inputs.regress_out_timeseries = File.sample(seed=6)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_tcorrmap_2():
-    task = TCorrMap()
+def test_tnorm_2():
+    task = TNorm()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = Nifti1.sample(seed=2)
+    task.inputs.norm2 = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tnorm.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_calc.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,25 +1,49 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import All1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_norm import TNorm
+from pydra.tasks.afni.auto.utils.calc import Calc
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_tnorm_1():
-    task = TNorm()
-    task.inputs.in_file = Nifti1.sample(seed=0)
+def test_calc_1():
+    task = Calc()
+    task.inputs.in_file_a = Nifti1.sample(seed=0)
+    task.inputs.in_file_b = Nifti1.sample(seed=1)
+    task.inputs.in_file_c = File.sample(seed=2)
+    task.inputs.out_file = All1.sample(seed=3)
+    task.inputs.other = File.sample(seed=9)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_tnorm_2():
-    task = TNorm()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "rm.errts.unit errts+tlrc"
-    task.inputs.norm2 = True
+def test_calc_2():
+    task = Calc()
+    task.inputs.in_file_a = Nifti1.sample(seed=0)
+    task.inputs.in_file_b = Nifti1.sample(seed=1)
+    task.inputs.out_file = All1.sample(seed=3)
+    task.inputs.expr = "a*b"
+    task.inputs.outputtype = "NIFTI"
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
+@pytest.mark.xfail
+def test_calc_3():
+    task = Calc()
+    task.inputs.in_file_a = Nifti1.sample(seed=0)
+    task.inputs.out_file = All1.sample(seed=3)
+    task.inputs.expr = "1"
+    task.inputs.overwrite = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_to3d.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/model/tests/test_synthesize.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,26 +1,31 @@
-from fileformats.generic import Directory
+from fileformats.medimage import Nifti1
+from fileformats.medimage_afni import OneD
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.to_3d import To3D
+from pydra.tasks.afni.auto.model.synthesize import Synthesize
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_to3d_1():
-    task = To3D()
-    task.inputs.in_folder = Directory.sample(seed=1)
+def test_synthesize_1():
+    task = Synthesize()
+    task.inputs.cbucket = Nifti1.sample(seed=0)
+    task.inputs.matrix = OneD.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_to3d_2():
-    task = To3D()
-    task.inputs.out_file = "dicomdir.nii"
-    task.inputs.in_folder = "."
-    task.inputs.filetype = "anat"
-    task.inputs.datatype = "float"
+def test_synthesize_2():
+    task = Synthesize()
+    task.inputs.cbucket = Nifti1.sample(seed=0)
+    task.inputs.matrix = OneD.sample(seed=1)
+    task.inputs.select = ["baseline"]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tproject.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_t_shift.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,33 +1,65 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_project import TProject
+from pydra.tasks.afni.auto.preprocess.t_shift import t_shift
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
+@pytest.mark.xfail
+def test_t_shift_1():
+    task = t_shift()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.tr = "%.1fs" % TR
+    task.inputs.tzero = 0.0
+    task.inputs.slice_timing = list(np.arange(40) / TR)
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
+@pytest.mark.xfail
+def test_t_shift_2():
+    task = t_shift()
+    task.inputs.slice_encoding_direction = "k-"
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
+@pytest.mark.xfail
+def test_t_shift_3():
+    task = t_shift()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.tr = "%.1fs" % TR
+    task.inputs.tzero = 0.0
+    task.inputs.slice_timing = "slice_timing.1D"
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
 @pytest.mark.xfail
-def test_tproject_1():
-    task = TProject()
+def test_t_shift_4():
+    task = t_shift()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.censor = File.sample(seed=2)
-    task.inputs.concat = File.sample(seed=5)
-    task.inputs.ort = File.sample(seed=7)
-    task.inputs.dsort = [File.sample(seed=9)]
-    task.inputs.mask = File.sample(seed=13)
-    task.inputs.num_threads = 1
+    task.inputs.tr = "%.1fs" % TR
+    task.inputs.tzero = 0.0
+    task.inputs.tpattern = "alt+z"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_tproject_2():
-    task = TProject()
+def test_t_shift_5():
+    task = t_shift()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "projected.nii.gz"
-    task.inputs.polort = 3
-    task.inputs.bandpass = (0.00667, 99999)
-    task.inputs.automask = True
+    task.inputs.tr = "%.1fs" % TR
+    task.inputs.tzero = 0.0
+    task.inputs.tpattern = "@slice_timing.1D"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tshift.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tshift.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,17 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_shift import TShift
+from pydra.tasks.afni.auto.preprocess.t_shift import TShift
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
 def test_tshift_1():
     task = TShift()
     task.inputs.in_file = Nifti1.sample(seed=0)
     task.inputs.slice_encoding_direction = "k"
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tsmooth.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_tcat.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,30 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_smooth import TSmooth
+from pydra.tasks.afni.auto.utils.t_cat import TCat
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_tsmooth_1():
-    task = TSmooth()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.custom = File.sample(seed=9)
+def test_tcat_1():
+    task = TCat()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_tsmooth_2():
-    task = TSmooth()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.adaptive = 5
+def test_tcat_2():
+    task = TCat()
+    task.inputs.in_files = [Nifti1.sample(seed=0)]
+    task.inputs.out_file = Nifti1.sample(seed=1)
+    task.inputs.rlt = "+"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_tstat.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_auto_tcorrelate.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,26 +1,21 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.t_stat import TStat
+from pydra.tasks.afni.auto.preprocess.auto_tcorrelate import auto_tcorrelate
 import pytest
 
 
-@pytest.mark.xfail
-def test_tstat_1():
-    task = TStat()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.mask = File.sample(seed=2)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_tstat_2():
-    task = TStat()
+def test_auto_tcorrelate_1():
+    task = auto_tcorrelate()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "stats"
+    task.inputs.polort = -1
+    task.inputs.eta2 = True
+    task.inputs.mask = Nifti1.sample(seed=3)
+    task.inputs.mask_only_targets = True
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_unifize.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_bucket.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.unifize import Unifize
+from pydra.tasks.afni.auto.utils.bucket import Bucket
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_unifize_1():
-    task = Unifize()
-    task.inputs.in_file = Nifti1.sample(seed=0)
+def test_bucket_1():
+    task = Bucket()
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_unifize_2():
-    task = Unifize()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "structural_unifized.nii"
+def test_bucket_2():
+    task = Bucket()
+    task.inputs.in_file = [("functional.nii", "{2..$}"), ("functional.nii", "{1}")]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_warp.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_tcorrmap.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,40 +1,45 @@
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.warp import Warp
+from pydra.tasks.afni.auto.preprocess.t_corr_map import TCorrMap
 import pytest
 
 
-@pytest.mark.xfail
-def test_warp_1():
-    task = Warp()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.matparent = File.sample(seed=4)
-    task.inputs.oblique_parent = File.sample(seed=5)
-    task.inputs.gridset = File.sample(seed=8)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_warp_2():
-    task = Warp()
+def test_tcorrmap_1():
+    task = TCorrMap()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "trans.nii.gz"
-    task.inputs.deoblique = True
+    task.inputs.seeds = File.sample(seed=1)
+    task.inputs.mask = Nifti1.sample(seed=2)
+    task.inputs.regress_out_timeseries = File.sample(seed=6)
+    task.inputs.mean_file = File.sample(seed=9)
+    task.inputs.zmean = File.sample(seed=10)
+    task.inputs.qmean = File.sample(seed=11)
+    task.inputs.pmean = File.sample(seed=12)
+    task.inputs.absolute_threshold = File.sample(seed=14)
+    task.inputs.var_absolute_threshold = File.sample(seed=15)
+    task.inputs.var_absolute_threshold_normalize = File.sample(seed=16)
+    task.inputs.correlation_maps = File.sample(seed=17)
+    task.inputs.correlation_maps_masked = File.sample(seed=18)
+    task.inputs.average_expr = File.sample(seed=20)
+    task.inputs.average_expr_nonzero = File.sample(seed=21)
+    task.inputs.sum_expr = File.sample(seed=22)
+    task.inputs.histogram = File.sample(seed=24)
+    task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_warp_3():
-    task = Warp()
+def test_tcorrmap_2():
+    task = TCorrMap()
     task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "trans.nii.gz"
-    task.inputs.newgrid = 1.0
+    task.inputs.mask = Nifti1.sample(seed=2)
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_zcutup.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/utils/tests/test_convert_dset.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,25 +1,19 @@
-from fileformats.medimage.nifti import Nifti1
+from fileformats.generic import File
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.z_cut_up import ZCutUp
+from pydra.tasks.afni.auto.utils.convert_dset import convert_dset
 import pytest
 
 
-@pytest.mark.xfail
-def test_zcutup_1():
-    task = ZCutUp()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.num_threads = 1
-    print(f"CMDLINE: {task.cmdline}\n\n")
-    res = task(plugin=PassAfterTimeoutWorker)
-    print("RESULT: ", res)
+logger = logging.getLogger(__name__)
 
 
 @pytest.mark.xfail
-def test_zcutup_2():
-    task = ZCutUp()
-    task.inputs.in_file = Nifti1.sample(seed=0)
-    task.inputs.out_file = "functional_zcutup.nii"
-    task.inputs.keep = "0 10"
+def test_convert_dset_1():
+    task = convert_dset()
+    task.inputs.in_file = File.sample(seed=0)
+    task.inputs.out_file = File.sample(seed=1)
+    task.inputs.out_type = "niml_asc"
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/pydra/tasks/afni/auto/tests/test_zeropad.py` & `pydra_afni-0.3.2/pydra/tasks/afni/auto/preprocess/tests/test_allineate.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,32 +1,65 @@
+from fileformats.datascience import TextMatrix
 from fileformats.generic import File
-from fileformats.medimage.nifti import Nifti1
+from fileformats.medimage import Nifti1
+from fileformats.text import TextFile
+import logging
 from nipype2pydra.testing import PassAfterTimeoutWorker
-from pydra.tasks.afni.auto.zeropad import Zeropad
+from pydra.tasks.afni.auto.preprocess.allineate import Allineate
 import pytest
 
 
+logger = logging.getLogger(__name__)
+
+
 @pytest.mark.xfail
-def test_zeropad_1():
-    task = Zeropad()
-    task.inputs.in_files = Nifti1.sample(seed=0)
-    task.inputs.master = File.sample(seed=13)
+def test_allineate_1():
+    task = Allineate()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.reference = Nifti1.sample(seed=1)
+    task.inputs.out_file = Nifti1.sample(seed=2)
+    task.inputs.out_param_file = File.sample(seed=3)
+    task.inputs.in_param_file = File.sample(seed=4)
+    task.inputs.out_matrix = File.sample(seed=5)
+    task.inputs.in_matrix = TextMatrix.sample(seed=6)
+    task.inputs.allcostx = TextFile.sample(seed=8)
+    task.inputs.weight_file = File.sample(seed=29)
+    task.inputs.out_weight_file = File.sample(seed=31)
+    task.inputs.source_mask = File.sample(seed=32)
+    task.inputs.master = File.sample(seed=43)
     task.inputs.num_threads = 1
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
 
 
 @pytest.mark.xfail
-def test_zeropad_2():
-    task = Zeropad()
-    task.inputs.in_files = Nifti1.sample(seed=0)
-    task.inputs.out_file = "pad_functional.nii"
-    task.inputs.I = 10
-    task.inputs.S = 10
-    task.inputs.A = 10
-    task.inputs.P = 10
-    task.inputs.L = 10
-    task.inputs.R = 10
+def test_allineate_2():
+    task = Allineate()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.out_file = Nifti1.sample(seed=2)
+    task.inputs.in_matrix = TextMatrix.sample(seed=6)
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
+@pytest.mark.xfail
+def test_allineate_3():
+    task = Allineate()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.reference = Nifti1.sample(seed=1)
+    task.inputs.allcostx = TextFile.sample(seed=8)
+    print(f"CMDLINE: {task.cmdline}\n\n")
+    res = task(plugin=PassAfterTimeoutWorker)
+    print("RESULT: ", res)
+
+
+@pytest.mark.xfail
+def test_allineate_4():
+    task = Allineate()
+    task.inputs.in_file = Nifti1.sample(seed=0)
+    task.inputs.reference = Nifti1.sample(seed=1)
+    task.inputs.nwarp_fixmot = ["X", "Y"]
     print(f"CMDLINE: {task.cmdline}\n\n")
     res = task(plugin=PassAfterTimeoutWorker)
     print("RESULT: ", res)
```

### Comparing `pydra_afni-0.2.2.post186034/related-packages/conftest.py` & `pydra_afni-0.3.2/related-packages/conftest.py`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats/LICENSE` & `pydra_afni-0.3.2/related-packages/fileformats/LICENSE`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats/README.rst` & `pydra_afni-0.3.2/related-packages/fileformats-extras/README.rst`

 * *Files 26% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-FileFormats Medimage/AFNI
-=========================
+FileFormats-afni Extras
+======================================
+.. image:: https://github.com/nipype/pydra-freesurfer/actions/workflows/ci-cd.yaml/badge.svg
+    :target: https://github.com/nipype/pydra-freesurfer/actions/workflows/ci-cd.yaml
 
-.. image:: https://github.com/nipype/pydra-afni/actions/workflows/ci-cd.yaml/badge.svg
-   :target: https://github.com/nipype/pydra-afni/actions/workflows/ci-cd.yaml
 
-
-This is the AFNI extension module for the
-`fileformats <https://github.com/ArcanaFramework/fileformats>`__ package
+This is a extras module for the `fileformats-afni <https://github.com/nipype/pydra-freesurfer/>`__
+fileformats extension package, which provides additional functionality to format classes (i.e. aside
+from basic identification and validation), such as conversion tools, metadata parsers, test data generators, etc...
 
 
 Quick Installation
 ------------------
 
 This extension can be installed for Python 3 using *pip*::
 
-    $ pip3 install fileformats-medimage-afni
+    $ pip3 install fileformats-afni-extras
 
 This will install the core package and any other dependencies
 
 License
 -------
 
 This work is licensed under a
```

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats/pyproject.toml` & `pydra_afni-0.3.2/related-packages/fileformats/pyproject.toml`

 * *Files 3% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 build-backend = "hatchling.build"
 
 [project]
 name = "fileformats-medimage-afni"
 description = "Classes for representing different file formats in Python classes for use in type hinting in data workflows"
 readme = "README.rst"
 requires-python = ">=3.8"
-dependencies = ["fileformats", "fileformats-medimage"]
+dependencies = ["fileformats >= 0.4", "fileformats-medimage >= 0.2"]
 license = { file = "LICENSE" }
 authors = [{ name = "Thomas G. Close", email = "tom.g.close@gmail.com" }]
 maintainers = [{ name = "Thomas G. Close", email = "tom.g.close@gmail.com" }]
 keywords = ["file formats", "data"]
 classifiers = [
     "Development Status :: 3 - Alpha",
     "Environment :: Console",
```

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/LICENSE` & `pydra_afni-0.3.2/related-packages/fileformats-extras/LICENSE`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/pyproject.toml` & `pydra_afni-0.3.2/related-packages/fileformats-extras/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -4,17 +4,17 @@
 
 [project]
 name = "fileformats-medimage-afni-extras"
 description = "Extensions to add functionality to tool-specific *fileformats* classes"
 readme = "README.rst"
 requires-python = ">=3.8"
 dependencies = [
-    "fileformats",
+    "fileformats >= 0.7",
     "fileformats-medimage-afni",
-    "pydra >= 0.23.0a"
+    "pydra >= 0.22.0"
 ]
 license = {file = "LICENSE"}
 authors = [
     {name = "Thomas G. Close", email = "tom.g.close@gmail.com"},
 ]
 maintainers = [
     {name = "Thomas G. Close", email = "tom.g.close@gmail.com"},
```

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/fileformats/extras/medimage_afni/__init__.py` & `pydra_afni-0.3.2/related-packages/fileformats-extras/fileformats/extras/medimage_afni/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,61 +1,60 @@
-from ._version import __version__  # noqa: F401
-from pathlib import Path
 import typing as ty
-from random import Random
+from pathlib import Path
 from fileformats.core import FileSet, SampleFileGenerator
 from fileformats.medimage_afni import (
     OneD,
+    Dset,
+    ThreeD,
     Head,
-    All1,
+    NCorr,
     R1,
-    ThreeD,
-    Dset,
+    All1,
 )
+from ._version import __version__
 
 
 @FileSet.generate_sample_data.register
 def gen_sample_oned_data(
-    oned: OneD,
-    generator: SampleFileGenerator,
+    oned: OneD, generator: SampleFileGenerator
 ) -> ty.Iterable[Path]:
     raise NotImplementedError
 
 
 @FileSet.generate_sample_data.register
-def gen_sample_head_data(
-    head: Head,
-    generator: SampleFileGenerator,
+def gen_sample_dset_data(
+    dset: Dset, generator: SampleFileGenerator
 ) -> ty.Iterable[Path]:
     raise NotImplementedError
 
 
 @FileSet.generate_sample_data.register
-def gen_sample_all1_data(
-    all1: All1,
-    generator: SampleFileGenerator,
+def gen_sample_threed_data(
+    threed: ThreeD, generator: SampleFileGenerator
 ) -> ty.Iterable[Path]:
     raise NotImplementedError
 
 
 @FileSet.generate_sample_data.register
-def gen_sample_r1_data(
-    r1: R1,
-    generator: SampleFileGenerator,
+def gen_sample_head_data(
+    head: Head, generator: SampleFileGenerator
 ) -> ty.Iterable[Path]:
     raise NotImplementedError
 
 
 @FileSet.generate_sample_data.register
-def gen_sample_threed_data(
-    threed: ThreeD,
-    generator: SampleFileGenerator,
+def gen_sample_ncorr_data(
+    ncorr: NCorr, generator: SampleFileGenerator
 ) -> ty.Iterable[Path]:
     raise NotImplementedError
 
 
 @FileSet.generate_sample_data.register
-def gen_sample_dset_data(
-    dset: Dset,
-    generator: SampleFileGenerator,
+def gen_sample_r1_data(r1: R1, generator: SampleFileGenerator) -> ty.Iterable[Path]:
+    raise NotImplementedError
+
+
+@FileSet.generate_sample_data.register
+def gen_sample_all1_data(
+    all1: All1, generator: SampleFileGenerator
 ) -> ty.Iterable[Path]:
     raise NotImplementedError
```

### Comparing `pydra_afni-0.2.2.post186034/related-packages/fileformats-extras/fileformats/extras/medimage_afni/tests/test_generate_sample_data.py` & `pydra_afni-0.3.2/related-packages/fileformats-extras/fileformats/extras/medimage_afni/tests/test_generate_sample_data.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,39 +1,45 @@
 import pytest
 from fileformats.medimage_afni import (
     OneD,
+    Dset,
     ThreeD,
+    Head,
+    NCorr,
     R1,
     All1,
-    Dset,
-    Head,
 )
 
 
 @pytest.mark.xfail(reason="generate_sample_data not implemented")
-def test_generate_sample_oned_data():
+def test_generate_one_d_data():
     assert isinstance(OneD.sample(), OneD)
 
 
 @pytest.mark.xfail(reason="generate_sample_data not implemented")
-def test_generate_sample_threed_data():
+def test_generate_three_d_data():
     assert isinstance(ThreeD.sample(), ThreeD)
 
 
 @pytest.mark.xfail(reason="generate_sample_data not implemented")
-def test_generate_sample_r1_data():
-    assert isinstance(R1.sample(), R1)
+def test_generate_dset_data():
+    assert isinstance(Dset.sample(), Dset)
 
 
 @pytest.mark.xfail(reason="generate_sample_data not implemented")
-def test_generate_sample_all1_data():
-    assert isinstance(All1.sample(), All1)
+def test_generate_head_data():
+    assert isinstance(Head.sample(), Head)
 
 
 @pytest.mark.xfail(reason="generate_sample_data not implemented")
-def test_generate_sample_dset_data():
-    assert isinstance(Dset.sample(), Dset)
+def test_generate_ncorr_data():
+    assert isinstance(NCorr.sample(), NCorr)
 
 
 @pytest.mark.xfail(reason="generate_sample_data not implemented")
-def test_generate_sample_head_data():
-    assert isinstance(Head.sample(), Head)
+def test_generate_r1_data():
+    assert isinstance(R1.sample(), R1)
+
+
+@pytest.mark.xfail(reason="generate_sample_data not implemented")
+def test_generate_all1_data():
+    assert isinstance(All1.sample(), All1)
```

### Comparing `pydra_afni-0.2.2.post186034/.gitignore` & `pydra_afni-0.3.2/.gitignore`

 * *Files 21% similar despite different names*

```diff
@@ -127,19 +127,15 @@
 
 # Pyre type checker
 .pyre/
 
 # Pycharm
 .idea
 
-# Vim
-.*.sw[op]
-
 # VS Code
 .vscode
 
 # Mac garbarge
 .DS_store
 
 /pydra/tasks/afni/_version.py
-/related-packages/fileformats/fileformats/medimage_afni/_version.py
-/related-packages/fileformats-extras/fileformats/extras/medimage_afni/_version.py
+/related-packages/**/_version.py
```

### Comparing `pydra_afni-0.2.2.post186034/LICENSE` & `pydra_afni-0.3.2/LICENSE`

 * *Files identical despite different names*

### Comparing `pydra_afni-0.2.2.post186034/README.rst` & `pydra_afni-0.3.2/README.rst`

 * *Files 2% similar despite different names*

```diff
@@ -10,40 +10,40 @@
    :target: https://pypi.python.org/pypi/pydra-afni/
    :alt: Supported Python versions
 .. image:: https://img.shields.io/pypi/v/pydra-afni.svg
    :target: https://pypi.python.org/pypi/pydra-afni/
    :alt: Latest Version
 
 
-This package contains a collection of Pydra task interfaces for the `AFNI <https://afni.nimh.nih.gov/>`__
-software toolkit. The basis of this collection has been formed by the semi-automatic
-conversion of existing `Nipype <https://github.com/nipy/nipype>`__ interfaces to Pydra
-using the `Nipype2Pydra <https://github.com/nipype/nipype2pydra>`__ tool
+This package contains a collection of Pydra task interfaces for the afni toolkit.
+The basis of this collection has been formed by the semi-automatic conversion of
+existing `Nipype <https://github.com/nipy/nipype>`__ interfaces to Pydra using the
+`Nipype2Pydra <https://github.com/nipype/nipype2pydra>`__ tool
 
 
 Automatically-generated vs manually-curated tasks
 -------------------------------------------------
 
 Automatically generated tasks can be found in the `pydra.tasks.afni.auto` package.
 These packages should be treated with extreme caution as they likely do not pass testing.
 Generated tasks that have been edited and pass testing are imported into one or more of the
-`pydra.tasks.afni.v*` packages, corresponding to the version of AFNI they are designed for. 
+`pydra.tasks.afni.v*` packages, corresponding to the version of the afni toolkit
+they are designed for. 
 
 Tests
 -----
 
 This package comes with a battery of automatically generated test modules. To install
 the necessary dependencies to run the tests
 
 .. code-block::
 
    $ pip install -e .[test]
 
-Then the tests, including `doctests` <https://docs.python.org/3/library/doctest.html>`__,
-can be launched using
+Then the tests, including `doctests` <https://docs.python.org/3/library/doctest.html>`__, can be launched using
 
 .. code-block::
 
    $ pytest --doctest-modules pydra/tasks/*
 
 By default, the tests are set to time-out after 10s, after which the underlying tool is
 assumed to have passed the validation/initialisation phase and we assume that it will
@@ -67,22 +67,14 @@
 
 Contributing to this package
 ----------------------------
 
 Developer installation
 ~~~~~~~~~~~~~~~~~~~~~~
 
-Install the `fileformats <https://arcanaframework.github.io/fileformats/>`__ packages
-corresponding to AFNI specific file formats
-
-
-.. code-block::
-
-   $ pip install -e ./related-packages/fileformats[dev]
-   $ pip install -e ./related-packages/fileformats-extras[dev]
 
 Install repo in developer mode from the source directory and install pre-commit to
 ensure consistent code-style and quality.
 
 .. code-block::
 
    $ pip install -e .[test,dev]
@@ -97,16 +89,15 @@
 
 The run the conversion script to convert Nipype interfaces to Pydra
 
 .. code-block::
 
    $ nipype-auto-conv/generate
 
-Methodology
-~~~~~~~~~~~
+## Methodology
 
 The development of this package is expected to have two phases
 
 1. Where the corresponding Nipype interfaces are considered to be the ground truth, and
    the Pydra tasks are generated from them
 2. When the Pydra tasks are considered be mature and they are edited by hand
```

### Comparing `pydra_afni-0.2.2.post186034/pyproject.toml` & `pydra_afni-0.3.2/pyproject.toml`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,16 @@
 readme = "README.rst"
 requires-python = ">=3.8"
 dependencies = [
     "pydra >=0.22",
     "fileformats >=0.8.3",
     "fileformats-datascience >=0.1",
     "fileformats-medimage >=0.4.1",
-    "fileformats-medimage-afni"
+    "fileformats-medimage-afni",
+    "looseversion"
 ]
 license = {file = "LICENSE"}
 authors = [{name = "Nipype developers", email = "neuroimaging@python.org"}]
 maintainers = [{name = "Nipype developers", email = "neuroimaging@python.org"}]
 keywords = ["pydra"]
 classifiers = [
     "Development Status :: 2 - Pre-Alpha",
```

### Comparing `pydra_afni-0.2.2.post186034/PKG-INFO` & `pydra_afni-0.3.2/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.3
 Name: pydra-afni
-Version: 0.2.2.post186034
+Version: 0.3.2
 Summary: Pydra tasks package for afni
 Author-email: Nipype developers <neuroimaging@python.org>
 Maintainer-email: Nipype developers <neuroimaging@python.org>
 License:    Copyright 2021 Nipype developers
         
            Licensed under the Apache License, Version 2.0 (the "License");
            you may not use this file except in compliance with the License.
@@ -28,14 +28,15 @@
 Classifier: Programming Language :: Python :: 3
 Classifier: Topic :: Scientific/Engineering
 Requires-Python: >=3.8
 Requires-Dist: fileformats-datascience>=0.1
 Requires-Dist: fileformats-medimage-afni
 Requires-Dist: fileformats-medimage>=0.4.1
 Requires-Dist: fileformats>=0.8.3
+Requires-Dist: looseversion
 Requires-Dist: pydra>=0.22
 Provides-Extra: dev
 Requires-Dist: black; extra == 'dev'
 Requires-Dist: pre-commit; extra == 'dev'
 Provides-Extra: doc
 Requires-Dist: packaging; extra == 'doc'
 Requires-Dist: sphinx-rtd-theme; extra == 'doc'
@@ -69,40 +70,40 @@
    :target: https://pypi.python.org/pypi/pydra-afni/
    :alt: Supported Python versions
 .. image:: https://img.shields.io/pypi/v/pydra-afni.svg
    :target: https://pypi.python.org/pypi/pydra-afni/
    :alt: Latest Version
 
 
-This package contains a collection of Pydra task interfaces for the `AFNI <https://afni.nimh.nih.gov/>`__
-software toolkit. The basis of this collection has been formed by the semi-automatic
-conversion of existing `Nipype <https://github.com/nipy/nipype>`__ interfaces to Pydra
-using the `Nipype2Pydra <https://github.com/nipype/nipype2pydra>`__ tool
+This package contains a collection of Pydra task interfaces for the afni toolkit.
+The basis of this collection has been formed by the semi-automatic conversion of
+existing `Nipype <https://github.com/nipy/nipype>`__ interfaces to Pydra using the
+`Nipype2Pydra <https://github.com/nipype/nipype2pydra>`__ tool
 
 
 Automatically-generated vs manually-curated tasks
 -------------------------------------------------
 
 Automatically generated tasks can be found in the `pydra.tasks.afni.auto` package.
 These packages should be treated with extreme caution as they likely do not pass testing.
 Generated tasks that have been edited and pass testing are imported into one or more of the
-`pydra.tasks.afni.v*` packages, corresponding to the version of AFNI they are designed for. 
+`pydra.tasks.afni.v*` packages, corresponding to the version of the afni toolkit
+they are designed for. 
 
 Tests
 -----
 
 This package comes with a battery of automatically generated test modules. To install
 the necessary dependencies to run the tests
 
 .. code-block::
 
    $ pip install -e .[test]
 
-Then the tests, including `doctests` <https://docs.python.org/3/library/doctest.html>`__,
-can be launched using
+Then the tests, including `doctests` <https://docs.python.org/3/library/doctest.html>`__, can be launched using
 
 .. code-block::
 
    $ pytest --doctest-modules pydra/tasks/*
 
 By default, the tests are set to time-out after 10s, after which the underlying tool is
 assumed to have passed the validation/initialisation phase and we assume that it will
@@ -126,22 +127,14 @@
 
 Contributing to this package
 ----------------------------
 
 Developer installation
 ~~~~~~~~~~~~~~~~~~~~~~
 
-Install the `fileformats <https://arcanaframework.github.io/fileformats/>`__ packages
-corresponding to AFNI specific file formats
-
-
-.. code-block::
-
-   $ pip install -e ./related-packages/fileformats[dev]
-   $ pip install -e ./related-packages/fileformats-extras[dev]
 
 Install repo in developer mode from the source directory and install pre-commit to
 ensure consistent code-style and quality.
 
 .. code-block::
 
    $ pip install -e .[test,dev]
@@ -156,16 +149,15 @@
 
 The run the conversion script to convert Nipype interfaces to Pydra
 
 .. code-block::
 
    $ nipype-auto-conv/generate
 
-Methodology
-~~~~~~~~~~~
+## Methodology
 
 The development of this package is expected to have two phases
 
 1. Where the corresponding Nipype interfaces are considered to be the ground truth, and
    the Pydra tasks are generated from them
 2. When the Pydra tasks are considered be mature and they are edited by hand
```

